{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2239c1-e1b6-46be-8734-f1a3298fb062",
   "metadata": {},
   "source": [
    "# Pip Wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddb3b1f-8cf9-4ead-895f-9a5768440183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pytorch_lightning\\n!pip install torchmetrics\\n!pip install tokenizers\\n!pip install transformers\\n!pip install ray[tune]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install pytorch_lightning\n",
    "!pip install torchmetrics\n",
    "!pip install tokenizers\n",
    "!pip install transformers\n",
    "!pip install ray[tune]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc890c3d-d9af-45d0-a1df-36462ffdf4b7",
   "metadata": {
    "id": "ICgrtlaznr7F"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba724d89-aea8-4bf1-bd16-1380bcdce9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUiP-rVLnr7H",
    "outputId": "79dc16d8-54ad-42df-a406-ef7564341a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from tqdm.auto import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Type\n",
    "from copy import deepcopy\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, seed_everything, Trainer, LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.functional import f1_score, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loops.loop import Loop\n",
    "from pytorch_lightning.loops.fit_loop import FitLoop\n",
    "from pytorch_lightning.trainer.states import TrainerFn\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "# Ray[Tune]\n",
    "import ray\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "\n",
    "\n",
    "# HuggingFace Libraries\n",
    "import tokenizers\n",
    "import transformers \n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990e45de-3f45-42f3-b6d9-37e5bfad651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 20:12:33,563\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '131.114.50.210', 'raylet_ip_address': '131.114.50.210', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-08_20-12-31_852004_1360461/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-08_20-12-31_852004_1360461/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-08_20-12-31_852004_1360461', 'metrics_export_port': 51033, 'gcs_address': '131.114.50.210:63114', 'address': '131.114.50.210:63114', 'dashboard_agent_listen_port': 52365, 'node_id': '50cee8f1bfc0af36fd2ed3cfaa5c0ab37ee2b8f8c1121d7b74200276'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_gpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afdc09-2e7d-412d-9cbf-39e104819dad",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5fc28-1a0b-4c86-9da6-e156d4e88d13",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Class: notebook-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca2dbb5-92b6-4d04-b479-223aaeb390d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # General\n",
    "    seed = 42\n",
    "    \n",
    "    # Debug \n",
    "    debug = True\n",
    "    debug_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ccc5e-ced9-4c6b-ba6c-29e7ed9ffbac",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Dictionary: trial-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9985db04-ae1c-492c-9cca-eeac1b209381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a search space!\n",
    "config_dict = {\n",
    "    \"target_size\" : 1,\n",
    "    \"num_workers\" : 8,\n",
    "    \n",
    "    # Training parameters\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 2,\n",
    "    \"n_fold\" : 2,\n",
    "    \"warmup_steps\" : 0,\n",
    "    \"min_lr\" : 1e-6,\n",
    "    \"encoder_lr\" : 2e-5,\n",
    "    \"decoder_lr\" : 2e-5,\n",
    "    \"eps\" : 1e-6,\n",
    "    \"betas\" : (0.9, 0.999),\n",
    "    \"weight_decay\" : 0.01,\n",
    "    \"fc_dropout\" : 0.2,\n",
    "\n",
    "    # Transformers\n",
    "    # \"model\" : tune.grid_search([\"distilbert-base-uncased\", \"microsoft/deberta-v3-large\"]),\n",
    "    # \"model\" : tune.choice([\"microsoft/deberta-v3-large\"]),\n",
    "    # \"model\" : tune.choice([\"distilbert-base-uncased\"]),\n",
    "    \"model\" : \"distilbert-base-uncased\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd0738-9bbe-4d25-8510-aaf5a7110750",
   "metadata": {
    "id": "iIVnbwmdnr7K"
   },
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5da60d-3f9b-4ea6-9254-dc40d402afce",
   "metadata": {
    "id": "JaQ5oUkRnr7N"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../dataset/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38b47b-7a99-4942-b910-c0e7cac5cebf",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8398a15a-644b-4e83-8d46-543e37ed59d8",
   "metadata": {
    "id": "T-mYdoUjnr7R"
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"USPPPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384aa55c-0f30-4569-9300-3c2a3430727b",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00781e09-61ab-49ea-a16e-212fb8683047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeDb5W-Wnr7U",
    "outputId": "9efeb745-33a8-42c9-a578-3de670bc7cb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2b97f-909f-455b-b81d-b90a366b2676",
   "metadata": {},
   "source": [
    "## Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8e52ee-27e5-4260-90a1-684468fa2599",
   "metadata": {
    "id": "PWOAoAcCnr7W"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    score = sp.stats.pearsonr(y_true, y_pred)[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f8751-79fe-492a-a1c8-eb35867f3909",
   "metadata": {
    "id": "IeqIEukjnr7W"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca74519-9ccd-48be-ba61-67466fceea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id     anchor                  target context  \\\n",
       "0           0  37d61fd2272659b1  abatement  abatement of pollution     A47   \n",
       "1           1  7b9652b17b68b7a4  abatement          act of abating     A47   \n",
       "2           2  36d72442aefd8232  abatement         active catalyst     A47   \n",
       "3           3  5296b0c19e1ce60e  abatement     eliminating process     A47   \n",
       "4           4  54c1e3b9184cb5b6  abatement           forest region     A47   \n",
       "\n",
       "   score                                       context_text  \\\n",
       "0   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "1   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "2   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "3   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "4   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "\n",
       "                                                text  score_map  \n",
       "0  abatement[SEP]abatement of pollution[SEP]HUMAN...          2  \n",
       "1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...          3  \n",
       "2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...          1  \n",
       "3  abatement[SEP]eliminating process[SEP]HUMAN NE...          2  \n",
       "4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc_texts = torch.load('cpc_texts.pth')\n",
    "dataframe = pd.read_csv(\"dataframe.csv\")\n",
    "display(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17be84-7e8e-4cc8-99a5-5b5835d9984c",
   "metadata": {},
   "source": [
    "## Debug Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8036555-0930-4a1e-a4e6-fb088d201ced",
   "metadata": {
    "id": "6zeWhBTmvC2N"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    dataframe = dataframe.iloc[:CFG.debug_samples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc687c3-b2d5-4ad1-b872-bc08c0edea4e",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f8730b-3f39-46bb-ad8d-28521a3aa08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1222e36d9a94c2a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>stone abutments</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]stone abutments[SEP]HUMAN NECESS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>bc5af15a01442792</td>\n",
       "      <td>abatement</td>\n",
       "      <td>control panel</td>\n",
       "      <td>F24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "      <td>abatement[SEP]control panel[SEP]MECHANICAL ENG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>80126fcecd1c57c9</td>\n",
       "      <td>abnormal position</td>\n",
       "      <td>abnormal placement</td>\n",
       "      <td>D03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>TEXTILES; PAPER. WEAVING</td>\n",
       "      <td>abnormal position[SEP]abnormal placement[SEP]T...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>4bb652c1091f3d1d</td>\n",
       "      <td>abatement</td>\n",
       "      <td>diminished image</td>\n",
       "      <td>F24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "      <td>abatement[SEP]diminished image[SEP]MECHANICAL ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>115dcdbc38948359</td>\n",
       "      <td>abnormal position</td>\n",
       "      <td>position vector</td>\n",
       "      <td>D03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXTILES; PAPER. WEAVING</td>\n",
       "      <td>abnormal position[SEP]position vector[SEP]TEXT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                id             anchor              target  \\\n",
       "18          18  1222e36d9a94c2a4          abatement     stone abutments   \n",
       "30          30  bc5af15a01442792          abatement       control panel   \n",
       "73          73  80126fcecd1c57c9  abnormal position  abnormal placement   \n",
       "33          33  4bb652c1091f3d1d          abatement    diminished image   \n",
       "90          90  115dcdbc38948359  abnormal position     position vector   \n",
       "\n",
       "   context  score                                       context_text  \\\n",
       "18     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "30     F24   0.00  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...   \n",
       "73     D03   0.75                           TEXTILES; PAPER. WEAVING   \n",
       "33     F24   0.00  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...   \n",
       "90     D03   0.00                           TEXTILES; PAPER. WEAVING   \n",
       "\n",
       "                                                 text  score_map  \n",
       "18  abatement[SEP]stone abutments[SEP]HUMAN NECESS...          0  \n",
       "30  abatement[SEP]control panel[SEP]MECHANICAL ENG...          0  \n",
       "73  abnormal position[SEP]abnormal placement[SEP]T...          3  \n",
       "33  abatement[SEP]diminished image[SEP]MECHANICAL ...          0  \n",
       "90  abnormal position[SEP]position vector[SEP]TEXT...          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>4f8d18e7ee6f98e9</td>\n",
       "      <td>abnormal position</td>\n",
       "      <td>locked position</td>\n",
       "      <td>D03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXTILES; PAPER. WEAVING</td>\n",
       "      <td>abnormal position[SEP]locked position[SEP]TEXT...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>8aedbf799717e3e7</td>\n",
       "      <td>abnormal position</td>\n",
       "      <td>condition shown</td>\n",
       "      <td>B23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MACHINE T...</td>\n",
       "      <td>abnormal position[SEP]condition shown[SEP]PERF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>9c0105f34aedca0d</td>\n",
       "      <td>abnormal position</td>\n",
       "      <td>positions</td>\n",
       "      <td>B41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. PRINTING;...</td>\n",
       "      <td>abnormal position[SEP]positions[SEP]PERFORMING...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>1d4a73e6a5e56a01</td>\n",
       "      <td>abatement</td>\n",
       "      <td>treating emissions</td>\n",
       "      <td>F24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "      <td>abatement[SEP]treating emissions[SEP]MECHANICA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>4d9fb5ff45c8ab1d</td>\n",
       "      <td>abatement</td>\n",
       "      <td>subsiding</td>\n",
       "      <td>F24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "      <td>abatement[SEP]subsiding[SEP]MECHANICAL ENGINEE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                id             anchor              target  \\\n",
       "83          83  4f8d18e7ee6f98e9  abnormal position     locked position   \n",
       "53          53  8aedbf799717e3e7  abnormal position     condition shown   \n",
       "70          70  9c0105f34aedca0d  abnormal position           positions   \n",
       "45          45  1d4a73e6a5e56a01          abatement  treating emissions   \n",
       "44          44  4d9fb5ff45c8ab1d          abatement           subsiding   \n",
       "\n",
       "   context  score                                       context_text  \\\n",
       "83     D03   0.50                           TEXTILES; PAPER. WEAVING   \n",
       "53     B23   0.25  PERFORMING OPERATIONS; TRANSPORTING. MACHINE T...   \n",
       "70     B41   0.50  PERFORMING OPERATIONS; TRANSPORTING. PRINTING;...   \n",
       "45     F24   0.50  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...   \n",
       "44     F24   0.50  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...   \n",
       "\n",
       "                                                 text  score_map  \n",
       "83  abnormal position[SEP]locked position[SEP]TEXT...          2  \n",
       "53  abnormal position[SEP]condition shown[SEP]PERF...          1  \n",
       "70  abnormal position[SEP]positions[SEP]PERFORMING...          2  \n",
       "45  abatement[SEP]treating emissions[SEP]MECHANICA...          2  \n",
       "44  abatement[SEP]subsiding[SEP]MECHANICAL ENGINEE...          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed, stratify = dataframe.score_map)\n",
    "train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb4ea4-8f8b-4860-bccf-238f968b3c3e",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c5624-94b1-4170-b3ea-5656ca92c3f4",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fee091-3c88-4e80-b6ba-16dc97f07200",
   "metadata": {
    "id": "Vs9TXF3pufI0"
   },
   "outputs": [],
   "source": [
    "def set_tokenizer(config_dict):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config_dict['model'])\n",
    "    tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "    config_dict['tokenizer'] = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74b765-ebb0-4d17-8c23-ad9d7bfaa153",
   "metadata": {
    "id": "I8CsgvQFnr7e"
   },
   "source": [
    "## Maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4147285a-c73b-4329-8eeb-d862bf599d29",
   "metadata": {
    "id": "Hxle-CPRnr7e"
   },
   "outputs": [],
   "source": [
    "def set_max_len(config_dict, cpc_texts=cpc_texts, train_df=dataframe):\n",
    "    tokenizer = config_dict['tokenizer']\n",
    "    lengths_dict = {}\n",
    "\n",
    "    lengths = []\n",
    "    tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    lengths_dict['context_text'] = lengths\n",
    "\n",
    "    for text_col in ['anchor', 'target']:\n",
    "        lengths = []\n",
    "        tk0 = tqdm(train_df[text_col].fillna(\"\").values, total=len(train_df))\n",
    "        for text in tk0:\n",
    "            length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "            lengths.append(length)\n",
    "        lengths_dict[text_col] = lengths\n",
    "\n",
    "    config_dict['max_len'] = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n",
    "                    + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cef85f-21a3-4a36-8982-fdf33b97e362",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66398e59-885f-49ef-8f6b-79b5518c7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(config_dict, text):\n",
    "    tokenizer = config_dict['tokenizer']\n",
    "    inputs = tokenizer(text,\n",
    "                       add_special_tokens = True,\n",
    "                       max_length = config_dict['max_len'],\n",
    "                       padding = \"max_length\",\n",
    "                       return_offsets_mapping = False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5087433-6899-4564-9194-537a0164aefd",
   "metadata": {
    "id": "AEyPtCQvnr7f"
   },
   "outputs": [],
   "source": [
    "class USPPM_dataset(Dataset):\n",
    "    def __init__(self, config_dict, train_df, train=True):\n",
    "        self.config_dict = config_dict\n",
    "        self.texts = train_df['text'].values\n",
    "        self.train = train\n",
    "        if train:\n",
    "            self.labels = train_df['score'].values\n",
    "            self.score_map = train_df['score_map'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.config_dict, self.texts[item])\n",
    "        if self.train:\n",
    "            labels = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "            return dict(\n",
    "                  inputs = inputs,\n",
    "                  labels = labels\n",
    "            )\n",
    "        else:\n",
    "            return dict(\n",
    "                  inputs = inputs\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f2468-de35-4bd7-87e8-8b83a3794ab1",
   "metadata": {},
   "source": [
    "# K-Fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18fb2d-a3f7-4cfb-a3dc-ad613c26c2fb",
   "metadata": {
    "id": "Q0HgRiNlnr7g"
   },
   "source": [
    "## KFold DataModule definition                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a3a977-1f80-4039-abfc-eb24ebd4e9a2",
   "metadata": {
    "id": "MVmHarn0nr7h"
   },
   "outputs": [],
   "source": [
    "class BaseKFoldDataModule(LightningDataModule, ABC):\n",
    "    @abstractmethod\n",
    "    def setup_folds(self, num_folds: int) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def setup_fold_index(self, fold_index: int) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d242c6a-01f3-4388-a38b-47f85fcd2240",
   "metadata": {
    "id": "4wjghxElnr7i"
   },
   "source": [
    "## KFoldDataModule implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f986de2-1661-4654-8db0-348e7d8174c1",
   "metadata": {
    "id": "BUeE7TJUnr7i"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class USPPPM_kf_datamodule(BaseKFoldDataModule):\n",
    "    def __init__(self, config_dict, dataframe = dataframe):\n",
    "        \n",
    "        self.config_dict = config_dict\n",
    "        self.prepare_data_per_node = False\n",
    "        self._log_hyperparams = False\n",
    "        \n",
    "        train_dataset: Optional[Dataset] = None\n",
    "        test_dataset: Optional[Dataset] = None\n",
    "        train_fold: Optional[Dataset] = None\n",
    "        val_fold: Optional[Dataset] = None\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "            \n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        # train_df, test_df = train_test_split(self.dataframe, test_size = 0.1, random_state = CFG.seed, stratify = self.dataframe.score_map)\n",
    "        train_df, test_df = train_test_split(self.dataframe, test_size = 0.1, random_state = CFG.seed)\n",
    "        self.train_dataset = USPPM_dataset(self.config_dict, train_df)\n",
    "        self.test_dataset = USPPM_dataset(self.config_dict, test_df)\n",
    "\n",
    "    def setup_folds(self, num_folds: int) -> None:\n",
    "        self.num_folds = num_folds\n",
    "        Fold = StratifiedKFold(n_splits=self.num_folds, shuffle=True)\n",
    "        self.splits = [split for split in Fold.split(self.train_dataset, self.train_dataset.score_map)]\n",
    "\n",
    "    def setup_fold_index(self, fold_index: int) -> None:\n",
    "        train_indices, val_indices = self.splits[fold_index]\n",
    "        self.train_fold = Subset(self.train_dataset, train_indices)\n",
    "        self.val_fold = Subset(self.train_dataset, val_indices)\n",
    "        print(\"TRAIN FOLD\", fold_index + 1, len(self.train_fold))\n",
    "        print(\"VALID FOLD\", fold_index + 1, len(self.val_fold))\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_fold, num_workers = self.config_dict['num_workers'], batch_size = self.config_dict['batch_size'])\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.val_fold, num_workers = self.config_dict['num_workers'], batch_size = self.config_dict['batch_size'])\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.test_dataset, num_workers = self.config_dict['num_workers'], batch_size = self.config_dict['batch_size'])\n",
    "    \n",
    "    def __post_init__(cls):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275e1d1-51fd-4d78-a9f1-4b8dde805ab0",
   "metadata": {
    "id": "1RLF9XVinr7j"
   },
   "source": [
    "## Ensemble Model for kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aebb0fff-b740-4997-9ebd-1624d561d9af",
   "metadata": {
    "id": "dwvwouh3nr7j"
   },
   "outputs": [],
   "source": [
    "class EnsembleVotingModel(LightningModule):\n",
    "    def __init__(self, model_cls: Type[LightningModule], checkpoint_paths: List[str], config_dict):\n",
    "        super().__init__()\n",
    "        # Create `num_folds` models with their associated fold weights\n",
    "        self.models = torch.nn.ModuleList([model_cls.load_from_checkpoint(p, config_dict=config_dict) for p in checkpoint_paths])\n",
    "        self.get_score = get_score\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        # Compute the averaged predictions over the `num_folds` models.\n",
    "        inputs = batch[\"inputs\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        losses = []\n",
    "        scores = []\n",
    "        \n",
    "        for m in self.models : \n",
    "            loss, outputs = m(inputs, labels.unsqueeze(1))\n",
    "            predictions = outputs.squeeze().sigmoid().cpu().detach().numpy()\n",
    "            \n",
    "            score = self.get_score(labels.cpu().numpy(), predictions)\n",
    "            scores.append(score)\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            \n",
    "        avg_loss = np.mean(losses)\n",
    "        avg_score = np.mean(scores)\n",
    "        \n",
    "        self.log(\"ensemble_avg_loss\", avg_loss, prog_bar=True, logger=True)\n",
    "        print('ensemble_avg_loss', avg_loss)\n",
    "        self.log(\"ensemble_avg_score\", avg_score, prog_bar=True, logger=True)\n",
    "        print(\"ensemble_avg_score\", avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea969f-f0e2-4771-8460-f5df58d3aa7e",
   "metadata": {
    "id": "E2ch26C4nr7k"
   },
   "source": [
    "## KFoldLoop implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdcaf77c-dc40-4149-9a17-6b297691c26c",
   "metadata": {
    "id": "ozwbPnfenr7m"
   },
   "outputs": [],
   "source": [
    "class KFoldLoop(Loop):\n",
    "    def __init__(self, num_folds: int, config_dict, export_path: str) -> None:\n",
    "        super().__init__()\n",
    "        self.num_folds = num_folds\n",
    "        self.current_fold: int = 0\n",
    "        self.export_path = export_path\n",
    "        self.config_dict = config_dict\n",
    "\n",
    "    @property\n",
    "    def done(self) -> bool:\n",
    "        return self.current_fold >= self.num_folds\n",
    "\n",
    "    def connect(self, fit_loop: FitLoop) -> None:\n",
    "        self.fit_loop = fit_loop\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Nothing to reset in this loop.\"\"\"\n",
    "\n",
    "    def on_run_start(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Used to call `setup_folds` from the `BaseKFoldDataModule` instance and store the original weights of the model.\"\"\"\n",
    "        assert isinstance(self.trainer.datamodule, BaseKFoldDataModule)\n",
    "        self.trainer.datamodule.setup_folds(self.num_folds)\n",
    "        self.lightning_module_state_dict = deepcopy(self.trainer.lightning_module.state_dict())\n",
    "\n",
    "    def on_advance_start(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Used to call `setup_fold_index` from the `BaseKFoldDataModule` instance.\"\"\"\n",
    "        print(f\"STARTING FOLD {self.current_fold+1}\")\n",
    "        assert isinstance(self.trainer.datamodule, BaseKFoldDataModule)\n",
    "        self.trainer.datamodule.setup_fold_index(self.current_fold)\n",
    "\n",
    "    def advance(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Used to the run a fitting and testing on the current hold.\"\"\"\n",
    "        self._reset_fitting()  # requires to reset the tracking stage.\n",
    "        self.fit_loop.run()\n",
    "\n",
    "        self._reset_testing()  # requires to reset the tracking stage.\n",
    "        self.trainer.test_loop.run()\n",
    "        print('TEST for FOLD', self.current_fold+1)\n",
    "        \n",
    "        self.current_fold += 1  # increment fold tracking number.\n",
    "\n",
    "    def on_advance_end(self) -> None:\n",
    "        \"\"\"Used to save the weights of the current fold and reset the LightningModule and its optimizers.\"\"\"\n",
    "        self.trainer.save_checkpoint(os.path.join(self.export_path, f\"model.{self.current_fold}.pt\"))\n",
    "        # restore the original weights + optimizers and schedulers.\n",
    "        self.trainer.lightning_module.load_state_dict(self.lightning_module_state_dict)\n",
    "        self.trainer.strategy.setup_optimizers(self.trainer)\n",
    "        self.replace(fit_loop=FitLoop)\n",
    "\n",
    "    def on_run_end(self) -> None:\n",
    "        \"\"\"Used to compute the performance of the ensemble model on the test set.\"\"\"\n",
    "        checkpoint_paths = [os.path.join(self.export_path, f\"model.{f_idx + 1}.pt\") for f_idx in range(self.num_folds)]\n",
    "        voting_model = EnsembleVotingModel(type(self.trainer.lightning_module), checkpoint_paths, self.config_dict)\n",
    "        voting_model.trainer = self.trainer\n",
    "\n",
    "        # This requires to connect the new model and move it the right device.\n",
    "        self.trainer.strategy.connect(voting_model)\n",
    "        self.trainer.strategy.model_to_device()\n",
    "        self.trainer.test_loop.run()\n",
    "\n",
    "    def on_save_checkpoint(self) -> Dict[str, int]:\n",
    "        return {\"current_fold\": self.current_fold}\n",
    "\n",
    "    def on_load_checkpoint(self, state_dict: Dict) -> None:\n",
    "        self.current_fold = state_dict[\"current_fold\"]\n",
    "\n",
    "    def _reset_fitting(self) -> None:\n",
    "        self.trainer.reset_train_dataloader()\n",
    "        self.trainer.reset_val_dataloader()\n",
    "        self.trainer.state.fn = TrainerFn.FITTING\n",
    "        self.trainer.training = True\n",
    "\n",
    "    def _reset_testing(self) -> None:\n",
    "        self.trainer.reset_test_dataloader()\n",
    "        self.trainer.state.fn = TrainerFn.TESTING\n",
    "        self.trainer.testing = True\n",
    "\n",
    "    def __getattr__(self, key) -> Any:\n",
    "        # requires to be overridden as attributes of the wrapped loop are being accessed.\n",
    "        if key not in self.__dict__:\n",
    "            return getattr(self.fit_loop, key)\n",
    "        return self.__dict__[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b6702-c290-42e7-8055-33f48a348dff",
   "metadata": {
    "id": "GYPJGJ-Fnr7n"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f8ff48d-c3de-4e84-8df6-b064ed250e6f",
   "metadata": {
    "id": "GY0QVy62nr7o"
   },
   "outputs": [],
   "source": [
    "class USPPPM_model(pl.LightningModule):\n",
    "    def __init__(self, config_dict=config_dict, config_path=None, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(config_dict['model'], output_hidden_states = True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(config_dict['model'], config = self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "            \n",
    "        self.config_dict = config_dict\n",
    "        self.n_warmup_steps = config_dict['warmup_steps']\n",
    "        self.n_training_steps = config_dict['training_steps']\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "            \n",
    "        self.fc_dropout = nn.Dropout(config_dict['fc_dropout'])\n",
    "        self.fc = nn.Linear(self.config.hidden_size, config_dict['target_size'])\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.batch_labels = []\n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(inputs, labels.unsqueeze(1))\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        # session.report({\"train_loss\": loss})  # Send the score to Tune.\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(inputs, labels.unsqueeze(1))\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        # session.report({\"val_loss\": loss})  # Send the score to Tune.\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(inputs, labels.unsqueeze(1))\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        # session.report({\"test_loss\": loss})  # Send the score to Tune.\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "    \n",
    "    def validation_epoch_end(self, batch_results):\n",
    "        outputs, labels, losses = [], [], []\n",
    "        for batch in batch_results:\n",
    "            outputs.append(batch['predictions'])\n",
    "            labels.append(batch['labels'])\n",
    "            losses.append(batch['loss'])\n",
    "\n",
    "        labels = torch.cat(labels).cpu().numpy()\n",
    "        predictions = np.concatenate(torch.cat(outputs).sigmoid().to('cpu').numpy())\n",
    "        score = get_score(labels, predictions)\n",
    "        self.log(\"val_score\", score, prog_bar=True, logger=True)\n",
    "        # tune.report({\"val_score\": score})  # Send the score to Tune.\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config_dict['encoder_lr'])\n",
    "        # optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        )\n",
    "        return dict(\n",
    "          optimizer=optimizer,\n",
    "          lr_scheduler=dict(\n",
    "            scheduler=scheduler,\n",
    "            interval='step'\n",
    "          )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563fc01-1170-43cf-ac1b-f577730cf1a6",
   "metadata": {
    "id": "fK6gpNx1nr7q"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b10ba-6205-419f-844f-0fe5b9dc07d0",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f7ea00-b260-41fd-a636-159e38b66fa8",
   "metadata": {
    "id": "fAEhe31znr7q"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "metrics = {\"val_score\": \"val_score\", \"train_loss\" : \"train_loss\", \"val_loss\" : \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143d9932-bb80-433c-b534-9464d9729443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config_dict):  # Pass a \"config\" dictionary into your trainable.\n",
    "\n",
    "    steps_per_epoch = len(train_df) // config_dict['batch_size']\n",
    "    config_dict['training_steps'] = steps_per_epoch * config_dict['epochs']\n",
    "    \n",
    "    set_tokenizer(config_dict)\n",
    "    set_max_len(config_dict)\n",
    "    # train_dataset = USPPM_dataset(config_dict)\n",
    "    datamodule = USPPPM_kf_datamodule(config_dict, dataframe)\n",
    "    \n",
    "    model = USPPPM_model(config_dict)\n",
    "    \n",
    "    callbacks = [TuneReportCallback(metrics, on=\"validation_end\")]\n",
    "    trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            check_val_every_n_epoch=1,\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=config_dict['epochs'],\n",
    "            devices=[1],\n",
    "            accelerator=\"gpu\",\n",
    "            )\n",
    "    \n",
    "    internal_fit_loop = trainer.fit_loop\n",
    "    trainer.fit_loop = KFoldLoop(config_dict['n_fold'], config_dict, export_path=\"./\")\n",
    "    trainer.fit_loop.connect(internal_fit_loop)\n",
    "    \n",
    "    trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2bb7871-f022-485e-ba7d-d94bbc4db88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fc2e9088904141bbd404d095bd4170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa7bd4d3b474c8e859cd7415b06c290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14b42147b874eadab5416bb90cc2a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "  rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | model      | DistilBertModel   | 66.4 M\n",
      "1 | criterion  | BCEWithLogitsLoss | 0     \n",
      "2 | fc_dropout | Dropout           | 0     \n",
      "3 | fc         | Linear            | 769   \n",
      "4 | attention  | Sequential        | 394 K \n",
      "-------------------------------------------------\n",
      "66.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.8 M    Total params\n",
      "267.032   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FOLD 1\n",
      "TRAIN FOLD 1 45\n",
      "VALID FOLD 1 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9f3ebc35e54e70af115331a2e20ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 20:12:46,807\tWARNING session.py:82 -- Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \n",
      "2022-11-08 20:12:46,808\tWARNING session.py:88 --   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 374, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 358, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/usr/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-24-9135d746aa4b>\", line 1, in <module>\n",
      "    trainable(config_dict)\n",
      "  File \"<ipython-input-23-cc24b5ae0c0c>\", line 28, in trainable\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1283, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"<ipython-input-20-7d71315c5781>\", line 34, in advance\n",
      "    self.fit_loop.run()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 271, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 201, in run\n",
      "    self.on_advance_end()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 241, in on_advance_end\n",
      "    self._run_validation()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 299, in _run_validation\n",
      "    self.val_loop.run()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py\", line 207, in run\n",
      "    output = self.on_run_end()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 201, in on_run_end\n",
      "    self._on_evaluation_end()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 265, in _on_evaluation_end\n",
      "    self.trainer._call_callback_hooks(hook_name, *args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1597, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/integration/pytorch_lightning.py\", line 155, in on_validation_end\n",
      "    self._handle(trainer, pl_module)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/integration/pytorch_lightning.py\", line 239, in _handle\n",
      "    tune.report(**report_dict)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732b5aeb53f641adb93905c896331d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6805387735366821     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6805387735366821    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST for FOLD 1\n",
      "STARTING FOLD 2\n",
      "TRAIN FOLD 2 45\n",
      "VALID FOLD 2 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4f9bbcaa854fa4994353ec3ca17a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021d006aa3d3485eb3fdc54f2591dee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6977958679199219     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6977958679199219    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST for FOLD 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd39b1f0931b44229148ad92dc2e3511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble_avg_loss 0.6891673\n",
      "ensemble_avg_score -0.06593299006263478\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     ensemble_avg_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.689167320728302     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    ensemble_avg_score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   -0.06593299006263478    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    ensemble_avg_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.689167320728302    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   ensemble_avg_score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  -0.06593299006263478   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainable(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351dabf-0be8-490c-9b0c-7fba2c2ab500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4585c05-b217-4753-979e-d975a4ea5872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742d830-c91c-44e7-b124-f2de9095bf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3aed1-8e1e-4634-b772-12a48b881ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afbb39-4d68-4114-b44a-f4c98041590a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d3d30-471e-4901-b0ba-5647b0b0b28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbdaa7-9fb5-47de-9510-940e8f947158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90fa2d9-943a-4b10-b67d-e3dfb002d16c",
   "metadata": {},
   "source": [
    "tuner = tune.Tuner(tune.with_resources(trainable, \n",
    "                                       {\"gpu\": 4}), \n",
    "                                       param_space = config_dict,\n",
    "                                       tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\"),\n",
    "                                       # tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\"),\n",
    "                                       run_config = air.RunConfig(name=\"tune_uspppm\", verbose=3)\n",
    "                                      )\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc4ec7-dc43-473c-be21-d15bf4021932",
   "metadata": {},
   "source": [
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result()  # Get best result object\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d41de4-a568-4693-8519-cd1bb2d02a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
