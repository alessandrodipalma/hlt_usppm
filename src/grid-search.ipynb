{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2239c1-e1b6-46be-8734-f1a3298fb062",
   "metadata": {},
   "source": [
    "# Pip Wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddb3b1f-8cf9-4ead-895f-9a5768440183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pytorch_lightning\\n!pip install torchmetrics\\n!pip install tokenizers\\n!pip install transformers\\n!pip install ray[tune]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install pytorch_lightning\n",
    "!pip install torchmetrics\n",
    "!pip install tokenizers\n",
    "!pip install transformers\n",
    "!pip install ray[tune]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc890c3d-d9af-45d0-a1df-36462ffdf4b7",
   "metadata": {
    "id": "ICgrtlaznr7F"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba724d89-aea8-4bf1-bd16-1380bcdce9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUiP-rVLnr7H",
    "outputId": "79dc16d8-54ad-42df-a406-ef7564341a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything, Trainer, LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.functional import f1_score, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar \n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "# Ray[Tune]\n",
    "import ray\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "\n",
    "import torch\n",
    "# HuggingFace Libraries\n",
    "import tokenizers\n",
    "import transformers \n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "#out code \n",
    "from kfold_loop import KFoldLoop\n",
    "from USPPM_model import USPPPM_model\n",
    "from USPPM_dataset import set_tokenizer, set_max_len\n",
    "from USPPM_kfold_datamodule import USPPPM_kf_datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afdc09-2e7d-412d-9cbf-39e104819dad",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5fc28-1a0b-4c86-9da6-e156d4e88d13",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Class: notebook-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca2dbb5-92b6-4d04-b479-223aaeb390d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # General\n",
    "    seed = 42\n",
    "    \n",
    "    # Debug \n",
    "    debug = False\n",
    "    debug_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ccc5e-ced9-4c6b-ba6c-29e7ed9ffbac",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Dictionary: trial-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9985db04-ae1c-492c-9cca-eeac1b209381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a search space!\n",
    "config_dict = {\n",
    "    \"target_size\" : 1,\n",
    "    \"num_workers\" : 16,\n",
    "    \n",
    "    # Training parameters\n",
    "    \"batch_size\" : 32,\n",
    "    \"epochs\" : 2,\n",
    "    \"n_fold\" : 2,\n",
    "    \"warmup_steps\" : 0,\n",
    "    \"min_lr\" : 1e-6,\n",
    "    \"encoder_lr\" : 2e-5,\n",
    "    \"decoder_lr\" : 2e-5,\n",
    "    \"eps\" : 1e-6,\n",
    "    \"betas\" : (0.9, 0.999),\n",
    "    \"weight_decay\" : 0.01,\n",
    "    \"fc_dropout\" : 0.2,\n",
    "    \"seed\" : 42,\n",
    "\n",
    "    # Transformers\n",
    "    # \"model\" : tune.choice([\"microsoft/deberta-v3-large\"]),\n",
    "     \"model\" : tune.choice([\"distilbert-base-uncased\"]),\n",
    "    #\"model\" : tune.grid_search([\"AI-Growth-Lab/PatentSBERTa\",\"distilbert-base-uncased\",\"ahotrod/electra_large_discriminator_squad2_512\",\"Yanhao/simcse-bert-for-patent\",\"microsoft/deberta-v3-large\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd0738-9bbe-4d25-8510-aaf5a7110750",
   "metadata": {
    "id": "iIVnbwmdnr7K"
   },
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5da60d-3f9b-4ea6-9254-dc40d402afce",
   "metadata": {
    "id": "JaQ5oUkRnr7N"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../dataset/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38b47b-7a99-4942-b910-c0e7cac5cebf",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8398a15a-644b-4e83-8d46-543e37ed59d8",
   "metadata": {
    "id": "T-mYdoUjnr7R"
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"USPPPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384aa55c-0f30-4569-9300-3c2a3430727b",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00781e09-61ab-49ea-a16e-212fb8683047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeDb5W-Wnr7U",
    "outputId": "9efeb745-33a8-42c9-a578-3de670bc7cb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f8751-79fe-492a-a1c8-eb35867f3909",
   "metadata": {
    "id": "IeqIEukjnr7W"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca74519-9ccd-48be-ba61-67466fceea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id     anchor                  target context  \\\n",
       "0           0  37d61fd2272659b1  abatement  abatement of pollution     A47   \n",
       "1           1  7b9652b17b68b7a4  abatement          act of abating     A47   \n",
       "2           2  36d72442aefd8232  abatement         active catalyst     A47   \n",
       "3           3  5296b0c19e1ce60e  abatement     eliminating process     A47   \n",
       "4           4  54c1e3b9184cb5b6  abatement           forest region     A47   \n",
       "\n",
       "   score                                       context_text  \\\n",
       "0   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "1   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "2   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "3   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "4   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "\n",
       "                                                text  score_map  \n",
       "0  abatement[SEP]abatement of pollution[SEP]HUMAN...          2  \n",
       "1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...          3  \n",
       "2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...          1  \n",
       "3  abatement[SEP]eliminating process[SEP]HUMAN NE...          2  \n",
       "4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc_texts = torch.load('cpc_texts.pth')\n",
    "dataframe = pd.read_csv(\"dataframe.csv\")\n",
    "display(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17be84-7e8e-4cc8-99a5-5b5835d9984c",
   "metadata": {},
   "source": [
    "## Debug Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8036555-0930-4a1e-a4e6-fb088d201ced",
   "metadata": {
    "id": "6zeWhBTmvC2N"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    dataframe = dataframe.iloc[:CFG.debug_samples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc687c3-b2d5-4ad1-b872-bc08c0edea4e",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09f8730b-3f39-46bb-ad8d-28521a3aa08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9900</td>\n",
       "      <td>0dbb44b9a145edec</td>\n",
       "      <td>distributor pipe</td>\n",
       "      <td>pipe</td>\n",
       "      <td>B01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...</td>\n",
       "      <td>distributor pipe[SEP]pipe[SEP]PERFORMING OPERA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1303</td>\n",
       "      <td>74afca34a5439c23</td>\n",
       "      <td>ammonia recovery</td>\n",
       "      <td>recovery of water</td>\n",
       "      <td>C01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HEMISTRY; METALLURGY. INORGANIC CHEMISTRY</td>\n",
       "      <td>ammonia recovery[SEP]recovery of water[SEP]HEM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16591</th>\n",
       "      <td>16591</td>\n",
       "      <td>6371befc3ee1b0f2</td>\n",
       "      <td>inner closed</td>\n",
       "      <td>cylindrical inner member</td>\n",
       "      <td>E04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>FIXED CONSTRUCTIONS. BUILDING</td>\n",
       "      <td>inner closed[SEP]cylindrical inner member[SEP]...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25822</th>\n",
       "      <td>25822</td>\n",
       "      <td>20489196c73bd86b</td>\n",
       "      <td>produce thin layers</td>\n",
       "      <td>produce layers</td>\n",
       "      <td>G01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PHYSICS. MEASURING; TESTING</td>\n",
       "      <td>produce thin layers[SEP]produce layers[SEP]PHY...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23640</th>\n",
       "      <td>23640</td>\n",
       "      <td>9af994b21c892022</td>\n",
       "      <td>parallel orientation</td>\n",
       "      <td>zero angle</td>\n",
       "      <td>G06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>PHYSICS. COMPUTING; CALCULATING; COUNTING</td>\n",
       "      <td>parallel orientation[SEP]zero angle[SEP]PHYSIC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                id                anchor  \\\n",
       "9900         9900  0dbb44b9a145edec      distributor pipe   \n",
       "1303         1303  74afca34a5439c23      ammonia recovery   \n",
       "16591       16591  6371befc3ee1b0f2          inner closed   \n",
       "25822       25822  20489196c73bd86b   produce thin layers   \n",
       "23640       23640  9af994b21c892022  parallel orientation   \n",
       "\n",
       "                         target context  score  \\\n",
       "9900                       pipe     B01   0.50   \n",
       "1303          recovery of water     C01   0.25   \n",
       "16591  cylindrical inner member     E04   0.50   \n",
       "25822            produce layers     G01   0.50   \n",
       "23640                zero angle     G06   0.25   \n",
       "\n",
       "                                            context_text  \\\n",
       "9900   PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...   \n",
       "1303           HEMISTRY; METALLURGY. INORGANIC CHEMISTRY   \n",
       "16591                      FIXED CONSTRUCTIONS. BUILDING   \n",
       "25822                        PHYSICS. MEASURING; TESTING   \n",
       "23640          PHYSICS. COMPUTING; CALCULATING; COUNTING   \n",
       "\n",
       "                                                    text  score_map  \n",
       "9900   distributor pipe[SEP]pipe[SEP]PERFORMING OPERA...          2  \n",
       "1303   ammonia recovery[SEP]recovery of water[SEP]HEM...          1  \n",
       "16591  inner closed[SEP]cylindrical inner member[SEP]...          2  \n",
       "25822  produce thin layers[SEP]produce layers[SEP]PHY...          2  \n",
       "23640  parallel orientation[SEP]zero angle[SEP]PHYSIC...          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33511</th>\n",
       "      <td>33511</td>\n",
       "      <td>ed1c4e525eb105fe</td>\n",
       "      <td>transmit alarm</td>\n",
       "      <td>display indicator</td>\n",
       "      <td>G08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PHYSICS. SIGNALLING</td>\n",
       "      <td>transmit alarm[SEP]display indicator[SEP]PHYSI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18670</th>\n",
       "      <td>18670</td>\n",
       "      <td>5386316f318f5221</td>\n",
       "      <td>locking formation</td>\n",
       "      <td>retaining element</td>\n",
       "      <td>B60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n",
       "      <td>locking formation[SEP]retaining element[SEP]PE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>1544ca6753fcbddd</td>\n",
       "      <td>lateral power</td>\n",
       "      <td>transducer</td>\n",
       "      <td>H01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ELECTRICITY. BASIC ELECTRIC ELEMENTS</td>\n",
       "      <td>lateral power[SEP]transducer[SEP]ELECTRICITY. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>31660</td>\n",
       "      <td>f9d8979b94cec923</td>\n",
       "      <td>spreader body</td>\n",
       "      <td>spreader</td>\n",
       "      <td>A01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>HUMAN NECESSITIES. GRICULTURE; FORESTRY; ANIMA...</td>\n",
       "      <td>spreader body[SEP]spreader[SEP]HUMAN NECESSITI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15573</th>\n",
       "      <td>15573</td>\n",
       "      <td>e151ca5ea5cc0f08</td>\n",
       "      <td>high gradient magnetic separators</td>\n",
       "      <td>magnetic filtration</td>\n",
       "      <td>B03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. SEPARATIO...</td>\n",
       "      <td>high gradient magnetic separators[SEP]magnetic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                id                             anchor  \\\n",
       "33511       33511  ed1c4e525eb105fe                     transmit alarm   \n",
       "18670       18670  5386316f318f5221                  locking formation   \n",
       "18049       18049  1544ca6753fcbddd                      lateral power   \n",
       "31660       31660  f9d8979b94cec923                      spreader body   \n",
       "15573       15573  e151ca5ea5cc0f08  high gradient magnetic separators   \n",
       "\n",
       "                    target context  score  \\\n",
       "33511    display indicator     G08   0.00   \n",
       "18670    retaining element     B60   0.25   \n",
       "18049           transducer     H01   0.25   \n",
       "31660             spreader     A01   0.75   \n",
       "15573  magnetic filtration     B03   0.50   \n",
       "\n",
       "                                            context_text  \\\n",
       "33511                                PHYSICS. SIGNALLING   \n",
       "18670  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...   \n",
       "18049               ELECTRICITY. BASIC ELECTRIC ELEMENTS   \n",
       "31660  HUMAN NECESSITIES. GRICULTURE; FORESTRY; ANIMA...   \n",
       "15573  PERFORMING OPERATIONS; TRANSPORTING. SEPARATIO...   \n",
       "\n",
       "                                                    text  score_map  \n",
       "33511  transmit alarm[SEP]display indicator[SEP]PHYSI...          0  \n",
       "18670  locking formation[SEP]retaining element[SEP]PE...          1  \n",
       "18049  lateral power[SEP]transducer[SEP]ELECTRICITY. ...          1  \n",
       "31660  spreader body[SEP]spreader[SEP]HUMAN NECESSITI...          3  \n",
       "15573  high gradient magnetic separators[SEP]magnetic...          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed, stratify = dataframe.score_map)\n",
    "train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563fc01-1170-43cf-ac1b-f577730cf1a6",
   "metadata": {
    "id": "fK6gpNx1nr7q"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b10ba-6205-419f-844f-0fe5b9dc07d0",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990e45de-3f45-42f3-b6d9-37e5bfad651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 23:50:39,886\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '131.114.50.210', 'raylet_ip_address': '131.114.50.210', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-13_23-50-37_974448_3348272/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-13_23-50-37_974448_3348272/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-13_23-50-37_974448_3348272', 'metrics_export_port': 52059, 'gcs_address': '131.114.50.210:49063', 'address': '131.114.50.210:49063', 'dashboard_agent_listen_port': 52365, 'node_id': 'd2f1d2a03c8b3edb5a637641b1f18637f8548ebe3977cbbe5c6c9beb'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f7ea00-b260-41fd-a636-159e38b66fa8",
   "metadata": {
    "id": "fAEhe31znr7q"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "metrics = {\"val_score\": \"val_score\", \"train_loss\" : \"train_loss\", \"val_loss\" : \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143d9932-bb80-433c-b534-9464d9729443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config_dict):  # Pass a \"config\" dictionary into your trainable.\n",
    "\n",
    "    steps_per_epoch = len(train_df) // config_dict['batch_size']\n",
    "    config_dict['training_steps'] = steps_per_epoch * config_dict['epochs']\n",
    "    \n",
    "    set_tokenizer(config_dict, OUTPUT_DIR)\n",
    "    set_max_len(config_dict, cpc_texts, dataframe)\n",
    "    # train_dataset = USPPM_dataset(config_dict)\n",
    "    datamodule = USPPPM_kf_datamodule(config_dict, dataframe)\n",
    "    \n",
    "    model = USPPPM_model(config_dict)\n",
    "    \n",
    "    callbacks = [TuneReportCallback(metrics, on=\"validation_end\"), checkpoint_callback, early_stopping_callback, TQDMProgressBar(refresh_rate=2)]\n",
    "    trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            check_val_every_n_epoch=1,\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=config_dict['epochs'],\n",
    "            #devices=[1],\n",
    "            accelerator=\"gpu\",\n",
    "        \n",
    "            )\n",
    "    \n",
    "    internal_fit_loop = trainer.fit_loop\n",
    "    trainer.fit_loop = KFoldLoop(config_dict['n_fold'], config_dict, export_path=\"./\")\n",
    "    trainer.fit_loop.connect(internal_fit_loop)\n",
    "    \n",
    "    trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb538c9-a170-402e-9f9e-9065038755e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-14 00:01:10 (running for 00:10:27.74)<br>Memory usage on this node: 109.5/503.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/80 CPUs, 0/4 GPUs, 0.0/269.17 GiB heap, 0.0/119.35 GiB objects (0.0/1.0 accelerator_type:P100)<br>Current best trial: 9a289_00000 with val_score=0.6134706616697575 and parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 32, 'epochs': 2, 'n_fold': 2, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'distilbert-base-uncased', 'training_steps': 2050, 'tokenizer': PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), 'max_len': 125}<br>Result logdir: /storagenfs/m.petix/ray_results/tune_uspppm<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                   </th><th>model               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_score</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_9a289_00000</td><td>TERMINATED</td><td>131.114.50.210:3350669</td><td>distilbert-base_3300</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         567.619</td><td style=\"text-align: right;\">   0.613471</td><td style=\"text-align: right;\">    0.576764</td><td style=\"text-align: right;\">  0.600198</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resource_group = tune.PlacementGroupFactory([{\"CPU\": 1, \"GPU\": 1}])\n",
    "\n",
    "tuner = tune.Tuner(tune.with_resources(trainable, \n",
    "                                       {\"cpu\":0.25,\"gpu\":1}),\n",
    "                                       param_space = config_dict,\n",
    "                                       tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\",max_concurrent_trials=4),\n",
    "                                       # tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\"),\n",
    "                                       run_config = air.RunConfig(name=\"tune_uspppm\", verbose=2, progress_reporter=tune.JupyterNotebookReporter(overwrite=True))\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c31a8c09-0fc2-4c9d-955c-cd00f881d558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 23:50:42,385\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "100%|██████████| 136/136 [00:00<00:00, 5165.35it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1582/36473 [00:00<00:02, 15813.00it/s]\n",
      "  9%|▉         | 3193/36473 [00:00<00:02, 15987.06it/s]\n",
      " 13%|█▎        | 4792/36473 [00:00<00:02, 15499.01it/s]\n",
      " 17%|█▋        | 6344/36473 [00:00<00:01, 15362.43it/s]\n",
      " 22%|██▏       | 7882/36473 [00:00<00:01, 15017.26it/s]\n",
      " 26%|██▌       | 9386/36473 [00:00<00:01, 14982.74it/s]\n",
      " 30%|██▉       | 10934/36473 [00:00<00:01, 15138.06it/s]\n",
      " 34%|███▍      | 12471/36473 [00:00<00:01, 15210.70it/s]\n",
      " 39%|███▊      | 14104/36473 [00:00<00:01, 15554.69it/s]\n",
      " 43%|████▎     | 15730/36473 [00:01<00:01, 15768.86it/s]\n",
      " 47%|████▋     | 17308/36473 [00:01<00:01, 15693.19it/s]\n",
      " 52%|█████▏    | 18898/36473 [00:01<00:01, 15752.27it/s]\n",
      " 60%|██████    | 22029/36473 [00:01<00:00, 15471.08it/s]\n",
      " 65%|██████▍   | 23577/36473 [00:01<00:00, 15454.13it/s]\n",
      " 69%|██████▉   | 25123/36473 [00:01<00:00, 15318.05it/s]\n",
      " 73%|███████▎  | 26656/36473 [00:01<00:00, 15316.26it/s]\n",
      " 77%|███████▋  | 28234/36473 [00:01<00:00, 15451.97it/s]\n",
      " 82%|████████▏ | 29868/36473 [00:01<00:00, 15715.85it/s]\n",
      " 86%|████████▋ | 31494/36473 [00:02<00:00, 15875.93it/s]\n",
      " 91%|█████████ | 33091/36473 [00:02<00:00, 15902.17it/s]\n",
      " 99%|█████████▉| 36271/36473 [00:02<00:00, 15722.19it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15548.38it/s]\n",
      "  4%|▍         | 1534/36473 [00:00<00:02, 15328.17it/s]\n",
      "  8%|▊         | 3067/36473 [00:00<00:02, 15061.27it/s]\n",
      " 13%|█▎        | 4623/36473 [00:00<00:02, 15286.19it/s]\n",
      " 17%|█▋        | 6153/36473 [00:00<00:01, 15280.54it/s]\n",
      " 21%|██        | 7703/36473 [00:00<00:01, 15356.18it/s]\n",
      " 25%|██▌       | 9292/36473 [00:00<00:01, 15536.09it/s]\n",
      " 30%|██▉       | 10846/36473 [00:00<00:01, 15514.96it/s]\n",
      " 38%|███▊      | 13970/36473 [00:00<00:01, 15570.29it/s]\n",
      " 43%|████▎     | 15528/36473 [00:01<00:01, 15332.40it/s]\n",
      " 47%|████▋     | 17063/36473 [00:01<00:01, 15129.43it/s]\n",
      " 51%|█████     | 18577/36473 [00:01<00:01, 15013.60it/s]\n",
      " 55%|█████▌    | 20114/36473 [00:01<00:01, 15118.20it/s]\n",
      " 59%|█████▉    | 21627/36473 [00:01<00:00, 15110.69it/s]\n",
      " 63%|██████▎   | 23150/36473 [00:01<00:00, 15146.00it/s]\n",
      " 68%|██████▊   | 24694/36473 [00:01<00:00, 15232.42it/s]\n",
      " 72%|███████▏  | 26266/36473 [00:01<00:00, 15376.46it/s]\n",
      " 76%|███████▋  | 27832/36473 [00:01<00:00, 15460.78it/s]\n",
      " 81%|████████  | 29388/36473 [00:01<00:00, 15489.39it/s]\n",
      " 85%|████████▍ | 30938/36473 [00:02<00:00, 15326.77it/s]\n",
      " 89%|████████▉ | 32472/36473 [00:02<00:00, 15223.51it/s]\n",
      " 93%|█████████▎| 33995/36473 [00:02<00:00, 15109.47it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15272.36it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m - This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m - This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Missing logger folder: lightning_logs/USPPPM\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /storagenfs/m.petix/hlt_usppm/src/checkpoints exists and is not empty.\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m STARTING FOLD 1\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m TRAIN FOLD 1 16412\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m VALID FOLD 1 16413\n",
      "Epoch 0:   0%|          | 0/1026 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m   | Name       | Type              | Params\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m -------------------------------------------------\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 0 | model      | DistilBertModel   | 66.4 M\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 1 | criterion  | BCEWithLogitsLoss | 0     \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 2 | fc_dropout | Dropout           | 0     \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 3 | fc         | Linear            | 769   \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 4 | attention  | Sequential        | 394 K \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m -------------------------------------------------\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 66.8 M    Trainable params\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 66.8 M    Total params\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m 267.032   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 2/1026 [00:01<12:08,  1.40it/s, loss=0.686, v_num=0, train_loss=0.695]\n",
      "Epoch 0:   0%|          | 4/1026 [00:01<07:44,  2.20it/s, loss=0.671, v_num=0, train_loss=0.669]\n",
      "Epoch 0:   1%|          | 6/1026 [00:02<06:14,  2.73it/s, loss=0.663, v_num=0, train_loss=0.633]\n",
      "Epoch 0:   1%|          | 8/1026 [00:02<05:28,  3.10it/s, loss=0.665, v_num=0, train_loss=0.631]\n",
      "Epoch 0:   1%|          | 10/1026 [00:02<05:02,  3.36it/s, loss=0.66, v_num=0, train_loss=0.632] \n",
      "Epoch 0:   1%|          | 12/1026 [00:03<04:43,  3.58it/s, loss=0.662, v_num=0, train_loss=0.691]\n",
      "Epoch 0:   1%|▏         | 14/1026 [00:03<04:30,  3.74it/s, loss=0.659, v_num=0, train_loss=0.648]\n",
      "Epoch 0:   2%|▏         | 16/1026 [00:04<04:19,  3.89it/s, loss=0.659, v_num=0, train_loss=0.657]\n",
      "Epoch 0:   2%|▏         | 18/1026 [00:04<04:10,  4.02it/s, loss=0.662, v_num=0, train_loss=0.679]\n",
      "Epoch 0:   2%|▏         | 20/1026 [00:04<04:04,  4.11it/s, loss=0.665, v_num=0, train_loss=0.673]\n",
      "Epoch 0:   2%|▏         | 22/1026 [00:05<03:58,  4.21it/s, loss=0.662, v_num=0, train_loss=0.657]\n",
      "Epoch 0:   2%|▏         | 24/1026 [00:05<03:53,  4.28it/s, loss=0.663, v_num=0, train_loss=0.666]\n",
      "Epoch 0:   3%|▎         | 26/1026 [00:05<03:49,  4.35it/s, loss=0.664, v_num=0, train_loss=0.646]\n",
      "Epoch 0:   3%|▎         | 28/1026 [00:06<03:46,  4.41it/s, loss=0.664, v_num=0, train_loss=0.682]\n",
      "Epoch 0:   3%|▎         | 30/1026 [00:06<03:43,  4.45it/s, loss=0.664, v_num=0, train_loss=0.640]\n",
      "Epoch 0:   3%|▎         | 32/1026 [00:07<03:40,  4.50it/s, loss=0.661, v_num=0, train_loss=0.625]\n",
      "Epoch 0:   3%|▎         | 34/1026 [00:07<03:38,  4.55it/s, loss=0.661, v_num=0, train_loss=0.652]\n",
      "Epoch 0:   4%|▎         | 36/1026 [00:07<03:36,  4.58it/s, loss=0.658, v_num=0, train_loss=0.607]\n",
      "Epoch 0:   4%|▎         | 38/1026 [00:08<03:33,  4.62it/s, loss=0.658, v_num=0, train_loss=0.699]\n",
      "Epoch 0:   4%|▍         | 40/1026 [00:08<03:31,  4.65it/s, loss=0.656, v_num=0, train_loss=0.695]\n",
      "Epoch 0:   4%|▍         | 42/1026 [00:08<03:30,  4.68it/s, loss=0.657, v_num=0, train_loss=0.671]\n",
      "Epoch 0:   4%|▍         | 44/1026 [00:09<03:28,  4.71it/s, loss=0.656, v_num=0, train_loss=0.644]\n",
      "Epoch 0:   4%|▍         | 46/1026 [00:09<03:27,  4.73it/s, loss=0.659, v_num=0, train_loss=0.641]\n",
      "Epoch 0:   5%|▍         | 48/1026 [00:10<03:25,  4.75it/s, loss=0.657, v_num=0, train_loss=0.662]\n",
      "Epoch 0:   5%|▍         | 50/1026 [00:10<03:24,  4.77it/s, loss=0.657, v_num=0, train_loss=0.639]\n",
      "Epoch 0:   5%|▌         | 52/1026 [00:10<03:25,  4.73it/s, loss=0.659, v_num=0, train_loss=0.666]\n",
      "Epoch 0:   5%|▌         | 54/1026 [00:11<03:24,  4.75it/s, loss=0.661, v_num=0, train_loss=0.657]\n",
      "Epoch 0:   5%|▌         | 56/1026 [00:11<03:23,  4.77it/s, loss=0.662, v_num=0, train_loss=0.632]\n",
      "Epoch 0:   6%|▌         | 58/1026 [00:12<03:21,  4.79it/s, loss=0.66, v_num=0, train_loss=0.653] \n",
      "Epoch 0:   6%|▌         | 60/1026 [00:12<03:20,  4.81it/s, loss=0.654, v_num=0, train_loss=0.611]\n",
      "Epoch 0:   6%|▌         | 62/1026 [00:12<03:19,  4.82it/s, loss=0.651, v_num=0, train_loss=0.650]\n",
      "Epoch 0:   6%|▌         | 64/1026 [00:13<03:18,  4.84it/s, loss=0.651, v_num=0, train_loss=0.660]\n",
      "Epoch 0:   6%|▋         | 66/1026 [00:13<03:17,  4.85it/s, loss=0.653, v_num=0, train_loss=0.686]\n",
      "Epoch 0:   7%|▋         | 68/1026 [00:13<03:16,  4.86it/s, loss=0.653, v_num=0, train_loss=0.672]\n",
      "Epoch 0:   7%|▋         | 70/1026 [00:14<03:16,  4.88it/s, loss=0.655, v_num=0, train_loss=0.677]\n",
      "Epoch 0:   7%|▋         | 72/1026 [00:14<03:15,  4.89it/s, loss=0.652, v_num=0, train_loss=0.642]\n",
      "Epoch 0:   7%|▋         | 74/1026 [00:15<03:14,  4.90it/s, loss=0.651, v_num=0, train_loss=0.656]\n",
      "Epoch 0:   7%|▋         | 76/1026 [00:15<03:13,  4.91it/s, loss=0.652, v_num=0, train_loss=0.637]\n",
      "Epoch 0:   8%|▊         | 78/1026 [00:15<03:12,  4.92it/s, loss=0.653, v_num=0, train_loss=0.666]\n",
      "Epoch 0:   8%|▊         | 80/1026 [00:16<03:11,  4.93it/s, loss=0.657, v_num=0, train_loss=0.661]\n",
      "Epoch 0:   8%|▊         | 82/1026 [00:16<03:11,  4.94it/s, loss=0.659, v_num=0, train_loss=0.684]\n",
      "Epoch 0:   8%|▊         | 84/1026 [00:16<03:10,  4.95it/s, loss=0.657, v_num=0, train_loss=0.624]\n",
      "Epoch 0:   8%|▊         | 86/1026 [00:17<03:09,  4.96it/s, loss=0.651, v_num=0, train_loss=0.677]\n",
      "Epoch 0:   9%|▊         | 88/1026 [00:17<03:08,  4.97it/s, loss=0.648, v_num=0, train_loss=0.619]\n",
      "Epoch 0:   9%|▉         | 90/1026 [00:18<03:08,  4.97it/s, loss=0.645, v_num=0, train_loss=0.641]\n",
      "Epoch 0:   9%|▉         | 92/1026 [00:18<03:07,  4.98it/s, loss=0.642, v_num=0, train_loss=0.595]\n",
      "Epoch 0:   9%|▉         | 94/1026 [00:18<03:07,  4.98it/s, loss=0.641, v_num=0, train_loss=0.654]\n",
      "Epoch 0:   9%|▉         | 96/1026 [00:19<03:06,  4.98it/s, loss=0.639, v_num=0, train_loss=0.604]\n",
      "Epoch 0:  10%|▉         | 98/1026 [00:19<03:06,  4.99it/s, loss=0.637, v_num=0, train_loss=0.651]\n",
      "Epoch 0:  10%|▉         | 100/1026 [00:20<03:05,  4.99it/s, loss=0.635, v_num=0, train_loss=0.621]\n",
      "Epoch 0:  10%|▉         | 102/1026 [00:20<03:05,  4.99it/s, loss=0.636, v_num=0, train_loss=0.664]\n",
      "Epoch 0:  10%|█         | 104/1026 [00:20<03:04,  5.00it/s, loss=0.636, v_num=0, train_loss=0.654]\n",
      "Epoch 0:  10%|█         | 106/1026 [00:21<03:03,  5.00it/s, loss=0.636, v_num=0, train_loss=0.657]\n",
      "Epoch 0:  11%|█         | 108/1026 [00:21<03:03,  5.01it/s, loss=0.636, v_num=0, train_loss=0.620]\n",
      "Epoch 0:  11%|█         | 110/1026 [00:21<03:02,  5.01it/s, loss=0.635, v_num=0, train_loss=0.624]\n",
      "Epoch 0:  11%|█         | 112/1026 [00:22<03:02,  5.01it/s, loss=0.636, v_num=0, train_loss=0.572]\n",
      "Epoch 0:  11%|█         | 114/1026 [00:22<03:01,  5.01it/s, loss=0.636, v_num=0, train_loss=0.627]\n",
      "Epoch 0:  11%|█▏        | 116/1026 [00:23<03:01,  5.01it/s, loss=0.636, v_num=0, train_loss=0.598]\n",
      "Epoch 0:  12%|█▏        | 118/1026 [00:23<03:00,  5.02it/s, loss=0.632, v_num=0, train_loss=0.582]\n",
      "Epoch 0:  12%|█▏        | 120/1026 [00:23<03:00,  5.02it/s, loss=0.635, v_num=0, train_loss=0.652]\n",
      "Epoch 0:  12%|█▏        | 122/1026 [00:24<02:59,  5.03it/s, loss=0.626, v_num=0, train_loss=0.597]\n",
      "Epoch 0:  12%|█▏        | 124/1026 [00:24<02:59,  5.03it/s, loss=0.624, v_num=0, train_loss=0.657]\n",
      "Epoch 0:  12%|█▏        | 126/1026 [00:25<02:58,  5.03it/s, loss=0.621, v_num=0, train_loss=0.587]\n",
      "Epoch 0:  12%|█▏        | 128/1026 [00:25<02:58,  5.03it/s, loss=0.62, v_num=0, train_loss=0.592] \n",
      "Epoch 0:  13%|█▎        | 130/1026 [00:25<02:57,  5.03it/s, loss=0.619, v_num=0, train_loss=0.642]\n",
      "Epoch 0:  13%|█▎        | 132/1026 [00:26<02:57,  5.04it/s, loss=0.619, v_num=0, train_loss=0.573]\n",
      "Epoch 0:  13%|█▎        | 134/1026 [00:26<02:57,  5.04it/s, loss=0.616, v_num=0, train_loss=0.643]\n",
      "Epoch 0:  13%|█▎        | 136/1026 [00:26<02:56,  5.04it/s, loss=0.616, v_num=0, train_loss=0.592]\n",
      "Epoch 0:  13%|█▎        | 138/1026 [00:27<02:55,  5.05it/s, loss=0.616, v_num=0, train_loss=0.622]\n",
      "Epoch 0:  14%|█▎        | 140/1026 [00:27<02:55,  5.05it/s, loss=0.613, v_num=0, train_loss=0.603]\n",
      "Epoch 0:  14%|█▍        | 142/1026 [00:28<02:55,  5.05it/s, loss=0.616, v_num=0, train_loss=0.655]\n",
      "Epoch 0:  14%|█▍        | 144/1026 [00:28<02:54,  5.05it/s, loss=0.615, v_num=0, train_loss=0.605]\n",
      "Epoch 0:  14%|█▍        | 146/1026 [00:28<02:54,  5.05it/s, loss=0.615, v_num=0, train_loss=0.616]\n",
      "Epoch 0:  14%|█▍        | 148/1026 [00:29<02:53,  5.05it/s, loss=0.618, v_num=0, train_loss=0.633]\n",
      "Epoch 0:  15%|█▍        | 150/1026 [00:29<02:53,  5.06it/s, loss=0.617, v_num=0, train_loss=0.588]\n",
      "Epoch 0:  15%|█▍        | 152/1026 [00:30<02:52,  5.06it/s, loss=0.615, v_num=0, train_loss=0.592]\n",
      "Epoch 0:  15%|█▌        | 154/1026 [00:30<02:52,  5.06it/s, loss=0.621, v_num=0, train_loss=0.642]\n",
      "Epoch 0:  15%|█▌        | 156/1026 [00:30<02:51,  5.06it/s, loss=0.618, v_num=0, train_loss=0.602]\n",
      "Epoch 0:  15%|█▌        | 158/1026 [00:31<02:51,  5.06it/s, loss=0.614, v_num=0, train_loss=0.540]\n",
      "Epoch 0:  16%|█▌        | 160/1026 [00:31<02:51,  5.06it/s, loss=0.612, v_num=0, train_loss=0.629]\n",
      "Epoch 0:  16%|█▌        | 162/1026 [00:31<02:50,  5.06it/s, loss=0.607, v_num=0, train_loss=0.562]\n",
      "Epoch 0:  16%|█▌        | 164/1026 [00:32<02:50,  5.07it/s, loss=0.606, v_num=0, train_loss=0.607]\n",
      "Epoch 0:  16%|█▌        | 166/1026 [00:32<02:49,  5.07it/s, loss=0.606, v_num=0, train_loss=0.567]\n",
      "Epoch 0:  16%|█▋        | 168/1026 [00:33<02:49,  5.07it/s, loss=0.608, v_num=0, train_loss=0.622]\n",
      "Epoch 0:  17%|█▋        | 170/1026 [00:33<02:48,  5.07it/s, loss=0.606, v_num=0, train_loss=0.586]\n",
      "Epoch 0:  17%|█▋        | 172/1026 [00:33<02:48,  5.07it/s, loss=0.609, v_num=0, train_loss=0.612]\n",
      "Epoch 0:  17%|█▋        | 174/1026 [00:34<02:47,  5.08it/s, loss=0.604, v_num=0, train_loss=0.584]\n",
      "Epoch 0:  17%|█▋        | 176/1026 [00:34<02:47,  5.07it/s, loss=0.604, v_num=0, train_loss=0.605]\n",
      "Epoch 0:  17%|█▋        | 178/1026 [00:35<02:47,  5.08it/s, loss=0.605, v_num=0, train_loss=0.575]\n",
      "Epoch 0:  18%|█▊        | 180/1026 [00:35<02:46,  5.08it/s, loss=0.605, v_num=0, train_loss=0.631]\n",
      "Epoch 0:  18%|█▊        | 182/1026 [00:35<02:46,  5.08it/s, loss=0.612, v_num=0, train_loss=0.640]\n",
      "Epoch 0:  18%|█▊        | 184/1026 [00:36<02:45,  5.08it/s, loss=0.616, v_num=0, train_loss=0.668]\n",
      "Epoch 0:  18%|█▊        | 186/1026 [00:36<02:45,  5.08it/s, loss=0.612, v_num=0, train_loss=0.552]\n",
      "Epoch 0:  18%|█▊        | 188/1026 [00:36<02:44,  5.08it/s, loss=0.607, v_num=0, train_loss=0.611]\n",
      "Epoch 0:  19%|█▊        | 190/1026 [00:37<02:44,  5.08it/s, loss=0.609, v_num=0, train_loss=0.701]\n",
      "Epoch 0:  19%|█▊        | 192/1026 [00:37<02:44,  5.08it/s, loss=0.611, v_num=0, train_loss=0.626]\n",
      "Epoch 0:  19%|█▉        | 194/1026 [00:38<02:43,  5.08it/s, loss=0.61, v_num=0, train_loss=0.612] \n",
      "Epoch 0:  19%|█▉        | 196/1026 [00:38<02:43,  5.09it/s, loss=0.616, v_num=0, train_loss=0.615]\n",
      "Epoch 0:  19%|█▉        | 198/1026 [00:38<02:42,  5.09it/s, loss=0.621, v_num=0, train_loss=0.626]\n",
      "Epoch 0:  19%|█▉        | 200/1026 [00:39<02:42,  5.09it/s, loss=0.619, v_num=0, train_loss=0.572]\n",
      "Epoch 0:  20%|█▉        | 202/1026 [00:39<02:41,  5.09it/s, loss=0.618, v_num=0, train_loss=0.616]\n",
      "Epoch 0:  20%|█▉        | 204/1026 [00:40<02:41,  5.09it/s, loss=0.613, v_num=0, train_loss=0.597]\n",
      "Epoch 0:  20%|██        | 206/1026 [00:40<02:41,  5.09it/s, loss=0.62, v_num=0, train_loss=0.664] \n",
      "Epoch 0:  20%|██        | 208/1026 [00:40<02:40,  5.09it/s, loss=0.621, v_num=0, train_loss=0.610]\n",
      "Epoch 0:  20%|██        | 210/1026 [00:41<02:40,  5.09it/s, loss=0.623, v_num=0, train_loss=0.641]\n",
      "Epoch 0:  21%|██        | 212/1026 [00:41<02:39,  5.09it/s, loss=0.622, v_num=0, train_loss=0.634]\n",
      "Epoch 0:  21%|██        | 214/1026 [00:42<02:39,  5.09it/s, loss=0.623, v_num=0, train_loss=0.630]\n",
      "Epoch 0:  21%|██        | 216/1026 [00:42<02:38,  5.10it/s, loss=0.618, v_num=0, train_loss=0.605]\n",
      "Epoch 0:  21%|██        | 218/1026 [00:42<02:38,  5.10it/s, loss=0.616, v_num=0, train_loss=0.646]\n",
      "Epoch 0:  21%|██▏       | 220/1026 [00:43<02:38,  5.10it/s, loss=0.618, v_num=0, train_loss=0.606]\n",
      "Epoch 0:  22%|██▏       | 222/1026 [00:43<02:37,  5.10it/s, loss=0.616, v_num=0, train_loss=0.556]\n",
      "Epoch 0:  22%|██▏       | 224/1026 [00:43<02:37,  5.10it/s, loss=0.617, v_num=0, train_loss=0.578]\n",
      "Epoch 0:  22%|██▏       | 226/1026 [00:44<02:36,  5.10it/s, loss=0.613, v_num=0, train_loss=0.574]\n",
      "Epoch 0:  22%|██▏       | 228/1026 [00:44<02:36,  5.10it/s, loss=0.615, v_num=0, train_loss=0.645]\n",
      "Epoch 0:  22%|██▏       | 230/1026 [00:45<02:36,  5.10it/s, loss=0.614, v_num=0, train_loss=0.585]\n",
      "Epoch 0:  23%|██▎       | 232/1026 [00:45<02:35,  5.10it/s, loss=0.611, v_num=0, train_loss=0.634]\n",
      "Epoch 0:  23%|██▎       | 234/1026 [00:45<02:35,  5.10it/s, loss=0.609, v_num=0, train_loss=0.531]\n",
      "Epoch 0:  23%|██▎       | 236/1026 [00:46<02:34,  5.11it/s, loss=0.611, v_num=0, train_loss=0.648]\n",
      "Epoch 0:  23%|██▎       | 238/1026 [00:46<02:34,  5.11it/s, loss=0.605, v_num=0, train_loss=0.573]\n",
      "Epoch 0:  23%|██▎       | 240/1026 [00:47<02:33,  5.11it/s, loss=0.601, v_num=0, train_loss=0.585]\n",
      "Epoch 0:  24%|██▎       | 242/1026 [00:47<02:33,  5.11it/s, loss=0.607, v_num=0, train_loss=0.614]\n",
      "Epoch 0:  24%|██▍       | 244/1026 [00:47<02:33,  5.11it/s, loss=0.605, v_num=0, train_loss=0.578]\n",
      "Epoch 0:  24%|██▍       | 246/1026 [00:48<02:32,  5.11it/s, loss=0.605, v_num=0, train_loss=0.619]\n",
      "Epoch 0:  24%|██▍       | 248/1026 [00:48<02:32,  5.11it/s, loss=0.608, v_num=0, train_loss=0.628]\n",
      "Epoch 0:  24%|██▍       | 250/1026 [00:48<02:31,  5.11it/s, loss=0.603, v_num=0, train_loss=0.529]\n",
      "Epoch 0:  25%|██▍       | 252/1026 [00:49<02:31,  5.11it/s, loss=0.604, v_num=0, train_loss=0.612]\n",
      "Epoch 0:  25%|██▍       | 254/1026 [00:49<02:31,  5.11it/s, loss=0.605, v_num=0, train_loss=0.627]\n",
      "Epoch 0:  25%|██▍       | 256/1026 [00:50<02:30,  5.11it/s, loss=0.604, v_num=0, train_loss=0.606]\n",
      "Epoch 0:  25%|██▌       | 258/1026 [00:50<02:30,  5.11it/s, loss=0.609, v_num=0, train_loss=0.642]\n",
      "Epoch 0:  25%|██▌       | 260/1026 [00:50<02:29,  5.11it/s, loss=0.613, v_num=0, train_loss=0.639]\n",
      "Epoch 0:  26%|██▌       | 262/1026 [00:51<02:29,  5.11it/s, loss=0.607, v_num=0, train_loss=0.588]\n",
      "Epoch 0:  26%|██▌       | 264/1026 [00:51<02:28,  5.11it/s, loss=0.612, v_num=0, train_loss=0.672]\n",
      "Epoch 0:  26%|██▌       | 266/1026 [00:51<02:28,  5.12it/s, loss=0.608, v_num=0, train_loss=0.606]\n",
      "Epoch 0:  26%|██▌       | 268/1026 [00:52<02:28,  5.12it/s, loss=0.602, v_num=0, train_loss=0.551]\n",
      "Epoch 0:  26%|██▋       | 270/1026 [00:52<02:27,  5.12it/s, loss=0.603, v_num=0, train_loss=0.515]\n",
      "Epoch 0:  27%|██▋       | 272/1026 [00:53<02:27,  5.12it/s, loss=0.602, v_num=0, train_loss=0.586]\n",
      "Epoch 0:  27%|██▋       | 274/1026 [00:53<02:26,  5.12it/s, loss=0.603, v_num=0, train_loss=0.635]\n",
      "Epoch 0:  27%|██▋       | 276/1026 [00:53<02:26,  5.12it/s, loss=0.605, v_num=0, train_loss=0.637]\n",
      "Epoch 0:  27%|██▋       | 278/1026 [00:54<02:26,  5.12it/s, loss=0.601, v_num=0, train_loss=0.546]\n",
      "Epoch 0:  27%|██▋       | 280/1026 [00:54<02:25,  5.12it/s, loss=0.601, v_num=0, train_loss=0.585]\n",
      "Epoch 0:  27%|██▋       | 282/1026 [00:55<02:25,  5.12it/s, loss=0.603, v_num=0, train_loss=0.622]\n",
      "Epoch 0:  28%|██▊       | 284/1026 [00:55<02:24,  5.12it/s, loss=0.599, v_num=0, train_loss=0.578]\n",
      "Epoch 0:  28%|██▊       | 286/1026 [00:55<02:24,  5.12it/s, loss=0.6, v_num=0, train_loss=0.616]  \n",
      "Epoch 0:  28%|██▊       | 288/1026 [00:56<02:24,  5.12it/s, loss=0.6, v_num=0, train_loss=0.619]\n",
      "Epoch 0:  28%|██▊       | 290/1026 [00:56<02:23,  5.12it/s, loss=0.603, v_num=0, train_loss=0.583]\n",
      "Epoch 0:  28%|██▊       | 292/1026 [00:57<02:23,  5.12it/s, loss=0.604, v_num=0, train_loss=0.578]\n",
      "Epoch 0:  29%|██▊       | 294/1026 [00:57<02:22,  5.12it/s, loss=0.602, v_num=0, train_loss=0.617]\n",
      "Epoch 0:  29%|██▉       | 296/1026 [00:57<02:22,  5.12it/s, loss=0.597, v_num=0, train_loss=0.564]\n",
      "Epoch 0:  29%|██▉       | 298/1026 [00:58<02:22,  5.12it/s, loss=0.601, v_num=0, train_loss=0.584]\n",
      "Epoch 0:  29%|██▉       | 300/1026 [00:58<02:21,  5.13it/s, loss=0.597, v_num=0, train_loss=0.577]\n",
      "Epoch 0:  29%|██▉       | 302/1026 [00:58<02:21,  5.13it/s, loss=0.602, v_num=0, train_loss=0.672]\n",
      "Epoch 0:  30%|██▉       | 304/1026 [00:59<02:20,  5.13it/s, loss=0.602, v_num=0, train_loss=0.552]\n",
      "Epoch 0:  30%|██▉       | 306/1026 [00:59<02:20,  5.13it/s, loss=0.606, v_num=0, train_loss=0.595]\n",
      "Epoch 0:  30%|███       | 308/1026 [01:00<02:20,  5.13it/s, loss=0.606, v_num=0, train_loss=0.591]\n",
      "Epoch 0:  30%|███       | 310/1026 [01:00<02:19,  5.13it/s, loss=0.604, v_num=0, train_loss=0.589]\n",
      "Epoch 0:  30%|███       | 312/1026 [01:00<02:19,  5.13it/s, loss=0.605, v_num=0, train_loss=0.599]\n",
      "Epoch 0:  31%|███       | 314/1026 [01:01<02:18,  5.13it/s, loss=0.603, v_num=0, train_loss=0.576]\n",
      "Epoch 0:  31%|███       | 316/1026 [01:01<02:18,  5.13it/s, loss=0.603, v_num=0, train_loss=0.571]\n",
      "Epoch 0:  31%|███       | 318/1026 [01:01<02:17,  5.13it/s, loss=0.602, v_num=0, train_loss=0.514]\n",
      "Epoch 0:  31%|███       | 320/1026 [01:02<02:17,  5.13it/s, loss=0.601, v_num=0, train_loss=0.607]\n",
      "Epoch 0:  31%|███▏      | 322/1026 [01:02<02:17,  5.13it/s, loss=0.596, v_num=0, train_loss=0.563]\n",
      "Epoch 0:  32%|███▏      | 324/1026 [01:03<02:16,  5.13it/s, loss=0.596, v_num=0, train_loss=0.576]\n",
      "Epoch 0:  32%|███▏      | 326/1026 [01:03<02:16,  5.13it/s, loss=0.591, v_num=0, train_loss=0.557]\n",
      "Epoch 0:  32%|███▏      | 328/1026 [01:03<02:16,  5.13it/s, loss=0.593, v_num=0, train_loss=0.608]\n",
      "Epoch 0:  32%|███▏      | 330/1026 [01:04<02:15,  5.13it/s, loss=0.592, v_num=0, train_loss=0.597]\n",
      "Epoch 0:  32%|███▏      | 332/1026 [01:04<02:15,  5.13it/s, loss=0.589, v_num=0, train_loss=0.574]\n",
      "Epoch 0:  33%|███▎      | 334/1026 [01:05<02:14,  5.13it/s, loss=0.591, v_num=0, train_loss=0.656]\n",
      "Epoch 0:  33%|███▎      | 336/1026 [01:05<02:14,  5.13it/s, loss=0.593, v_num=0, train_loss=0.615]\n",
      "Epoch 0:  33%|███▎      | 338/1026 [01:05<02:14,  5.13it/s, loss=0.595, v_num=0, train_loss=0.604]\n",
      "Epoch 0:  33%|███▎      | 340/1026 [01:06<02:13,  5.13it/s, loss=0.596, v_num=0, train_loss=0.593]\n",
      "Epoch 0:  33%|███▎      | 342/1026 [01:06<02:13,  5.13it/s, loss=0.596, v_num=0, train_loss=0.631]\n",
      "Epoch 0:  34%|███▎      | 344/1026 [01:06<02:12,  5.14it/s, loss=0.601, v_num=0, train_loss=0.581]\n",
      "Epoch 0:  34%|███▎      | 346/1026 [01:07<02:12,  5.14it/s, loss=0.604, v_num=0, train_loss=0.572]\n",
      "Epoch 0:  34%|███▍      | 348/1026 [01:07<02:12,  5.14it/s, loss=0.603, v_num=0, train_loss=0.619]\n",
      "Epoch 0:  34%|███▍      | 350/1026 [01:08<02:11,  5.14it/s, loss=0.611, v_num=0, train_loss=0.638]\n",
      "Epoch 0:  34%|███▍      | 352/1026 [01:08<02:11,  5.14it/s, loss=0.614, v_num=0, train_loss=0.608]\n",
      "Epoch 0:  35%|███▍      | 354/1026 [01:08<02:10,  5.14it/s, loss=0.613, v_num=0, train_loss=0.574]\n",
      "Epoch 0:  35%|███▍      | 356/1026 [01:09<02:10,  5.14it/s, loss=0.608, v_num=0, train_loss=0.557]\n",
      "Epoch 0:  35%|███▍      | 358/1026 [01:09<02:10,  5.14it/s, loss=0.608, v_num=0, train_loss=0.520]\n",
      "Epoch 0:  35%|███▌      | 360/1026 [01:10<02:09,  5.14it/s, loss=0.612, v_num=0, train_loss=0.649]\n",
      "Epoch 0:  35%|███▌      | 362/1026 [01:10<02:09,  5.14it/s, loss=0.612, v_num=0, train_loss=0.596]\n",
      "Epoch 0:  35%|███▌      | 364/1026 [01:10<02:08,  5.14it/s, loss=0.606, v_num=0, train_loss=0.589]\n",
      "Epoch 0:  36%|███▌      | 366/1026 [01:11<02:08,  5.14it/s, loss=0.602, v_num=0, train_loss=0.570]\n",
      "Epoch 0:  36%|███▌      | 368/1026 [01:11<02:08,  5.14it/s, loss=0.596, v_num=0, train_loss=0.608]\n",
      "Epoch 0:  36%|███▌      | 370/1026 [01:11<02:07,  5.14it/s, loss=0.592, v_num=0, train_loss=0.633]\n",
      "Epoch 0:  36%|███▋      | 372/1026 [01:12<02:07,  5.14it/s, loss=0.59, v_num=0, train_loss=0.541] \n",
      "Epoch 0:  36%|███▋      | 374/1026 [01:12<02:06,  5.14it/s, loss=0.588, v_num=0, train_loss=0.550]\n",
      "Epoch 0:  37%|███▋      | 376/1026 [01:13<02:06,  5.14it/s, loss=0.59, v_num=0, train_loss=0.558] \n",
      "Epoch 0:  37%|███▋      | 378/1026 [01:13<02:06,  5.14it/s, loss=0.593, v_num=0, train_loss=0.638]\n",
      "Epoch 0:  37%|███▋      | 380/1026 [01:13<02:05,  5.14it/s, loss=0.591, v_num=0, train_loss=0.638]\n",
      "Epoch 0:  37%|███▋      | 382/1026 [01:14<02:05,  5.14it/s, loss=0.594, v_num=0, train_loss=0.633]\n",
      "Epoch 0:  37%|███▋      | 384/1026 [01:14<02:04,  5.14it/s, loss=0.59, v_num=0, train_loss=0.553] \n",
      "Epoch 0:  38%|███▊      | 386/1026 [01:15<02:04,  5.14it/s, loss=0.593, v_num=0, train_loss=0.575]\n",
      "Epoch 0:  38%|███▊      | 388/1026 [01:15<02:04,  5.14it/s, loss=0.598, v_num=0, train_loss=0.643]\n",
      "Epoch 0:  38%|███▊      | 390/1026 [01:15<02:03,  5.14it/s, loss=0.597, v_num=0, train_loss=0.603]\n",
      "Epoch 0:  38%|███▊      | 392/1026 [01:16<02:03,  5.14it/s, loss=0.6, v_num=0, train_loss=0.621]  \n",
      "Epoch 0:  38%|███▊      | 394/1026 [01:16<02:02,  5.14it/s, loss=0.602, v_num=0, train_loss=0.589]\n",
      "Epoch 0:  39%|███▊      | 396/1026 [01:16<02:02,  5.14it/s, loss=0.598, v_num=0, train_loss=0.490]\n",
      "Epoch 0:  39%|███▉      | 398/1026 [01:17<02:02,  5.14it/s, loss=0.597, v_num=0, train_loss=0.602]\n",
      "Epoch 0:  39%|███▉      | 400/1026 [01:17<02:01,  5.15it/s, loss=0.594, v_num=0, train_loss=0.618]\n",
      "Epoch 0:  39%|███▉      | 402/1026 [01:18<02:01,  5.15it/s, loss=0.596, v_num=0, train_loss=0.692]\n",
      "Epoch 0:  39%|███▉      | 404/1026 [01:18<02:00,  5.14it/s, loss=0.599, v_num=0, train_loss=0.573]\n",
      "Epoch 0:  40%|███▉      | 406/1026 [01:18<02:00,  5.14it/s, loss=0.599, v_num=0, train_loss=0.559]\n",
      "Epoch 0:  40%|███▉      | 408/1026 [01:19<02:00,  5.15it/s, loss=0.597, v_num=0, train_loss=0.610]\n",
      "Epoch 0:  40%|███▉      | 410/1026 [01:19<01:59,  5.15it/s, loss=0.596, v_num=0, train_loss=0.584]\n",
      "Epoch 0:  40%|████      | 412/1026 [01:20<01:59,  5.15it/s, loss=0.593, v_num=0, train_loss=0.636]\n",
      "Epoch 0:  40%|████      | 414/1026 [01:20<01:58,  5.15it/s, loss=0.588, v_num=0, train_loss=0.541]\n",
      "Epoch 0:  41%|████      | 416/1026 [01:20<01:58,  5.15it/s, loss=0.593, v_num=0, train_loss=0.595]\n",
      "Epoch 0:  41%|████      | 418/1026 [01:21<01:58,  5.15it/s, loss=0.583, v_num=0, train_loss=0.527]\n",
      "Epoch 0:  41%|████      | 420/1026 [01:21<01:57,  5.15it/s, loss=0.584, v_num=0, train_loss=0.689]\n",
      "Epoch 0:  41%|████      | 422/1026 [01:21<01:57,  5.15it/s, loss=0.58, v_num=0, train_loss=0.549] \n",
      "Epoch 0:  41%|████▏     | 424/1026 [01:22<01:56,  5.15it/s, loss=0.581, v_num=0, train_loss=0.595]\n",
      "Epoch 0:  42%|████▏     | 426/1026 [01:22<01:56,  5.15it/s, loss=0.583, v_num=0, train_loss=0.602]\n",
      "Epoch 0:  42%|████▏     | 428/1026 [01:23<01:56,  5.15it/s, loss=0.582, v_num=0, train_loss=0.578]\n",
      "Epoch 0:  42%|████▏     | 430/1026 [01:23<01:55,  5.15it/s, loss=0.585, v_num=0, train_loss=0.601]\n",
      "Epoch 0:  42%|████▏     | 432/1026 [01:23<01:55,  5.15it/s, loss=0.583, v_num=0, train_loss=0.552]\n",
      "Epoch 0:  42%|████▏     | 434/1026 [01:24<01:54,  5.15it/s, loss=0.584, v_num=0, train_loss=0.557]\n",
      "Epoch 0:  42%|████▏     | 436/1026 [01:24<01:54,  5.15it/s, loss=0.589, v_num=0, train_loss=0.651]\n",
      "Epoch 0:  43%|████▎     | 438/1026 [01:25<01:54,  5.15it/s, loss=0.597, v_num=0, train_loss=0.614]\n",
      "Epoch 0:  43%|████▎     | 440/1026 [01:25<01:53,  5.15it/s, loss=0.598, v_num=0, train_loss=0.582]\n",
      "Epoch 0:  43%|████▎     | 442/1026 [01:25<01:53,  5.15it/s, loss=0.594, v_num=0, train_loss=0.559]\n",
      "Epoch 0:  43%|████▎     | 444/1026 [01:26<01:53,  5.15it/s, loss=0.591, v_num=0, train_loss=0.560]\n",
      "Epoch 0:  43%|████▎     | 446/1026 [01:26<01:52,  5.15it/s, loss=0.59, v_num=0, train_loss=0.584] \n",
      "Epoch 0:  44%|████▎     | 448/1026 [01:26<01:52,  5.15it/s, loss=0.591, v_num=0, train_loss=0.634]\n",
      "Epoch 0:  44%|████▍     | 450/1026 [01:27<01:51,  5.15it/s, loss=0.587, v_num=0, train_loss=0.500]\n",
      "Epoch 0:  44%|████▍     | 452/1026 [01:27<01:51,  5.15it/s, loss=0.593, v_num=0, train_loss=0.580]\n",
      "Epoch 0:  44%|████▍     | 454/1026 [01:28<01:51,  5.15it/s, loss=0.597, v_num=0, train_loss=0.604]\n",
      "Epoch 0:  44%|████▍     | 456/1026 [01:28<01:50,  5.15it/s, loss=0.589, v_num=0, train_loss=0.509]\n",
      "Epoch 0:  45%|████▍     | 458/1026 [01:28<01:50,  5.15it/s, loss=0.586, v_num=0, train_loss=0.540]\n",
      "Epoch 0:  45%|████▍     | 460/1026 [01:29<01:49,  5.15it/s, loss=0.587, v_num=0, train_loss=0.609]\n",
      "Epoch 0:  45%|████▌     | 462/1026 [01:29<01:49,  5.15it/s, loss=0.599, v_num=0, train_loss=0.654]\n",
      "Epoch 0:  45%|████▌     | 464/1026 [01:30<01:49,  5.15it/s, loss=0.606, v_num=0, train_loss=0.570]\n",
      "Epoch 0:  45%|████▌     | 466/1026 [01:30<01:48,  5.15it/s, loss=0.605, v_num=0, train_loss=0.612]\n",
      "Epoch 0:  46%|████▌     | 468/1026 [01:30<01:48,  5.15it/s, loss=0.605, v_num=0, train_loss=0.625]\n",
      "Epoch 0:  46%|████▌     | 470/1026 [01:31<01:47,  5.15it/s, loss=0.606, v_num=0, train_loss=0.553]\n",
      "Epoch 0:  46%|████▌     | 472/1026 [01:31<01:47,  5.15it/s, loss=0.607, v_num=0, train_loss=0.628]\n",
      "Epoch 0:  46%|████▌     | 474/1026 [01:32<01:47,  5.15it/s, loss=0.61, v_num=0, train_loss=0.573] \n",
      "Epoch 0:  46%|████▋     | 476/1026 [01:32<01:46,  5.15it/s, loss=0.612, v_num=0, train_loss=0.587]\n",
      "Epoch 0:  47%|████▋     | 478/1026 [01:32<01:46,  5.15it/s, loss=0.615, v_num=0, train_loss=0.614]\n",
      "Epoch 0:  47%|████▋     | 480/1026 [01:33<01:45,  5.15it/s, loss=0.614, v_num=0, train_loss=0.569]\n",
      "Epoch 0:  47%|████▋     | 482/1026 [01:33<01:45,  5.15it/s, loss=0.599, v_num=0, train_loss=0.528]\n",
      "Epoch 0:  47%|████▋     | 484/1026 [01:33<01:45,  5.15it/s, loss=0.596, v_num=0, train_loss=0.593]\n",
      "Epoch 0:  47%|████▋     | 486/1026 [01:34<01:44,  5.15it/s, loss=0.595, v_num=0, train_loss=0.597]\n",
      "Epoch 0:  48%|████▊     | 488/1026 [01:34<01:44,  5.15it/s, loss=0.591, v_num=0, train_loss=0.584]\n",
      "Epoch 0:  48%|████▊     | 490/1026 [01:35<01:44,  5.15it/s, loss=0.589, v_num=0, train_loss=0.542]\n",
      "Epoch 0:  48%|████▊     | 492/1026 [01:35<01:43,  5.15it/s, loss=0.582, v_num=0, train_loss=0.511]\n",
      "Epoch 0:  48%|████▊     | 494/1026 [01:35<01:43,  5.15it/s, loss=0.581, v_num=0, train_loss=0.623]\n",
      "Epoch 0:  48%|████▊     | 496/1026 [01:36<01:42,  5.16it/s, loss=0.582, v_num=0, train_loss=0.582]\n",
      "Epoch 0:  49%|████▊     | 498/1026 [01:36<01:42,  5.16it/s, loss=0.588, v_num=0, train_loss=0.664]\n",
      "Epoch 0:  49%|████▊     | 500/1026 [01:37<01:42,  5.15it/s, loss=0.587, v_num=0, train_loss=0.574]\n",
      "Epoch 0:  49%|████▉     | 502/1026 [01:37<01:41,  5.15it/s, loss=0.591, v_num=0, train_loss=0.544]\n",
      "Epoch 0:  49%|████▉     | 504/1026 [01:37<01:41,  5.16it/s, loss=0.591, v_num=0, train_loss=0.605]\n",
      "Epoch 0:  49%|████▉     | 506/1026 [01:38<01:40,  5.16it/s, loss=0.59, v_num=0, train_loss=0.558] \n",
      "Epoch 0:  50%|████▉     | 508/1026 [01:38<01:40,  5.16it/s, loss=0.596, v_num=0, train_loss=0.625]\n",
      "Epoch 0:  50%|████▉     | 510/1026 [01:38<01:40,  5.16it/s, loss=0.602, v_num=0, train_loss=0.614]\n",
      "Epoch 0:  50%|████▉     | 512/1026 [01:39<01:39,  5.16it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[0m \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation:   0%|          | 0/513 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/513 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 514/1026 [01:40<01:39,  5.13it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  50%|█████     | 516/1026 [01:40<01:39,  5.14it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  50%|█████     | 518/1026 [01:40<01:38,  5.15it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  51%|█████     | 520/1026 [01:40<01:37,  5.17it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   2%|▏         | 8/513 [00:00<00:26, 19.12it/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 522/1026 [01:40<01:37,  5.18it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   2%|▏         | 10/513 [00:00<00:26, 18.68it/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 524/1026 [01:40<01:36,  5.20it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   2%|▏         | 12/513 [00:00<00:27, 18.39it/s]\u001b[A\n",
      "Epoch 0:  51%|█████▏    | 526/1026 [01:40<01:35,  5.21it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   3%|▎         | 14/513 [00:00<00:27, 18.20it/s]\u001b[A\n",
      "Epoch 0:  51%|█████▏    | 528/1026 [01:41<01:35,  5.22it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   3%|▎         | 16/513 [00:00<00:27, 18.04it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 530/1026 [01:41<01:34,  5.24it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   4%|▎         | 18/513 [00:01<00:27, 17.93it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 532/1026 [01:41<01:34,  5.25it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   4%|▍         | 20/513 [00:01<00:27, 17.83it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 534/1026 [01:41<01:33,  5.26it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   4%|▍         | 22/513 [00:01<00:27, 17.77it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 536/1026 [01:41<01:32,  5.28it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   5%|▍         | 24/513 [00:01<00:27, 17.71it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 538/1026 [01:41<01:32,  5.29it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   5%|▌         | 26/513 [00:01<00:27, 17.66it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 540/1026 [01:41<01:31,  5.30it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   5%|▌         | 28/513 [00:01<00:27, 17.62it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 542/1026 [01:41<01:31,  5.32it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   6%|▌         | 30/513 [00:01<00:27, 17.58it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 544/1026 [01:42<01:30,  5.33it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   6%|▌         | 32/513 [00:01<00:27, 17.55it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 546/1026 [01:42<01:29,  5.34it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   7%|▋         | 34/513 [00:01<00:27, 17.52it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 548/1026 [01:42<01:29,  5.36it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   7%|▋         | 36/513 [00:02<00:27, 17.49it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▎    | 550/1026 [01:42<01:28,  5.37it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   7%|▋         | 38/513 [00:02<00:27, 17.46it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 552/1026 [01:42<01:28,  5.39it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   8%|▊         | 40/513 [00:02<00:27, 17.45it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 554/1026 [01:42<01:27,  5.40it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   8%|▊         | 42/513 [00:02<00:27, 17.43it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 556/1026 [01:42<01:26,  5.41it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   9%|▊         | 44/513 [00:02<00:26, 17.41it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 558/1026 [01:42<01:26,  5.43it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:   9%|▉         | 46/513 [00:02<00:26, 17.40it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 560/1026 [01:42<01:25,  5.44it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   9%|▉         | 48/513 [00:02<00:26, 17.39it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 562/1026 [01:43<01:25,  5.45it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  10%|▉         | 50/513 [00:02<00:26, 17.38it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 564/1026 [01:43<01:24,  5.46it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  10%|█         | 52/513 [00:02<00:26, 17.36it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▌    | 566/1026 [01:43<01:23,  5.48it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  11%|█         | 54/513 [00:03<00:26, 17.35it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▌    | 568/1026 [01:43<01:23,  5.49it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  11%|█         | 56/513 [00:03<00:26, 17.34it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 570/1026 [01:43<01:22,  5.50it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  11%|█▏        | 58/513 [00:03<00:26, 17.33it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 572/1026 [01:43<01:22,  5.52it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  12%|█▏        | 60/513 [00:03<00:26, 17.32it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 574/1026 [01:43<01:21,  5.53it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  12%|█▏        | 62/513 [00:03<00:26, 17.32it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 576/1026 [01:43<01:21,  5.54it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  12%|█▏        | 64/513 [00:03<00:25, 17.31it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▋    | 578/1026 [01:44<01:20,  5.56it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  13%|█▎        | 66/513 [00:03<00:25, 17.30it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 580/1026 [01:44<01:20,  5.57it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  13%|█▎        | 68/513 [00:03<00:25, 17.30it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 582/1026 [01:44<01:19,  5.58it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  14%|█▎        | 70/513 [00:04<00:25, 17.29it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 584/1026 [01:44<01:18,  5.60it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  14%|█▍        | 72/513 [00:04<00:25, 17.28it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 586/1026 [01:44<01:18,  5.61it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  14%|█▍        | 74/513 [00:04<00:25, 17.27it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 588/1026 [01:44<01:17,  5.62it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  15%|█▍        | 76/513 [00:04<00:25, 17.27it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 590/1026 [01:44<01:17,  5.63it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  15%|█▌        | 78/513 [00:04<00:25, 17.26it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 592/1026 [01:44<01:16,  5.65it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  16%|█▌        | 80/513 [00:04<00:25, 17.26it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 594/1026 [01:44<01:16,  5.66it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  16%|█▌        | 82/513 [00:04<00:24, 17.26it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 596/1026 [01:45<01:15,  5.67it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  16%|█▋        | 84/513 [00:04<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 598/1026 [01:45<01:15,  5.68it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  17%|█▋        | 86/513 [00:04<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 600/1026 [01:45<01:14,  5.70it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  17%|█▋        | 88/513 [00:05<00:24, 17.24it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▊    | 602/1026 [01:45<01:14,  5.71it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  18%|█▊        | 90/513 [00:05<00:24, 17.24it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 604/1026 [01:45<01:13,  5.72it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  18%|█▊        | 92/513 [00:05<00:24, 17.24it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 606/1026 [01:45<01:13,  5.74it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  18%|█▊        | 94/513 [00:05<00:24, 17.23it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 608/1026 [01:45<01:12,  5.75it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  19%|█▊        | 96/513 [00:05<00:24, 17.23it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 610/1026 [01:45<01:12,  5.76it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  19%|█▉        | 98/513 [00:05<00:24, 17.23it/s]\u001b[A\n",
      "Epoch 0:  60%|█████▉    | 612/1026 [01:46<01:11,  5.77it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  19%|█▉        | 100/513 [00:05<00:23, 17.22it/s]\u001b[A\n",
      "Epoch 0:  60%|█████▉    | 614/1026 [01:46<01:11,  5.79it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  20%|█▉        | 102/513 [00:05<00:23, 17.22it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 616/1026 [01:46<01:10,  5.80it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  20%|██        | 104/513 [00:06<00:23, 17.22it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 618/1026 [01:46<01:10,  5.81it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  21%|██        | 106/513 [00:06<00:23, 17.21it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 620/1026 [01:46<01:09,  5.82it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██        | 108/513 [00:06<00:23, 17.21it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 622/1026 [01:46<01:09,  5.83it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██▏       | 110/513 [00:06<00:23, 17.21it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 624/1026 [01:46<01:08,  5.85it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  22%|██▏       | 112/513 [00:06<00:23, 17.21it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 626/1026 [01:46<01:08,  5.86it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  22%|██▏       | 114/513 [00:06<00:23, 17.20it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 628/1026 [01:46<01:07,  5.87it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 116/513 [00:06<00:23, 17.20it/s]\u001b[A\n",
      "Epoch 0:  61%|██████▏   | 630/1026 [01:47<01:07,  5.88it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  23%|██▎       | 118/513 [00:06<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 632/1026 [01:47<01:06,  5.90it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 120/513 [00:06<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 634/1026 [01:47<01:06,  5.91it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  24%|██▍       | 122/513 [00:07<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 636/1026 [01:47<01:05,  5.92it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  24%|██▍       | 124/513 [00:07<00:22, 17.19it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 638/1026 [01:47<01:05,  5.93it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▍       | 126/513 [00:07<00:22, 17.19it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 640/1026 [01:47<01:04,  5.94it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  25%|██▍       | 128/513 [00:07<00:22, 17.19it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 642/1026 [01:47<01:04,  5.96it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▌       | 130/513 [00:07<00:22, 17.19it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 644/1026 [01:47<01:03,  5.97it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  26%|██▌       | 132/513 [00:07<00:22, 17.19it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 646/1026 [01:48<01:03,  5.98it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  26%|██▌       | 134/513 [00:07<00:22, 17.19it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 648/1026 [01:48<01:03,  5.99it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 136/513 [00:07<00:21, 17.18it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 650/1026 [01:48<01:02,  6.00it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  27%|██▋       | 138/513 [00:08<00:21, 17.18it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▎   | 652/1026 [01:48<01:02,  6.02it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 140/513 [00:08<00:21, 17.18it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▎   | 654/1026 [01:48<01:01,  6.03it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  28%|██▊       | 142/513 [00:08<00:21, 17.18it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 656/1026 [01:48<01:01,  6.04it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  28%|██▊       | 144/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 658/1026 [01:48<01:00,  6.05it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  28%|██▊       | 146/513 [00:08<00:21, 17.18it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 660/1026 [01:48<01:00,  6.06it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  29%|██▉       | 148/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 662/1026 [01:48<00:59,  6.08it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  29%|██▉       | 150/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 664/1026 [01:49<00:59,  6.09it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  30%|██▉       | 152/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 666/1026 [01:49<00:59,  6.10it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  30%|███       | 154/513 [00:08<00:20, 17.17it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▌   | 668/1026 [01:49<00:58,  6.11it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  30%|███       | 156/513 [00:09<00:20, 17.17it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▌   | 670/1026 [01:49<00:58,  6.12it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  31%|███       | 158/513 [00:09<00:20, 17.17it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▌   | 672/1026 [01:49<00:57,  6.14it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  31%|███       | 160/513 [00:09<00:20, 17.17it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 674/1026 [01:49<00:57,  6.15it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  32%|███▏      | 162/513 [00:09<00:20, 17.17it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 676/1026 [01:49<00:56,  6.16it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  32%|███▏      | 164/513 [00:09<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 678/1026 [01:49<00:56,  6.17it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  32%|███▏      | 166/513 [00:09<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▋   | 680/1026 [01:50<00:55,  6.18it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  33%|███▎      | 168/513 [00:09<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▋   | 682/1026 [01:50<00:55,  6.19it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  33%|███▎      | 170/513 [00:09<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 684/1026 [01:50<00:55,  6.20it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  34%|███▎      | 172/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 686/1026 [01:50<00:54,  6.22it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  34%|███▍      | 174/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 688/1026 [01:50<00:54,  6.23it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  34%|███▍      | 176/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 690/1026 [01:50<00:53,  6.24it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  35%|███▍      | 178/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 692/1026 [01:50<00:53,  6.25it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  35%|███▌      | 180/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 694/1026 [01:50<00:53,  6.26it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  35%|███▌      | 182/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 696/1026 [01:50<00:52,  6.27it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  36%|███▌      | 184/513 [00:10<00:19, 17.16it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 698/1026 [01:51<00:52,  6.29it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  36%|███▋      | 186/513 [00:10<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 700/1026 [01:51<00:51,  6.30it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 188/513 [00:10<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 702/1026 [01:51<00:51,  6.31it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  37%|███▋      | 190/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▊   | 704/1026 [01:51<00:50,  6.32it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 192/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 706/1026 [01:51<00:50,  6.33it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  38%|███▊      | 194/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 708/1026 [01:51<00:50,  6.34it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  38%|███▊      | 196/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 710/1026 [01:51<00:49,  6.35it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▊      | 198/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 712/1026 [01:51<00:49,  6.36it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▉      | 200/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  70%|██████▉   | 714/1026 [01:51<00:48,  6.38it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▉      | 202/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  70%|██████▉   | 716/1026 [01:52<00:48,  6.39it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  40%|███▉      | 204/513 [00:11<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 0:  70%|██████▉   | 718/1026 [01:52<00:48,  6.40it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  40%|████      | 206/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 720/1026 [01:52<00:47,  6.41it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  41%|████      | 208/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 722/1026 [01:52<00:47,  6.42it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  41%|████      | 210/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 724/1026 [01:52<00:46,  6.43it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  41%|████▏     | 212/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 726/1026 [01:52<00:46,  6.44it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  42%|████▏     | 214/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 728/1026 [01:52<00:46,  6.45it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  42%|████▏     | 216/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 730/1026 [01:52<00:45,  6.46it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  42%|████▏     | 218/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  71%|███████▏  | 732/1026 [01:53<00:45,  6.48it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  43%|████▎     | 220/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 734/1026 [01:53<00:45,  6.49it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  43%|████▎     | 222/513 [00:12<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 736/1026 [01:53<00:44,  6.50it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  44%|████▎     | 224/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 738/1026 [01:53<00:44,  6.51it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  44%|████▍     | 226/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 740/1026 [01:53<00:43,  6.52it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  44%|████▍     | 228/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 742/1026 [01:53<00:43,  6.53it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  45%|████▍     | 230/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 744/1026 [01:53<00:43,  6.54it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  45%|████▌     | 232/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 746/1026 [01:53<00:42,  6.55it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  46%|████▌     | 234/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 748/1026 [01:53<00:42,  6.56it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  46%|████▌     | 236/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 750/1026 [01:54<00:41,  6.57it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  46%|████▋     | 238/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 752/1026 [01:54<00:41,  6.58it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  47%|████▋     | 240/513 [00:14<00:15, 17.14it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 754/1026 [01:54<00:41,  6.59it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  47%|████▋     | 242/513 [00:14<00:15, 17.14it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▎  | 756/1026 [01:54<00:40,  6.61it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 244/513 [00:14<00:15, 17.14it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 758/1026 [01:54<00:40,  6.62it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 246/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 760/1026 [01:54<00:40,  6.63it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  48%|████▊     | 248/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 762/1026 [01:54<00:39,  6.64it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  49%|████▊     | 250/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 764/1026 [01:54<00:39,  6.65it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  49%|████▉     | 252/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▍  | 766/1026 [01:55<00:39,  6.66it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  50%|████▉     | 254/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▍  | 768/1026 [01:55<00:38,  6.67it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  50%|████▉     | 256/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▌  | 770/1026 [01:55<00:38,  6.68it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  50%|█████     | 258/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▌  | 772/1026 [01:55<00:37,  6.69it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  51%|█████     | 260/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▌  | 774/1026 [01:55<00:37,  6.70it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  51%|█████     | 262/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 776/1026 [01:55<00:37,  6.71it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  51%|█████▏    | 264/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 778/1026 [01:55<00:36,  6.72it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  52%|█████▏    | 266/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 780/1026 [01:55<00:36,  6.73it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  52%|█████▏    | 268/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 782/1026 [01:55<00:36,  6.74it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  53%|█████▎    | 270/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▋  | 784/1026 [01:56<00:35,  6.75it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  53%|█████▎    | 272/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 786/1026 [01:56<00:35,  6.76it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  53%|█████▎    | 274/513 [00:15<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 788/1026 [01:56<00:35,  6.77it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  54%|█████▍    | 276/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 790/1026 [01:56<00:34,  6.78it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  54%|█████▍    | 278/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 792/1026 [01:56<00:34,  6.79it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▍    | 280/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 794/1026 [01:56<00:34,  6.81it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  55%|█████▍    | 282/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 796/1026 [01:56<00:33,  6.82it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▌    | 284/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 798/1026 [01:56<00:33,  6.83it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  56%|█████▌    | 286/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 800/1026 [01:57<00:33,  6.84it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  56%|█████▌    | 288/513 [00:16<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 802/1026 [01:57<00:32,  6.85it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 290/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 804/1026 [01:57<00:32,  6.86it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 292/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▊  | 806/1026 [01:57<00:32,  6.87it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  57%|█████▋    | 294/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 808/1026 [01:57<00:31,  6.88it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 296/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 810/1026 [01:57<00:31,  6.89it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  58%|█████▊    | 298/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 812/1026 [01:57<00:31,  6.90it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 300/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 814/1026 [01:57<00:30,  6.91it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  59%|█████▉    | 302/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 816/1026 [01:57<00:30,  6.92it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  59%|█████▉    | 304/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 818/1026 [01:58<00:30,  6.93it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|█████▉    | 306/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 820/1026 [01:58<00:29,  6.94it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|██████    | 308/513 [00:17<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 822/1026 [01:58<00:29,  6.95it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  60%|██████    | 310/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 824/1026 [01:58<00:29,  6.96it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  61%|██████    | 312/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 826/1026 [01:58<00:28,  6.97it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  61%|██████    | 314/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 828/1026 [01:58<00:28,  6.98it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  62%|██████▏   | 316/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 830/1026 [01:58<00:28,  6.99it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  62%|██████▏   | 318/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 832/1026 [01:58<00:27,  7.00it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  62%|██████▏   | 320/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 834/1026 [01:59<00:27,  7.01it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  63%|██████▎   | 322/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 836/1026 [01:59<00:27,  7.02it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  63%|██████▎   | 324/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 838/1026 [01:59<00:26,  7.03it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  64%|██████▎   | 326/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 840/1026 [01:59<00:26,  7.04it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  64%|██████▍   | 328/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 842/1026 [01:59<00:26,  7.05it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  64%|██████▍   | 330/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 844/1026 [01:59<00:25,  7.06it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  65%|██████▍   | 332/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 846/1026 [01:59<00:25,  7.07it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  65%|██████▌   | 334/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 848/1026 [01:59<00:25,  7.08it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  65%|██████▌   | 336/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 850/1026 [01:59<00:24,  7.09it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  66%|██████▌   | 338/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 852/1026 [02:00<00:24,  7.10it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  66%|██████▋   | 340/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 854/1026 [02:00<00:24,  7.11it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  67%|██████▋   | 342/513 [00:19<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 856/1026 [02:00<00:23,  7.12it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 344/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 858/1026 [02:00<00:23,  7.12it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 346/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 860/1026 [02:00<00:23,  7.13it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  68%|██████▊   | 348/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 862/1026 [02:00<00:22,  7.14it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  68%|██████▊   | 350/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 864/1026 [02:00<00:22,  7.15it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▊   | 352/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 866/1026 [02:00<00:22,  7.16it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  69%|██████▉   | 354/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 868/1026 [02:01<00:22,  7.17it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▉   | 356/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 870/1026 [02:01<00:21,  7.18it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  70%|██████▉   | 358/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 872/1026 [02:01<00:21,  7.19it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  70%|███████   | 360/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 874/1026 [02:01<00:21,  7.20it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  71%|███████   | 362/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 876/1026 [02:01<00:20,  7.21it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  71%|███████   | 364/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 878/1026 [02:01<00:20,  7.22it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████▏  | 366/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 880/1026 [02:01<00:20,  7.23it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  72%|███████▏  | 368/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 882/1026 [02:01<00:19,  7.24it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  72%|███████▏  | 370/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 884/1026 [02:01<00:19,  7.25it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  73%|███████▎  | 372/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 886/1026 [02:02<00:19,  7.26it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  73%|███████▎  | 374/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 888/1026 [02:02<00:18,  7.27it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  73%|███████▎  | 376/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 890/1026 [02:02<00:18,  7.28it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▎  | 378/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 892/1026 [02:02<00:18,  7.29it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▍  | 380/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 894/1026 [02:02<00:18,  7.30it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  74%|███████▍  | 382/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 896/1026 [02:02<00:17,  7.31it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  75%|███████▍  | 384/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 898/1026 [02:02<00:17,  7.31it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  75%|███████▌  | 386/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 900/1026 [02:02<00:17,  7.32it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▌  | 388/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 902/1026 [02:03<00:16,  7.33it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▌  | 390/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 904/1026 [02:03<00:16,  7.34it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  76%|███████▋  | 392/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 906/1026 [02:03<00:16,  7.35it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  77%|███████▋  | 394/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 908/1026 [02:03<00:16,  7.36it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  77%|███████▋  | 396/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 910/1026 [02:03<00:15,  7.37it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 398/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 912/1026 [02:03<00:15,  7.38it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 400/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 914/1026 [02:03<00:15,  7.39it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 402/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 916/1026 [02:03<00:14,  7.40it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  79%|███████▉  | 404/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 918/1026 [02:03<00:14,  7.41it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  79%|███████▉  | 406/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 920/1026 [02:04<00:14,  7.42it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  80%|███████▉  | 408/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 922/1026 [02:04<00:14,  7.43it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  80%|███████▉  | 410/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 924/1026 [02:04<00:13,  7.43it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  80%|████████  | 412/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 926/1026 [02:04<00:13,  7.44it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  81%|████████  | 414/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 928/1026 [02:04<00:13,  7.45it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  81%|████████  | 416/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 930/1026 [02:04<00:12,  7.46it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  81%|████████▏ | 418/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 932/1026 [02:04<00:12,  7.47it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  82%|████████▏ | 420/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 934/1026 [02:04<00:12,  7.48it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  82%|████████▏ | 422/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 936/1026 [02:04<00:12,  7.49it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  83%|████████▎ | 424/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 938/1026 [02:05<00:11,  7.50it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  83%|████████▎ | 426/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 940/1026 [02:05<00:11,  7.51it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  83%|████████▎ | 428/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 942/1026 [02:05<00:11,  7.52it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  84%|████████▍ | 430/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 944/1026 [02:05<00:10,  7.52it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  84%|████████▍ | 432/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 946/1026 [02:05<00:10,  7.53it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  85%|████████▍ | 434/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 948/1026 [02:05<00:10,  7.54it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  85%|████████▍ | 436/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 950/1026 [02:05<00:10,  7.55it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  85%|████████▌ | 438/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 952/1026 [02:05<00:09,  7.56it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  86%|████████▌ | 440/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 954/1026 [02:06<00:09,  7.57it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  86%|████████▌ | 442/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 956/1026 [02:06<00:09,  7.58it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 444/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 958/1026 [02:06<00:08,  7.59it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 446/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 960/1026 [02:06<00:08,  7.60it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  87%|████████▋ | 448/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 962/1026 [02:06<00:08,  7.60it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 450/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 964/1026 [02:06<00:08,  7.61it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 452/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 966/1026 [02:06<00:07,  7.62it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 454/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 968/1026 [02:06<00:07,  7.63it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  89%|████████▉ | 456/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 970/1026 [02:06<00:07,  7.64it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  89%|████████▉ | 458/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 972/1026 [02:07<00:07,  7.65it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|████████▉ | 460/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 974/1026 [02:07<00:06,  7.66it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|█████████ | 462/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 976/1026 [02:07<00:06,  7.66it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  90%|█████████ | 464/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 978/1026 [02:07<00:06,  7.67it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  91%|█████████ | 466/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 980/1026 [02:07<00:05,  7.68it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  91%|█████████ | 468/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 982/1026 [02:07<00:05,  7.69it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  92%|█████████▏| 470/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 984/1026 [02:07<00:05,  7.70it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  92%|█████████▏| 472/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 986/1026 [02:07<00:05,  7.71it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  92%|█████████▏| 474/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 988/1026 [02:08<00:04,  7.72it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  93%|█████████▎| 476/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 990/1026 [02:08<00:04,  7.73it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  93%|█████████▎| 478/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 992/1026 [02:08<00:04,  7.73it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  94%|█████████▎| 480/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 994/1026 [02:08<00:04,  7.74it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  94%|█████████▍| 482/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 996/1026 [02:08<00:03,  7.75it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  94%|█████████▍| 484/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 998/1026 [02:08<00:03,  7.76it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  95%|█████████▍| 486/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1000/1026 [02:08<00:03,  7.77it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  95%|█████████▌| 488/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1002/1026 [02:08<00:03,  7.78it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  96%|█████████▌| 490/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1004/1026 [02:08<00:02,  7.78it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▌| 492/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1006/1026 [02:09<00:02,  7.79it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▋| 494/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1008/1026 [02:09<00:02,  7.80it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 496/513 [00:28<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1010/1026 [02:09<00:02,  7.81it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  97%|█████████▋| 498/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 1012/1026 [02:09<00:01,  7.82it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 500/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1014/1026 [02:09<00:01,  7.83it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0:  98%|█████████▊| 502/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1016/1026 [02:09<00:01,  7.83it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  98%|█████████▊| 504/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1018/1026 [02:09<00:01,  7.84it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▊| 506/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1020/1026 [02:09<00:00,  7.85it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▉| 508/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1022/1026 [02:10<00:00,  7.86it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▉| 510/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1024/1026 [02:10<00:00,  7.87it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Validation DataLoader 0: 100%|█████████▉| 512/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0: 100%|██████████| 1026/1026 [02:10<00:00,  7.88it/s, loss=0.603, v_num=0, train_loss=0.604]\n",
      "Trial trainable_9a289_00000 reported val_score=0.70 with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 32, 'epochs': 2, 'n_fold': 2, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'distilbert-base-uncased'}.\n",
      "Epoch 0: 100%|██████████| 1026/1026 [02:10<00:00,  7.87it/s, loss=0.603, v_num=0, train_loss=0.623, val_loss=0.583, val_score=0.699]\n",
      "Epoch 0: 100%|██████████| 1026/1026 [02:10<00:00,  7.87it/s, loss=0.603, v_num=0, train_loss=0.623, val_loss=0.583, val_score=0.699]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Epoch 0, global step 513: 'val_loss' reached 0.58302 (best 0.58302), saving model to '/storagenfs/m.petix/hlt_usppm/src/checkpoints/best_checkpoint-v24.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1026 [00:00<?, ?it/s, loss=0.603, v_num=0, train_loss=0.623, val_loss=0.583, val_score=0.699]           \n",
      "Epoch 1:   0%|          | 2/1026 [00:01<11:26,  1.49it/s, loss=0.603, v_num=0, train_loss=0.623, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   0%|          | 4/1026 [00:01<07:20,  2.32it/s, loss=0.599, v_num=0, train_loss=0.586, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   1%|          | 6/1026 [00:02<05:57,  2.85it/s, loss=0.594, v_num=0, train_loss=0.610, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   1%|          | 8/1026 [00:02<05:16,  3.22it/s, loss=0.596, v_num=0, train_loss=0.571, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   1%|          | 10/1026 [00:02<04:51,  3.48it/s, loss=0.596, v_num=0, train_loss=0.541, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   1%|          | 12/1026 [00:03<04:35,  3.68it/s, loss=0.598, v_num=0, train_loss=0.632, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   1%|▏         | 14/1026 [00:03<04:24,  3.83it/s, loss=0.598, v_num=0, train_loss=0.624, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   2%|▏         | 16/1026 [00:04<04:15,  3.96it/s, loss=0.595, v_num=0, train_loss=0.620, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   2%|▏         | 18/1026 [00:04<04:07,  4.07it/s, loss=0.6, v_num=0, train_loss=0.651, val_loss=0.583, val_score=0.699]  \n",
      "Epoch 1:   2%|▏         | 20/1026 [00:04<04:01,  4.17it/s, loss=0.603, v_num=0, train_loss=0.654, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   2%|▏         | 22/1026 [00:05<03:56,  4.24it/s, loss=0.597, v_num=0, train_loss=0.622, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   2%|▏         | 24/1026 [00:05<03:52,  4.32it/s, loss=0.599, v_num=0, train_loss=0.596, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   3%|▎         | 26/1026 [00:05<03:48,  4.37it/s, loss=0.597, v_num=0, train_loss=0.599, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   3%|▎         | 28/1026 [00:06<03:45,  4.42it/s, loss=0.6, v_num=0, train_loss=0.662, val_loss=0.583, val_score=0.699]  \n",
      "Epoch 1:   3%|▎         | 30/1026 [00:06<03:43,  4.46it/s, loss=0.599, v_num=0, train_loss=0.569, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   3%|▎         | 32/1026 [00:07<03:41,  4.50it/s, loss=0.595, v_num=0, train_loss=0.563, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   3%|▎         | 34/1026 [00:07<03:38,  4.54it/s, loss=0.594, v_num=0, train_loss=0.578, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   4%|▎         | 36/1026 [00:07<03:36,  4.57it/s, loss=0.592, v_num=0, train_loss=0.585, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   4%|▎         | 38/1026 [00:08<03:34,  4.60it/s, loss=0.591, v_num=0, train_loss=0.591, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   4%|▍         | 40/1026 [00:08<03:33,  4.63it/s, loss=0.585, v_num=0, train_loss=0.627, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   4%|▍         | 42/1026 [00:09<03:31,  4.65it/s, loss=0.586, v_num=0, train_loss=0.524, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   4%|▍         | 44/1026 [00:09<03:30,  4.67it/s, loss=0.582, v_num=0, train_loss=0.523, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   4%|▍         | 46/1026 [00:09<03:28,  4.69it/s, loss=0.585, v_num=0, train_loss=0.583, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   5%|▍         | 48/1026 [00:10<03:27,  4.71it/s, loss=0.584, v_num=0, train_loss=0.635, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   5%|▍         | 50/1026 [00:10<03:26,  4.73it/s, loss=0.585, v_num=0, train_loss=0.596, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   5%|▌         | 52/1026 [00:10<03:25,  4.75it/s, loss=0.586, v_num=0, train_loss=0.596, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   5%|▌         | 54/1026 [00:11<03:23,  4.76it/s, loss=0.585, v_num=0, train_loss=0.629, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   5%|▌         | 56/1026 [00:11<03:22,  4.78it/s, loss=0.582, v_num=0, train_loss=0.557, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   6%|▌         | 58/1026 [00:12<03:22,  4.79it/s, loss=0.584, v_num=0, train_loss=0.619, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   6%|▌         | 60/1026 [00:12<03:21,  4.80it/s, loss=0.577, v_num=0, train_loss=0.509, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   6%|▌         | 62/1026 [00:12<03:20,  4.81it/s, loss=0.576, v_num=0, train_loss=0.566, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   6%|▌         | 64/1026 [00:13<03:19,  4.82it/s, loss=0.58, v_num=0, train_loss=0.609, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:   6%|▋         | 66/1026 [00:13<03:18,  4.84it/s, loss=0.583, v_num=0, train_loss=0.677, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   7%|▋         | 68/1026 [00:14<03:17,  4.85it/s, loss=0.581, v_num=0, train_loss=0.643, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   7%|▋         | 70/1026 [00:14<03:16,  4.86it/s, loss=0.583, v_num=0, train_loss=0.584, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   7%|▋         | 72/1026 [00:14<03:15,  4.87it/s, loss=0.579, v_num=0, train_loss=0.587, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   7%|▋         | 74/1026 [00:15<03:15,  4.88it/s, loss=0.579, v_num=0, train_loss=0.562, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   7%|▋         | 76/1026 [00:15<03:14,  4.88it/s, loss=0.581, v_num=0, train_loss=0.578, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   8%|▊         | 78/1026 [00:15<03:13,  4.89it/s, loss=0.578, v_num=0, train_loss=0.612, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   8%|▊         | 80/1026 [00:16<03:13,  4.90it/s, loss=0.582, v_num=0, train_loss=0.560, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   8%|▊         | 82/1026 [00:16<03:12,  4.90it/s, loss=0.587, v_num=0, train_loss=0.638, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   8%|▊         | 84/1026 [00:17<03:11,  4.91it/s, loss=0.59, v_num=0, train_loss=0.641, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:   8%|▊         | 86/1026 [00:17<03:11,  4.92it/s, loss=0.585, v_num=0, train_loss=0.639, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   9%|▊         | 88/1026 [00:17<03:10,  4.93it/s, loss=0.579, v_num=0, train_loss=0.551, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   9%|▉         | 90/1026 [00:18<03:09,  4.93it/s, loss=0.578, v_num=0, train_loss=0.602, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   9%|▉         | 92/1026 [00:18<03:09,  4.94it/s, loss=0.577, v_num=0, train_loss=0.521, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   9%|▉         | 94/1026 [00:19<03:08,  4.94it/s, loss=0.574, v_num=0, train_loss=0.571, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:   9%|▉         | 96/1026 [00:19<03:07,  4.95it/s, loss=0.578, v_num=0, train_loss=0.589, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  10%|▉         | 98/1026 [00:19<03:07,  4.95it/s, loss=0.579, v_num=0, train_loss=0.654, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  10%|▉         | 100/1026 [00:20<03:06,  4.96it/s, loss=0.58, v_num=0, train_loss=0.539, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  10%|▉         | 102/1026 [00:20<03:06,  4.97it/s, loss=0.574, v_num=0, train_loss=0.563, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  10%|█         | 104/1026 [00:20<03:05,  4.97it/s, loss=0.569, v_num=0, train_loss=0.572, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  10%|█         | 106/1026 [00:21<03:04,  4.97it/s, loss=0.571, v_num=0, train_loss=0.657, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  11%|█         | 108/1026 [00:21<03:04,  4.98it/s, loss=0.575, v_num=0, train_loss=0.549, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  11%|█         | 110/1026 [00:22<03:03,  4.98it/s, loss=0.572, v_num=0, train_loss=0.560, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  11%|█         | 112/1026 [00:22<03:03,  4.98it/s, loss=0.571, v_num=0, train_loss=0.472, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  11%|█         | 114/1026 [00:22<03:02,  4.99it/s, loss=0.572, v_num=0, train_loss=0.553, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  11%|█▏        | 116/1026 [00:23<03:02,  4.99it/s, loss=0.568, v_num=0, train_loss=0.555, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  12%|█▏        | 118/1026 [00:23<03:01,  5.00it/s, loss=0.557, v_num=0, train_loss=0.458, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  12%|█▏        | 120/1026 [00:23<03:01,  5.00it/s, loss=0.565, v_num=0, train_loss=0.645, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  12%|█▏        | 122/1026 [00:24<03:00,  5.00it/s, loss=0.562, v_num=0, train_loss=0.528, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  12%|█▏        | 124/1026 [00:24<03:00,  5.01it/s, loss=0.56, v_num=0, train_loss=0.626, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  12%|█▏        | 126/1026 [00:25<02:59,  5.01it/s, loss=0.555, v_num=0, train_loss=0.525, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  12%|█▏        | 128/1026 [00:25<02:59,  5.01it/s, loss=0.552, v_num=0, train_loss=0.517, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  13%|█▎        | 130/1026 [00:25<02:58,  5.01it/s, loss=0.552, v_num=0, train_loss=0.568, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  13%|█▎        | 132/1026 [00:26<02:58,  5.02it/s, loss=0.554, v_num=0, train_loss=0.515, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  13%|█▎        | 134/1026 [00:26<02:57,  5.02it/s, loss=0.553, v_num=0, train_loss=0.578, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  13%|█▎        | 136/1026 [00:27<02:57,  5.02it/s, loss=0.55, v_num=0, train_loss=0.494, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  13%|█▎        | 138/1026 [00:27<02:56,  5.03it/s, loss=0.554, v_num=0, train_loss=0.567, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  14%|█▎        | 140/1026 [00:27<02:56,  5.03it/s, loss=0.545, v_num=0, train_loss=0.532, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  14%|█▍        | 142/1026 [00:28<02:55,  5.03it/s, loss=0.543, v_num=0, train_loss=0.576, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  14%|█▍        | 144/1026 [00:28<02:55,  5.03it/s, loss=0.544, v_num=0, train_loss=0.563, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  14%|█▍        | 146/1026 [00:28<02:54,  5.04it/s, loss=0.545, v_num=0, train_loss=0.545, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  14%|█▍        | 148/1026 [00:29<02:54,  5.04it/s, loss=0.547, v_num=0, train_loss=0.572, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  15%|█▍        | 150/1026 [00:29<02:53,  5.04it/s, loss=0.546, v_num=0, train_loss=0.549, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  15%|█▍        | 152/1026 [00:30<02:53,  5.04it/s, loss=0.549, v_num=0, train_loss=0.555, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  15%|█▌        | 154/1026 [00:30<02:52,  5.05it/s, loss=0.558, v_num=0, train_loss=0.605, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  15%|█▌        | 156/1026 [00:30<02:52,  5.05it/s, loss=0.56, v_num=0, train_loss=0.575, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  15%|█▌        | 158/1026 [00:31<02:51,  5.05it/s, loss=0.558, v_num=0, train_loss=0.514, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  16%|█▌        | 160/1026 [00:31<02:51,  5.05it/s, loss=0.557, v_num=0, train_loss=0.554, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  16%|█▌        | 162/1026 [00:32<02:50,  5.05it/s, loss=0.555, v_num=0, train_loss=0.512, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  16%|█▌        | 164/1026 [00:32<02:50,  5.06it/s, loss=0.556, v_num=0, train_loss=0.558, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  16%|█▌        | 166/1026 [00:32<02:50,  5.06it/s, loss=0.556, v_num=0, train_loss=0.489, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  16%|█▋        | 168/1026 [00:33<02:49,  5.06it/s, loss=0.555, v_num=0, train_loss=0.533, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  17%|█▋        | 170/1026 [00:33<02:49,  5.06it/s, loss=0.555, v_num=0, train_loss=0.564, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  17%|█▋        | 172/1026 [00:33<02:48,  5.06it/s, loss=0.556, v_num=0, train_loss=0.586, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  17%|█▋        | 174/1026 [00:34<02:48,  5.06it/s, loss=0.55, v_num=0, train_loss=0.529, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  17%|█▋        | 176/1026 [00:34<02:47,  5.06it/s, loss=0.546, v_num=0, train_loss=0.529, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  17%|█▋        | 178/1026 [00:35<02:47,  5.07it/s, loss=0.546, v_num=0, train_loss=0.497, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  18%|█▊        | 180/1026 [00:35<02:46,  5.07it/s, loss=0.547, v_num=0, train_loss=0.589, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  18%|█▊        | 182/1026 [00:35<02:46,  5.07it/s, loss=0.553, v_num=0, train_loss=0.605, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  18%|█▊        | 184/1026 [00:36<02:45,  5.07it/s, loss=0.556, v_num=0, train_loss=0.619, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  18%|█▊        | 186/1026 [00:36<02:45,  5.08it/s, loss=0.556, v_num=0, train_loss=0.522, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  18%|█▊        | 188/1026 [00:37<02:45,  5.08it/s, loss=0.555, v_num=0, train_loss=0.546, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  19%|█▊        | 190/1026 [00:37<02:44,  5.08it/s, loss=0.556, v_num=0, train_loss=0.653, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  19%|█▊        | 192/1026 [00:37<02:44,  5.08it/s, loss=0.558, v_num=0, train_loss=0.590, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  19%|█▉        | 194/1026 [00:38<02:43,  5.08it/s, loss=0.556, v_num=0, train_loss=0.545, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  19%|█▉        | 196/1026 [00:38<02:43,  5.08it/s, loss=0.567, v_num=0, train_loss=0.589, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  19%|█▉        | 198/1026 [00:38<02:42,  5.08it/s, loss=0.574, v_num=0, train_loss=0.561, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  19%|█▉        | 200/1026 [00:39<02:42,  5.09it/s, loss=0.568, v_num=0, train_loss=0.467, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  20%|█▉        | 202/1026 [00:39<02:42,  5.09it/s, loss=0.57, v_num=0, train_loss=0.574, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  20%|█▉        | 204/1026 [00:40<02:41,  5.09it/s, loss=0.565, v_num=0, train_loss=0.572, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  20%|██        | 206/1026 [00:40<02:41,  5.09it/s, loss=0.572, v_num=0, train_loss=0.606, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  20%|██        | 208/1026 [00:40<02:40,  5.09it/s, loss=0.574, v_num=0, train_loss=0.595, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  20%|██        | 210/1026 [00:41<02:40,  5.09it/s, loss=0.577, v_num=0, train_loss=0.602, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  21%|██        | 212/1026 [00:41<02:39,  5.09it/s, loss=0.579, v_num=0, train_loss=0.614, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  21%|██        | 214/1026 [00:42<02:39,  5.09it/s, loss=0.581, v_num=0, train_loss=0.601, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  21%|██        | 216/1026 [00:42<02:38,  5.10it/s, loss=0.574, v_num=0, train_loss=0.582, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  21%|██        | 218/1026 [00:42<02:38,  5.10it/s, loss=0.574, v_num=0, train_loss=0.634, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  21%|██▏       | 220/1026 [00:43<02:38,  5.10it/s, loss=0.581, v_num=0, train_loss=0.573, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  22%|██▏       | 222/1026 [00:43<02:37,  5.10it/s, loss=0.581, v_num=0, train_loss=0.534, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  22%|██▏       | 224/1026 [00:43<02:37,  5.10it/s, loss=0.583, v_num=0, train_loss=0.524, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  22%|██▏       | 226/1026 [00:44<02:36,  5.10it/s, loss=0.58, v_num=0, train_loss=0.557, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  22%|██▏       | 228/1026 [00:44<02:36,  5.10it/s, loss=0.582, v_num=0, train_loss=0.575, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  22%|██▏       | 230/1026 [00:45<02:35,  5.10it/s, loss=0.578, v_num=0, train_loss=0.526, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  23%|██▎       | 232/1026 [00:45<02:35,  5.10it/s, loss=0.574, v_num=0, train_loss=0.595, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  23%|██▎       | 234/1026 [00:45<02:35,  5.10it/s, loss=0.573, v_num=0, train_loss=0.505, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  23%|██▎       | 236/1026 [00:46<02:34,  5.11it/s, loss=0.577, v_num=0, train_loss=0.616, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  23%|██▎       | 238/1026 [00:46<02:34,  5.11it/s, loss=0.57, v_num=0, train_loss=0.538, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  23%|██▎       | 240/1026 [00:46<02:33,  5.11it/s, loss=0.566, v_num=0, train_loss=0.555, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  24%|██▎       | 242/1026 [00:47<02:33,  5.11it/s, loss=0.572, v_num=0, train_loss=0.582, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  24%|██▍       | 244/1026 [00:47<02:33,  5.11it/s, loss=0.571, v_num=0, train_loss=0.562, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  24%|██▍       | 246/1026 [00:48<02:32,  5.11it/s, loss=0.569, v_num=0, train_loss=0.602, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  24%|██▍       | 248/1026 [00:48<02:32,  5.11it/s, loss=0.575, v_num=0, train_loss=0.606, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  24%|██▍       | 250/1026 [00:48<02:31,  5.11it/s, loss=0.569, v_num=0, train_loss=0.461, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  25%|██▍       | 252/1026 [00:49<02:31,  5.11it/s, loss=0.571, v_num=0, train_loss=0.585, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  25%|██▍       | 254/1026 [00:49<02:30,  5.11it/s, loss=0.569, v_num=0, train_loss=0.584, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  25%|██▍       | 256/1026 [00:50<02:30,  5.11it/s, loss=0.569, v_num=0, train_loss=0.574, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  25%|██▌       | 258/1026 [00:50<02:30,  5.11it/s, loss=0.576, v_num=0, train_loss=0.619, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  25%|██▌       | 260/1026 [00:50<02:29,  5.12it/s, loss=0.585, v_num=0, train_loss=0.683, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  26%|██▌       | 262/1026 [00:51<02:29,  5.12it/s, loss=0.577, v_num=0, train_loss=0.560, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  26%|██▌       | 264/1026 [00:51<02:28,  5.12it/s, loss=0.58, v_num=0, train_loss=0.628, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  26%|██▌       | 266/1026 [00:51<02:28,  5.12it/s, loss=0.576, v_num=0, train_loss=0.570, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  26%|██▌       | 268/1026 [00:52<02:28,  5.12it/s, loss=0.567, v_num=0, train_loss=0.523, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  26%|██▋       | 270/1026 [00:52<02:27,  5.12it/s, loss=0.571, v_num=0, train_loss=0.484, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  27%|██▋       | 272/1026 [00:53<02:27,  5.12it/s, loss=0.567, v_num=0, train_loss=0.525, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  27%|██▋       | 274/1026 [00:53<02:26,  5.12it/s, loss=0.569, v_num=0, train_loss=0.595, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  27%|██▋       | 276/1026 [00:53<02:26,  5.12it/s, loss=0.57, v_num=0, train_loss=0.608, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  27%|██▋       | 278/1026 [00:54<02:26,  5.12it/s, loss=0.564, v_num=0, train_loss=0.518, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  27%|██▋       | 280/1026 [00:54<02:25,  5.12it/s, loss=0.554, v_num=0, train_loss=0.529, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  27%|██▋       | 282/1026 [00:55<02:25,  5.12it/s, loss=0.557, v_num=0, train_loss=0.571, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  28%|██▊       | 284/1026 [00:55<02:24,  5.12it/s, loss=0.557, v_num=0, train_loss=0.562, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  28%|██▊       | 286/1026 [00:55<02:24,  5.13it/s, loss=0.554, v_num=0, train_loss=0.555, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  28%|██▊       | 288/1026 [00:56<02:23,  5.13it/s, loss=0.555, v_num=0, train_loss=0.580, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  28%|██▊       | 290/1026 [00:56<02:23,  5.13it/s, loss=0.556, v_num=0, train_loss=0.568, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  28%|██▊       | 292/1026 [00:56<02:23,  5.13it/s, loss=0.56, v_num=0, train_loss=0.542, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  29%|██▊       | 294/1026 [00:57<02:22,  5.13it/s, loss=0.561, v_num=0, train_loss=0.601, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  29%|██▉       | 296/1026 [00:57<02:22,  5.13it/s, loss=0.558, v_num=0, train_loss=0.520, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  29%|██▉       | 298/1026 [00:58<02:21,  5.13it/s, loss=0.562, v_num=0, train_loss=0.543, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  29%|██▉       | 300/1026 [00:58<02:21,  5.13it/s, loss=0.564, v_num=0, train_loss=0.524, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  29%|██▉       | 302/1026 [00:58<02:21,  5.13it/s, loss=0.567, v_num=0, train_loss=0.639, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  30%|██▉       | 304/1026 [00:59<02:20,  5.13it/s, loss=0.565, v_num=0, train_loss=0.503, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  30%|██▉       | 306/1026 [00:59<02:20,  5.13it/s, loss=0.571, v_num=0, train_loss=0.552, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  30%|███       | 308/1026 [01:00<02:19,  5.13it/s, loss=0.571, v_num=0, train_loss=0.553, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  30%|███       | 310/1026 [01:00<02:19,  5.13it/s, loss=0.568, v_num=0, train_loss=0.555, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  30%|███       | 312/1026 [01:00<02:19,  5.13it/s, loss=0.566, v_num=0, train_loss=0.528, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  31%|███       | 314/1026 [01:01<02:18,  5.13it/s, loss=0.564, v_num=0, train_loss=0.576, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  31%|███       | 316/1026 [01:01<02:18,  5.13it/s, loss=0.562, v_num=0, train_loss=0.532, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  31%|███       | 318/1026 [01:01<02:17,  5.13it/s, loss=0.561, v_num=0, train_loss=0.477, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  31%|███       | 320/1026 [01:02<02:17,  5.13it/s, loss=0.559, v_num=0, train_loss=0.545, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  31%|███▏      | 322/1026 [01:02<02:17,  5.13it/s, loss=0.554, v_num=0, train_loss=0.530, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  32%|███▏      | 324/1026 [01:03<02:16,  5.13it/s, loss=0.555, v_num=0, train_loss=0.541, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  32%|███▏      | 326/1026 [01:03<02:16,  5.14it/s, loss=0.552, v_num=0, train_loss=0.525, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  32%|███▏      | 328/1026 [01:03<02:15,  5.14it/s, loss=0.557, v_num=0, train_loss=0.605, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  32%|███▏      | 330/1026 [01:04<02:15,  5.14it/s, loss=0.558, v_num=0, train_loss=0.576, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  32%|███▏      | 332/1026 [01:04<02:15,  5.14it/s, loss=0.558, v_num=0, train_loss=0.567, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  33%|███▎      | 334/1026 [01:05<02:14,  5.14it/s, loss=0.556, v_num=0, train_loss=0.627, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  33%|███▎      | 336/1026 [01:05<02:14,  5.14it/s, loss=0.561, v_num=0, train_loss=0.587, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  33%|███▎      | 338/1026 [01:05<02:13,  5.14it/s, loss=0.561, v_num=0, train_loss=0.578, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  33%|███▎      | 340/1026 [01:06<02:13,  5.14it/s, loss=0.564, v_num=0, train_loss=0.520, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  33%|███▎      | 342/1026 [01:06<02:13,  5.14it/s, loss=0.564, v_num=0, train_loss=0.596, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  34%|███▎      | 344/1026 [01:06<02:12,  5.14it/s, loss=0.567, v_num=0, train_loss=0.543, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  34%|███▎      | 346/1026 [01:07<02:12,  5.14it/s, loss=0.568, v_num=0, train_loss=0.534, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  34%|███▍      | 348/1026 [01:07<02:11,  5.14it/s, loss=0.566, v_num=0, train_loss=0.597, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  34%|███▍      | 350/1026 [01:08<02:11,  5.14it/s, loss=0.573, v_num=0, train_loss=0.593, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  34%|███▍      | 352/1026 [01:08<02:11,  5.14it/s, loss=0.574, v_num=0, train_loss=0.562, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  35%|███▍      | 354/1026 [01:08<02:10,  5.14it/s, loss=0.577, v_num=0, train_loss=0.535, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  35%|███▍      | 356/1026 [01:09<02:10,  5.14it/s, loss=0.568, v_num=0, train_loss=0.518, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  35%|███▍      | 358/1026 [01:09<02:09,  5.14it/s, loss=0.567, v_num=0, train_loss=0.435, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  35%|███▌      | 360/1026 [01:09<02:09,  5.14it/s, loss=0.572, v_num=0, train_loss=0.614, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  35%|███▌      | 362/1026 [01:10<02:09,  5.14it/s, loss=0.571, v_num=0, train_loss=0.538, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  35%|███▌      | 364/1026 [01:10<02:08,  5.14it/s, loss=0.566, v_num=0, train_loss=0.550, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  36%|███▌      | 366/1026 [01:11<02:08,  5.14it/s, loss=0.564, v_num=0, train_loss=0.552, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  36%|███▌      | 368/1026 [01:11<02:07,  5.14it/s, loss=0.56, v_num=0, train_loss=0.576, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  36%|███▌      | 370/1026 [01:11<02:07,  5.14it/s, loss=0.554, v_num=0, train_loss=0.595, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  36%|███▋      | 372/1026 [01:12<02:07,  5.14it/s, loss=0.552, v_num=0, train_loss=0.514, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  36%|███▋      | 374/1026 [01:12<02:06,  5.14it/s, loss=0.55, v_num=0, train_loss=0.524, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  37%|███▋      | 376/1026 [01:13<02:06,  5.15it/s, loss=0.553, v_num=0, train_loss=0.540, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  37%|███▋      | 378/1026 [01:13<02:05,  5.15it/s, loss=0.557, v_num=0, train_loss=0.614, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  37%|███▋      | 380/1026 [01:13<02:05,  5.15it/s, loss=0.556, v_num=0, train_loss=0.648, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  37%|███▋      | 382/1026 [01:14<02:05,  5.15it/s, loss=0.56, v_num=0, train_loss=0.596, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  37%|███▋      | 384/1026 [01:14<02:04,  5.15it/s, loss=0.556, v_num=0, train_loss=0.502, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  38%|███▊      | 386/1026 [01:15<02:04,  5.15it/s, loss=0.557, v_num=0, train_loss=0.524, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  38%|███▊      | 388/1026 [01:15<02:03,  5.15it/s, loss=0.562, v_num=0, train_loss=0.611, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  38%|███▊      | 390/1026 [01:15<02:03,  5.15it/s, loss=0.563, v_num=0, train_loss=0.587, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  38%|███▊      | 392/1026 [01:16<02:03,  5.15it/s, loss=0.565, v_num=0, train_loss=0.575, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  38%|███▊      | 394/1026 [01:16<02:02,  5.15it/s, loss=0.568, v_num=0, train_loss=0.587, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  39%|███▊      | 396/1026 [01:16<02:02,  5.15it/s, loss=0.565, v_num=0, train_loss=0.473, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  39%|███▉      | 398/1026 [01:17<02:01,  5.15it/s, loss=0.562, v_num=0, train_loss=0.573, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  39%|███▉      | 400/1026 [01:17<02:01,  5.15it/s, loss=0.558, v_num=0, train_loss=0.602, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  39%|███▉      | 402/1026 [01:18<02:01,  5.15it/s, loss=0.562, v_num=0, train_loss=0.680, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  39%|███▉      | 404/1026 [01:18<02:00,  5.15it/s, loss=0.565, v_num=0, train_loss=0.537, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  40%|███▉      | 406/1026 [01:18<02:00,  5.15it/s, loss=0.566, v_num=0, train_loss=0.557, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  40%|███▉      | 408/1026 [01:19<02:00,  5.15it/s, loss=0.56, v_num=0, train_loss=0.519, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  40%|███▉      | 410/1026 [01:19<01:59,  5.15it/s, loss=0.559, v_num=0, train_loss=0.536, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  40%|████      | 412/1026 [01:20<01:59,  5.15it/s, loss=0.558, v_num=0, train_loss=0.631, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  40%|████      | 414/1026 [01:20<01:58,  5.15it/s, loss=0.553, v_num=0, train_loss=0.505, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  41%|████      | 416/1026 [01:20<01:58,  5.15it/s, loss=0.556, v_num=0, train_loss=0.532, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  41%|████      | 418/1026 [01:21<01:58,  5.15it/s, loss=0.547, v_num=0, train_loss=0.472, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  41%|████      | 420/1026 [01:21<01:57,  5.15it/s, loss=0.547, v_num=0, train_loss=0.627, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  41%|████      | 422/1026 [01:21<01:57,  5.15it/s, loss=0.539, v_num=0, train_loss=0.459, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  41%|████▏     | 424/1026 [01:22<01:56,  5.15it/s, loss=0.544, v_num=0, train_loss=0.583, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  42%|████▏     | 426/1026 [01:22<01:56,  5.15it/s, loss=0.547, v_num=0, train_loss=0.566, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  42%|████▏     | 428/1026 [01:23<01:56,  5.15it/s, loss=0.553, v_num=0, train_loss=0.582, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  42%|████▏     | 430/1026 [01:23<01:55,  5.15it/s, loss=0.553, v_num=0, train_loss=0.557, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  42%|████▏     | 432/1026 [01:23<01:55,  5.15it/s, loss=0.551, v_num=0, train_loss=0.512, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  42%|████▏     | 434/1026 [01:24<01:54,  5.15it/s, loss=0.552, v_num=0, train_loss=0.520, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  42%|████▏     | 436/1026 [01:24<01:54,  5.15it/s, loss=0.558, v_num=0, train_loss=0.636, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  43%|████▎     | 438/1026 [01:24<01:54,  5.15it/s, loss=0.567, v_num=0, train_loss=0.583, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  43%|████▎     | 440/1026 [01:25<01:53,  5.15it/s, loss=0.568, v_num=0, train_loss=0.548, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  43%|████▎     | 442/1026 [01:25<01:53,  5.15it/s, loss=0.568, v_num=0, train_loss=0.529, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  43%|████▎     | 444/1026 [01:26<01:52,  5.15it/s, loss=0.561, v_num=0, train_loss=0.532, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  43%|████▎     | 446/1026 [01:26<01:52,  5.15it/s, loss=0.56, v_num=0, train_loss=0.558, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  44%|████▎     | 448/1026 [01:26<01:52,  5.15it/s, loss=0.561, v_num=0, train_loss=0.583, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  44%|████▍     | 450/1026 [01:27<01:51,  5.15it/s, loss=0.559, v_num=0, train_loss=0.473, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  44%|████▍     | 452/1026 [01:27<01:51,  5.15it/s, loss=0.563, v_num=0, train_loss=0.524, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  44%|████▍     | 454/1026 [01:28<01:50,  5.16it/s, loss=0.566, v_num=0, train_loss=0.576, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  44%|████▍     | 456/1026 [01:28<01:50,  5.16it/s, loss=0.557, v_num=0, train_loss=0.483, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  45%|████▍     | 458/1026 [01:28<01:50,  5.16it/s, loss=0.555, v_num=0, train_loss=0.518, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  45%|████▍     | 460/1026 [01:29<01:49,  5.16it/s, loss=0.553, v_num=0, train_loss=0.512, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  45%|████▌     | 462/1026 [01:29<01:49,  5.16it/s, loss=0.56, v_num=0, train_loss=0.585, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  45%|████▌     | 464/1026 [01:29<01:48,  5.16it/s, loss=0.57, v_num=0, train_loss=0.564, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  45%|████▌     | 466/1026 [01:30<01:48,  5.16it/s, loss=0.567, v_num=0, train_loss=0.582, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  46%|████▌     | 468/1026 [01:30<01:48,  5.16it/s, loss=0.568, v_num=0, train_loss=0.614, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  46%|████▌     | 470/1026 [01:31<01:47,  5.16it/s, loss=0.569, v_num=0, train_loss=0.517, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  46%|████▌     | 472/1026 [01:31<01:47,  5.16it/s, loss=0.572, v_num=0, train_loss=0.608, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  46%|████▌     | 474/1026 [01:31<01:47,  5.16it/s, loss=0.575, v_num=0, train_loss=0.560, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  46%|████▋     | 476/1026 [01:32<01:46,  5.16it/s, loss=0.579, v_num=0, train_loss=0.555, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  47%|████▋     | 478/1026 [01:32<01:46,  5.16it/s, loss=0.582, v_num=0, train_loss=0.589, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  47%|████▋     | 480/1026 [01:33<01:45,  5.16it/s, loss=0.584, v_num=0, train_loss=0.534, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  47%|████▋     | 482/1026 [01:33<01:45,  5.16it/s, loss=0.572, v_num=0, train_loss=0.499, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  47%|████▋     | 484/1026 [01:33<01:45,  5.16it/s, loss=0.569, v_num=0, train_loss=0.563, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  47%|████▋     | 486/1026 [01:34<01:44,  5.16it/s, loss=0.567, v_num=0, train_loss=0.549, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  48%|████▊     | 488/1026 [01:34<01:44,  5.16it/s, loss=0.564, v_num=0, train_loss=0.558, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  48%|████▊     | 490/1026 [01:34<01:43,  5.16it/s, loss=0.56, v_num=0, train_loss=0.504, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  48%|████▊     | 492/1026 [01:35<01:43,  5.16it/s, loss=0.552, v_num=0, train_loss=0.494, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  48%|████▊     | 494/1026 [01:35<01:43,  5.16it/s, loss=0.55, v_num=0, train_loss=0.626, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  48%|████▊     | 496/1026 [01:36<01:42,  5.16it/s, loss=0.547, v_num=0, train_loss=0.488, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  49%|████▊     | 498/1026 [01:36<01:42,  5.16it/s, loss=0.554, v_num=0, train_loss=0.635, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  49%|████▊     | 500/1026 [01:36<01:41,  5.16it/s, loss=0.554, v_num=0, train_loss=0.562, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  49%|████▉     | 502/1026 [01:37<01:41,  5.16it/s, loss=0.557, v_num=0, train_loss=0.520, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  49%|████▉     | 504/1026 [01:37<01:41,  5.16it/s, loss=0.556, v_num=0, train_loss=0.569, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  49%|████▉     | 506/1026 [01:38<01:40,  5.16it/s, loss=0.554, v_num=0, train_loss=0.501, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  50%|████▉     | 508/1026 [01:38<01:40,  5.16it/s, loss=0.56, v_num=0, train_loss=0.609, val_loss=0.583, val_score=0.699] \n",
      "Epoch 1:  50%|████▉     | 510/1026 [01:38<01:39,  5.16it/s, loss=0.568, v_num=0, train_loss=0.571, val_loss=0.583, val_score=0.699]\n",
      "Epoch 1:  50%|████▉     | 512/1026 [01:39<01:39,  5.16it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[0m \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation:   0%|          | 0/513 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 514/1026 [01:40<01:39,  5.13it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   0%|          | 2/513 [00:00<00:17, 29.31it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 516/1026 [01:40<01:39,  5.14it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   1%|          | 4/513 [00:00<00:23, 21.60it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 518/1026 [01:40<01:38,  5.15it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   1%|          | 6/513 [00:00<00:25, 19.82it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 520/1026 [01:40<01:37,  5.17it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   2%|▏         | 8/513 [00:00<00:26, 19.03it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 522/1026 [01:40<01:37,  5.18it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   2%|▏         | 10/513 [00:00<00:27, 18.60it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 524/1026 [01:40<01:36,  5.19it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   2%|▏         | 12/513 [00:00<00:27, 18.32it/s]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 526/1026 [01:40<01:35,  5.21it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   3%|▎         | 14/513 [00:00<00:27, 18.12it/s]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 528/1026 [01:41<01:35,  5.22it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   3%|▎         | 16/513 [00:00<00:27, 18.00it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 530/1026 [01:41<01:34,  5.24it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   4%|▎         | 18/513 [00:01<00:27, 17.90it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 532/1026 [01:41<01:34,  5.25it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   4%|▍         | 20/513 [00:01<00:27, 17.81it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 534/1026 [01:41<01:33,  5.26it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:   4%|▍         | 22/513 [00:01<00:27, 17.72it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 536/1026 [01:41<01:32,  5.28it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  52%|█████▏    | 538/1026 [01:41<01:32,  5.29it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  53%|█████▎    | 540/1026 [01:41<01:31,  5.30it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  53%|█████▎    | 542/1026 [01:41<01:31,  5.32it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  53%|█████▎    | 544/1026 [01:42<01:30,  5.33it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  53%|█████▎    | 546/1026 [01:42<01:29,  5.34it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  53%|█████▎    | 548/1026 [01:42<01:29,  5.36it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  54%|█████▎    | 550/1026 [01:42<01:28,  5.37it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  54%|█████▍    | 552/1026 [01:42<01:28,  5.38it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  54%|█████▍    | 554/1026 [01:42<01:27,  5.40it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  54%|█████▍    | 556/1026 [01:42<01:26,  5.41it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  54%|█████▍    | 558/1026 [01:42<01:26,  5.42it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  55%|█████▍    | 560/1026 [01:42<01:25,  5.44it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  55%|█████▍    | 562/1026 [01:43<01:25,  5.45it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  55%|█████▍    | 564/1026 [01:43<01:24,  5.46it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  10%|█         | 52/513 [00:03<00:26, 17.31it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 566/1026 [01:43<01:23,  5.48it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  11%|█         | 54/513 [00:03<00:26, 17.31it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 568/1026 [01:43<01:23,  5.49it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  11%|█         | 56/513 [00:03<00:26, 17.30it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 570/1026 [01:43<01:22,  5.50it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  11%|█▏        | 58/513 [00:03<00:26, 17.29it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 572/1026 [01:43<01:22,  5.52it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  12%|█▏        | 60/513 [00:03<00:26, 17.28it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 574/1026 [01:43<01:21,  5.53it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  12%|█▏        | 62/513 [00:03<00:26, 17.28it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 576/1026 [01:43<01:21,  5.54it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  12%|█▏        | 64/513 [00:03<00:25, 17.27it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 578/1026 [01:44<01:20,  5.56it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  13%|█▎        | 66/513 [00:03<00:25, 17.27it/s]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 580/1026 [01:44<01:20,  5.57it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  13%|█▎        | 68/513 [00:03<00:25, 17.26it/s]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 582/1026 [01:44<01:19,  5.58it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  14%|█▎        | 70/513 [00:04<00:25, 17.26it/s]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 584/1026 [01:44<01:19,  5.59it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  14%|█▍        | 72/513 [00:04<00:25, 17.25it/s]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 586/1026 [01:44<01:18,  5.61it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  14%|█▍        | 74/513 [00:04<00:25, 17.25it/s]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 588/1026 [01:44<01:17,  5.62it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  15%|█▍        | 76/513 [00:04<00:25, 17.24it/s]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 590/1026 [01:44<01:17,  5.63it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  15%|█▌        | 78/513 [00:04<00:25, 17.24it/s]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 592/1026 [01:44<01:16,  5.65it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 594/1026 [01:44<01:16,  5.66it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 596/1026 [01:45<01:15,  5.67it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 598/1026 [01:45<01:15,  5.68it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 600/1026 [01:45<01:14,  5.70it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  59%|█████▊    | 602/1026 [01:45<01:14,  5.71it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  59%|█████▉    | 604/1026 [01:45<01:13,  5.72it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  59%|█████▉    | 606/1026 [01:45<01:13,  5.73it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  59%|█████▉    | 608/1026 [01:45<01:12,  5.75it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  59%|█████▉    | 610/1026 [01:45<01:12,  5.76it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  19%|█▉        | 98/513 [00:05<00:24, 17.21it/s]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 612/1026 [01:46<01:11,  5.77it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  60%|█████▉    | 614/1026 [01:46<01:11,  5.78it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  20%|█▉        | 102/513 [00:05<00:23, 17.20it/s]\u001b[A\n",
      "Epoch 1:  60%|██████    | 616/1026 [01:46<01:10,  5.80it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  60%|██████    | 618/1026 [01:46<01:10,  5.81it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██        | 106/513 [00:06<00:23, 17.20it/s]\u001b[A\n",
      "Epoch 1:  60%|██████    | 620/1026 [01:46<01:09,  5.82it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██        | 108/513 [00:06<00:23, 17.19it/s]\u001b[A\n",
      "Epoch 1:  61%|██████    | 622/1026 [01:46<01:09,  5.83it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██▏       | 110/513 [00:06<00:23, 17.19it/s]\u001b[A\n",
      "Epoch 1:  61%|██████    | 624/1026 [01:46<01:08,  5.85it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████    | 626/1026 [01:46<01:08,  5.86it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████    | 628/1026 [01:46<01:07,  5.87it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 116/513 [00:06<00:23, 17.19it/s]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 630/1026 [01:47<01:07,  5.88it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 118/513 [00:06<00:22, 17.18it/s]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 632/1026 [01:47<01:06,  5.90it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 120/513 [00:06<00:22, 17.18it/s]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 634/1026 [01:47<01:06,  5.91it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  24%|██▍       | 122/513 [00:07<00:22, 17.18it/s]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 636/1026 [01:47<01:05,  5.92it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  24%|██▍       | 124/513 [00:07<00:22, 17.18it/s]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 638/1026 [01:47<01:05,  5.93it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  62%|██████▏   | 640/1026 [01:47<01:04,  5.94it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▍       | 128/513 [00:07<00:22, 17.17it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 642/1026 [01:47<01:04,  5.96it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▌       | 130/513 [00:07<00:22, 17.17it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 644/1026 [01:47<01:04,  5.97it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  26%|██▌       | 132/513 [00:07<00:22, 17.17it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 646/1026 [01:48<01:03,  5.98it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  63%|██████▎   | 648/1026 [01:48<01:03,  5.99it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 136/513 [00:07<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 650/1026 [01:48<01:02,  6.00it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 138/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 652/1026 [01:48<01:02,  6.02it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 140/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 654/1026 [01:48<01:01,  6.03it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  64%|██████▍   | 656/1026 [01:48<01:01,  6.04it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  28%|██▊       | 144/513 [00:08<00:21, 17.17it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 658/1026 [01:48<01:00,  6.05it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  28%|██▊       | 146/513 [00:08<00:21, 17.16it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 660/1026 [01:48<01:00,  6.06it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  65%|██████▍   | 662/1026 [01:48<00:59,  6.08it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  29%|██▉       | 150/513 [00:08<00:21, 17.16it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 664/1026 [01:49<00:59,  6.09it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  65%|██████▍   | 666/1026 [01:49<00:59,  6.10it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  30%|███       | 154/513 [00:08<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 668/1026 [01:49<00:58,  6.11it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  65%|██████▌   | 670/1026 [01:49<00:58,  6.12it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  31%|███       | 158/513 [00:09<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 672/1026 [01:49<00:57,  6.13it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  31%|███       | 160/513 [00:09<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 674/1026 [01:49<00:57,  6.15it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  32%|███▏      | 162/513 [00:09<00:20, 17.16it/s]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 676/1026 [01:49<00:56,  6.16it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▌   | 678/1026 [01:49<00:56,  6.17it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  32%|███▏      | 166/513 [00:09<00:20, 17.15it/s]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 680/1026 [01:50<00:55,  6.18it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▋   | 682/1026 [01:50<00:55,  6.19it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  33%|███▎      | 170/513 [00:09<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 684/1026 [01:50<00:55,  6.20it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  34%|███▎      | 172/513 [00:10<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 686/1026 [01:50<00:54,  6.22it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  34%|███▍      | 174/513 [00:10<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 688/1026 [01:50<00:54,  6.23it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  67%|██████▋   | 690/1026 [01:50<00:53,  6.24it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  35%|███▍      | 178/513 [00:10<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 692/1026 [01:50<00:53,  6.25it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  68%|██████▊   | 694/1026 [01:50<00:53,  6.26it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  35%|███▌      | 182/513 [00:10<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 696/1026 [01:50<00:52,  6.27it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  68%|██████▊   | 698/1026 [01:51<00:52,  6.28it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  36%|███▋      | 186/513 [00:10<00:19, 17.15it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 700/1026 [01:51<00:51,  6.30it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 188/513 [00:10<00:18, 17.15it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 702/1026 [01:51<00:51,  6.31it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 190/513 [00:11<00:18, 17.14it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 704/1026 [01:51<00:50,  6.32it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 192/513 [00:11<00:18, 17.14it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 706/1026 [01:51<00:50,  6.33it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  69%|██████▉   | 708/1026 [01:51<00:50,  6.34it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  38%|███▊      | 196/513 [00:11<00:18, 17.14it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 710/1026 [01:51<00:49,  6.35it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▊      | 198/513 [00:11<00:18, 17.14it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 712/1026 [01:51<00:49,  6.36it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  70%|██████▉   | 714/1026 [01:52<00:48,  6.37it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▉      | 202/513 [00:11<00:18, 17.14it/s]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 716/1026 [01:52<00:48,  6.39it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  70%|██████▉   | 718/1026 [01:52<00:48,  6.40it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  40%|████      | 206/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 720/1026 [01:52<00:47,  6.41it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  41%|████      | 208/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 722/1026 [01:52<00:47,  6.42it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  41%|████      | 210/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 1:  71%|███████   | 724/1026 [01:52<00:46,  6.43it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████   | 726/1026 [01:52<00:46,  6.44it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  42%|████▏     | 214/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 1:  71%|███████   | 728/1026 [01:52<00:46,  6.45it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████   | 730/1026 [01:52<00:45,  6.46it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████▏  | 732/1026 [01:53<00:45,  6.47it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  43%|████▎     | 220/513 [00:12<00:17, 17.14it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 734/1026 [01:53<00:45,  6.49it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  43%|████▎     | 222/513 [00:12<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 736/1026 [01:53<00:44,  6.50it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  44%|████▎     | 224/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 738/1026 [01:53<00:44,  6.51it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  72%|███████▏  | 740/1026 [01:53<00:43,  6.52it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  44%|████▍     | 228/513 [00:13<00:16, 17.14it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 742/1026 [01:53<00:43,  6.53it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  45%|████▍     | 230/513 [00:13<00:16, 17.13it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 744/1026 [01:53<00:43,  6.54it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  73%|███████▎  | 746/1026 [01:53<00:42,  6.55it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  46%|████▌     | 234/513 [00:13<00:16, 17.13it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 748/1026 [01:53<00:42,  6.56it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  73%|███████▎  | 750/1026 [01:54<00:41,  6.57it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  46%|████▋     | 238/513 [00:13<00:16, 17.13it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 752/1026 [01:54<00:41,  6.58it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  47%|████▋     | 240/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 754/1026 [01:54<00:41,  6.59it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  74%|███████▎  | 756/1026 [01:54<00:40,  6.60it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 244/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 758/1026 [01:54<00:40,  6.62it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 246/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 760/1026 [01:54<00:40,  6.63it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  48%|████▊     | 248/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 762/1026 [01:54<00:39,  6.64it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  49%|████▊     | 250/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 764/1026 [01:54<00:39,  6.65it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  49%|████▉     | 252/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 766/1026 [01:55<00:39,  6.66it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  50%|████▉     | 254/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 768/1026 [01:55<00:38,  6.67it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  50%|████▉     | 256/513 [00:14<00:15, 17.13it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 770/1026 [01:55<00:38,  6.68it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  50%|█████     | 258/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 772/1026 [01:55<00:37,  6.69it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  51%|█████     | 260/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 774/1026 [01:55<00:37,  6.70it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  51%|█████     | 262/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 776/1026 [01:55<00:37,  6.71it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  51%|█████▏    | 264/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 778/1026 [01:55<00:36,  6.72it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  52%|█████▏    | 266/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 780/1026 [01:55<00:36,  6.73it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  52%|█████▏    | 268/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 782/1026 [01:55<00:36,  6.74it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  53%|█████▎    | 270/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 784/1026 [01:56<00:35,  6.75it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  53%|█████▎    | 272/513 [00:15<00:14, 17.13it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 786/1026 [01:56<00:35,  6.76it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  53%|█████▎    | 274/513 [00:15<00:13, 17.13it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 788/1026 [01:56<00:35,  6.77it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  54%|█████▍    | 276/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 790/1026 [01:56<00:34,  6.78it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  54%|█████▍    | 278/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 792/1026 [01:56<00:34,  6.79it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  55%|█████▍    | 280/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 794/1026 [01:56<00:34,  6.80it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▍    | 282/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 796/1026 [01:56<00:33,  6.81it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▌    | 284/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 798/1026 [01:56<00:33,  6.83it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  56%|█████▌    | 286/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 800/1026 [01:57<00:33,  6.84it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  56%|█████▌    | 288/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 802/1026 [01:57<00:32,  6.85it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 290/513 [00:16<00:13, 17.12it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 804/1026 [01:57<00:32,  6.86it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  57%|█████▋    | 292/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 806/1026 [01:57<00:32,  6.87it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 294/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 808/1026 [01:57<00:31,  6.88it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 296/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 810/1026 [01:57<00:31,  6.89it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 298/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 812/1026 [01:57<00:31,  6.90it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  58%|█████▊    | 300/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 814/1026 [01:57<00:30,  6.91it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  59%|█████▉    | 302/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 816/1026 [01:57<00:30,  6.92it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  59%|█████▉    | 304/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 818/1026 [01:58<00:30,  6.93it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|█████▉    | 306/513 [00:17<00:12, 17.12it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 820/1026 [01:58<00:29,  6.94it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  60%|██████    | 308/513 [00:17<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 822/1026 [01:58<00:29,  6.95it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|██████    | 310/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 824/1026 [01:58<00:29,  6.96it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  61%|██████    | 312/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 826/1026 [01:58<00:28,  6.97it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  61%|██████    | 314/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 828/1026 [01:58<00:28,  6.98it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  62%|██████▏   | 316/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 830/1026 [01:58<00:28,  6.99it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  62%|██████▏   | 318/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 832/1026 [01:58<00:27,  7.00it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  62%|██████▏   | 320/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 834/1026 [01:59<00:27,  7.01it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  63%|██████▎   | 322/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 836/1026 [01:59<00:27,  7.02it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  63%|██████▎   | 324/513 [00:18<00:11, 17.12it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 838/1026 [01:59<00:26,  7.03it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  64%|██████▎   | 326/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 840/1026 [01:59<00:26,  7.04it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  64%|██████▍   | 328/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 842/1026 [01:59<00:26,  7.05it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  64%|██████▍   | 330/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 844/1026 [01:59<00:25,  7.06it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  65%|██████▍   | 332/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 846/1026 [01:59<00:25,  7.07it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  65%|██████▌   | 334/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 848/1026 [01:59<00:25,  7.08it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  65%|██████▌   | 336/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 850/1026 [01:59<00:24,  7.09it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  66%|██████▌   | 338/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 852/1026 [02:00<00:24,  7.10it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  66%|██████▋   | 340/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 854/1026 [02:00<00:24,  7.10it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 342/513 [00:19<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 856/1026 [02:00<00:23,  7.11it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 344/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 858/1026 [02:00<00:23,  7.12it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 346/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 860/1026 [02:00<00:23,  7.13it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  68%|██████▊   | 348/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 862/1026 [02:00<00:22,  7.14it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  68%|██████▊   | 350/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 864/1026 [02:00<00:22,  7.15it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▊   | 352/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 866/1026 [02:00<00:22,  7.16it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  69%|██████▉   | 354/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 868/1026 [02:01<00:22,  7.17it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▉   | 356/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 870/1026 [02:01<00:21,  7.18it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  70%|██████▉   | 358/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 872/1026 [02:01<00:21,  7.19it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  70%|███████   | 360/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 874/1026 [02:01<00:21,  7.20it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████   | 362/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 876/1026 [02:01<00:20,  7.21it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████   | 364/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 878/1026 [02:01<00:20,  7.22it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  71%|███████▏  | 366/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 880/1026 [02:01<00:20,  7.23it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  72%|███████▏  | 368/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 882/1026 [02:01<00:19,  7.24it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  72%|███████▏  | 370/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 884/1026 [02:01<00:19,  7.25it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  73%|███████▎  | 372/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 886/1026 [02:02<00:19,  7.26it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  73%|███████▎  | 374/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 888/1026 [02:02<00:18,  7.27it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  73%|███████▎  | 376/513 [00:21<00:08, 17.11it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 890/1026 [02:02<00:18,  7.28it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▎  | 378/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 892/1026 [02:02<00:18,  7.29it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▍  | 380/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 894/1026 [02:02<00:18,  7.30it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▍  | 382/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 896/1026 [02:02<00:17,  7.30it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  75%|███████▍  | 384/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 898/1026 [02:02<00:17,  7.31it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  75%|███████▌  | 386/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 900/1026 [02:02<00:17,  7.32it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▌  | 388/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 902/1026 [02:03<00:16,  7.33it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▌  | 390/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 904/1026 [02:03<00:16,  7.34it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▋  | 392/513 [00:22<00:07, 17.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 906/1026 [02:03<00:16,  7.35it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  77%|███████▋  | 394/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 908/1026 [02:03<00:16,  7.36it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  77%|███████▋  | 396/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 910/1026 [02:03<00:15,  7.37it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  78%|███████▊  | 398/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 912/1026 [02:03<00:15,  7.38it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 400/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 914/1026 [02:03<00:15,  7.39it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  78%|███████▊  | 402/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 916/1026 [02:03<00:14,  7.40it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  79%|███████▉  | 404/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 918/1026 [02:03<00:14,  7.41it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  79%|███████▉  | 406/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 920/1026 [02:04<00:14,  7.42it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  80%|███████▉  | 408/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 922/1026 [02:04<00:14,  7.42it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  80%|███████▉  | 410/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 924/1026 [02:04<00:13,  7.43it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  80%|████████  | 412/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 926/1026 [02:04<00:13,  7.44it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  81%|████████  | 414/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 928/1026 [02:04<00:13,  7.45it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  81%|████████  | 416/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 930/1026 [02:04<00:12,  7.46it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  81%|████████▏ | 418/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 932/1026 [02:04<00:12,  7.47it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  82%|████████▏ | 420/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 934/1026 [02:04<00:12,  7.48it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  82%|████████▏ | 422/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 936/1026 [02:04<00:12,  7.49it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  83%|████████▎ | 424/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 938/1026 [02:05<00:11,  7.50it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  83%|████████▎ | 426/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 940/1026 [02:05<00:11,  7.51it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  83%|████████▎ | 428/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 942/1026 [02:05<00:11,  7.52it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  84%|████████▍ | 430/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 944/1026 [02:05<00:10,  7.52it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  84%|████████▍ | 432/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 946/1026 [02:05<00:10,  7.53it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  85%|████████▍ | 434/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 948/1026 [02:05<00:10,  7.54it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  85%|████████▍ | 436/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 950/1026 [02:05<00:10,  7.55it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  85%|████████▌ | 438/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 952/1026 [02:05<00:09,  7.56it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  86%|████████▌ | 440/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 954/1026 [02:06<00:09,  7.57it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  86%|████████▌ | 442/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 956/1026 [02:06<00:09,  7.58it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 444/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 958/1026 [02:06<00:08,  7.59it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 446/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 960/1026 [02:06<00:08,  7.59it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 448/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 962/1026 [02:06<00:08,  7.60it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 450/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 964/1026 [02:06<00:08,  7.61it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  88%|████████▊ | 452/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 966/1026 [02:06<00:07,  7.62it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 454/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 968/1026 [02:06<00:07,  7.63it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  89%|████████▉ | 456/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 970/1026 [02:06<00:07,  7.64it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  89%|████████▉ | 458/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 972/1026 [02:07<00:07,  7.65it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|████████▉ | 460/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 974/1026 [02:07<00:06,  7.66it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|█████████ | 462/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 976/1026 [02:07<00:06,  7.66it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|█████████ | 464/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 978/1026 [02:07<00:06,  7.67it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  91%|█████████ | 466/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 980/1026 [02:07<00:05,  7.68it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  91%|█████████ | 468/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 982/1026 [02:07<00:05,  7.69it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  92%|█████████▏| 470/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 984/1026 [02:07<00:05,  7.70it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  92%|█████████▏| 472/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 986/1026 [02:07<00:05,  7.71it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  92%|█████████▏| 474/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 988/1026 [02:08<00:04,  7.72it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  93%|█████████▎| 476/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 990/1026 [02:08<00:04,  7.72it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  93%|█████████▎| 478/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 992/1026 [02:08<00:04,  7.73it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  94%|█████████▎| 480/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 994/1026 [02:08<00:04,  7.74it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  94%|█████████▍| 482/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 996/1026 [02:08<00:03,  7.75it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  94%|█████████▍| 484/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 998/1026 [02:08<00:03,  7.76it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  95%|█████████▍| 486/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 1000/1026 [02:08<00:03,  7.77it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  95%|█████████▌| 488/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1002/1026 [02:08<00:03,  7.78it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▌| 490/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1004/1026 [02:08<00:02,  7.78it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▌| 492/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1006/1026 [02:09<00:02,  7.79it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  96%|█████████▋| 494/513 [00:28<00:01, 17.11it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1008/1026 [02:09<00:02,  7.80it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 496/513 [00:28<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1010/1026 [02:09<00:02,  7.81it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 498/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1012/1026 [02:09<00:01,  7.82it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 500/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1014/1026 [02:09<00:01,  7.83it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  98%|█████████▊| 502/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1016/1026 [02:09<00:01,  7.83it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  98%|█████████▊| 504/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1018/1026 [02:09<00:01,  7.84it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▊| 506/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1020/1026 [02:09<00:00,  7.85it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▉| 508/513 [00:29<00:00, 17.11it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1022/1026 [02:10<00:00,  7.86it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Validation DataLoader 0:  99%|█████████▉| 510/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1024/1026 [02:10<00:00,  7.87it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0: 100%|█████████▉| 512/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1: 100%|██████████| 1026/1026 [02:10<00:00,  7.88it/s, loss=0.569, v_num=0, train_loss=0.565, val_loss=0.583, val_score=0.699]\n",
      "Trial trainable_9a289_00000 reported val_score=0.73 with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 32, 'epochs': 2, 'n_fold': 2, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'distilbert-base-uncased'}.\n",
      "Epoch 1: 100%|██████████| 1026/1026 [02:10<00:00,  7.87it/s, loss=0.57, v_num=0, train_loss=0.572, val_loss=0.568, val_score=0.735] \n",
      "Epoch 1: 100%|██████████| 1026/1026 [02:10<00:00,  7.87it/s, loss=0.57, v_num=0, train_loss=0.572, val_loss=0.568, val_score=0.735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Epoch 1, global step 1026: 'val_loss' reached 0.56846 (best 0.56846), saving model to '/storagenfs/m.petix/hlt_usppm/src/checkpoints/best_checkpoint-v24.ckpt' as top 1\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m `Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1026/1026 [02:20<00:00,  7.31it/s, loss=0.57, v_num=0, train_loss=0.572, val_loss=0.568, val_score=0.735]\n",
      "Testing: 0it [00:00, ?it/s]0669)\u001b[0m \n",
      "Testing DataLoader 0:   2%|▏         | 2/114 [00:00<00:04, 27.39it/s]\n",
      "Testing DataLoader 0:   4%|▎         | 4/114 [00:00<00:05, 19.86it/s]\n",
      "Testing DataLoader 0:   5%|▌         | 6/114 [00:00<00:05, 18.59it/s]\n",
      "Testing DataLoader 0:   7%|▋         | 8/114 [00:00<00:05, 18.17it/s]\n",
      "Testing DataLoader 0:   9%|▉         | 10/114 [00:00<00:05, 17.91it/s]\n",
      "Testing DataLoader 0:  11%|█         | 12/114 [00:00<00:05, 17.77it/s]\n",
      "Testing DataLoader 0:  12%|█▏        | 14/114 [00:00<00:05, 17.68it/s]\n",
      "Testing DataLoader 0:  14%|█▍        | 16/114 [00:00<00:05, 17.60it/s]\n",
      "Testing DataLoader 0:  16%|█▌        | 18/114 [00:01<00:05, 17.54it/s]\n",
      "Testing DataLoader 0:  18%|█▊        | 20/114 [00:01<00:05, 17.50it/s]\n",
      "Testing DataLoader 0:  19%|█▉        | 22/114 [00:01<00:05, 17.45it/s]\n",
      "Testing DataLoader 0:  21%|██        | 24/114 [00:01<00:05, 17.42it/s]\n",
      "Testing DataLoader 0:  23%|██▎       | 26/114 [00:01<00:05, 17.39it/s]\n",
      "Testing DataLoader 0:  25%|██▍       | 28/114 [00:01<00:04, 17.37it/s]\n",
      "Testing DataLoader 0:  26%|██▋       | 30/114 [00:01<00:04, 17.35it/s]\n",
      "Testing DataLoader 0:  28%|██▊       | 32/114 [00:01<00:04, 17.33it/s]\n",
      "Testing DataLoader 0:  30%|██▉       | 34/114 [00:01<00:04, 17.32it/s]\n",
      "Testing DataLoader 0:  32%|███▏      | 36/114 [00:02<00:04, 17.30it/s]\n",
      "Testing DataLoader 0:  33%|███▎      | 38/114 [00:02<00:04, 17.29it/s]\n",
      "Testing DataLoader 0:  35%|███▌      | 40/114 [00:02<00:04, 17.28it/s]\n",
      "Testing DataLoader 0:  37%|███▋      | 42/114 [00:02<00:04, 17.27it/s]\n",
      "Testing DataLoader 0:  39%|███▊      | 44/114 [00:02<00:04, 17.26it/s]\n",
      "Testing DataLoader 0:  40%|████      | 46/114 [00:02<00:03, 17.25it/s]\n",
      "Testing DataLoader 0:  42%|████▏     | 48/114 [00:02<00:03, 17.24it/s]\n",
      "Testing DataLoader 0:  44%|████▍     | 50/114 [00:02<00:03, 17.23it/s]\n",
      "Testing DataLoader 0:  46%|████▌     | 52/114 [00:03<00:03, 17.23it/s]\n",
      "Testing DataLoader 0:  47%|████▋     | 54/114 [00:03<00:03, 17.22it/s]\n",
      "Testing DataLoader 0:  49%|████▉     | 56/114 [00:03<00:03, 17.22it/s]\n",
      "Testing DataLoader 0:  51%|█████     | 58/114 [00:03<00:03, 17.21it/s]\n",
      "Testing DataLoader 0:  53%|█████▎    | 60/114 [00:03<00:03, 17.21it/s]\n",
      "Testing DataLoader 0:  54%|█████▍    | 62/114 [00:03<00:03, 17.20it/s]\n",
      "Testing DataLoader 0:  56%|█████▌    | 64/114 [00:03<00:02, 17.20it/s]\n",
      "Testing DataLoader 0:  58%|█████▊    | 66/114 [00:03<00:02, 17.19it/s]\n",
      "Testing DataLoader 0:  60%|█████▉    | 68/114 [00:03<00:02, 17.19it/s]\n",
      "Testing DataLoader 0:  61%|██████▏   | 70/114 [00:04<00:02, 17.19it/s]\n",
      "Testing DataLoader 0:  63%|██████▎   | 72/114 [00:04<00:02, 17.19it/s]\n",
      "Testing DataLoader 0:  65%|██████▍   | 74/114 [00:04<00:02, 17.18it/s]\n",
      "Testing DataLoader 0:  67%|██████▋   | 76/114 [00:04<00:02, 17.18it/s]\n",
      "Testing DataLoader 0:  68%|██████▊   | 78/114 [00:04<00:02, 17.18it/s]\n",
      "Testing DataLoader 0:  70%|███████   | 80/114 [00:04<00:01, 17.18it/s]\n",
      "Testing DataLoader 0:  72%|███████▏  | 82/114 [00:04<00:01, 17.17it/s]\n",
      "Testing DataLoader 0:  74%|███████▎  | 84/114 [00:04<00:01, 17.17it/s]\n",
      "Testing DataLoader 0:  75%|███████▌  | 86/114 [00:05<00:01, 17.17it/s]\n",
      "Testing DataLoader 0:  77%|███████▋  | 88/114 [00:05<00:01, 17.17it/s]\n",
      "Testing DataLoader 0:  79%|███████▉  | 90/114 [00:05<00:01, 17.17it/s]\n",
      "Testing DataLoader 0:  81%|████████  | 92/114 [00:05<00:01, 17.16it/s]\n",
      "Testing DataLoader 0:  82%|████████▏ | 94/114 [00:05<00:01, 17.16it/s]\n",
      "Testing DataLoader 0:  84%|████████▍ | 96/114 [00:05<00:01, 17.16it/s]\n",
      "Testing DataLoader 0:  86%|████████▌ | 98/114 [00:05<00:00, 17.16it/s]\n",
      "Testing DataLoader 0:  88%|████████▊ | 100/114 [00:05<00:00, 17.16it/s]\n",
      "Testing DataLoader 0:  89%|████████▉ | 102/114 [00:05<00:00, 17.16it/s]\n",
      "Testing DataLoader 0:  91%|█████████ | 104/114 [00:06<00:00, 17.15it/s]\n",
      "Testing DataLoader 0:  93%|█████████▎| 106/114 [00:06<00:00, 17.15it/s]\n",
      "Testing DataLoader 0:  95%|█████████▍| 108/114 [00:06<00:00, 17.15it/s]\n",
      "Testing DataLoader 0:  96%|█████████▋| 110/114 [00:06<00:00, 17.15it/s]\n",
      "Testing DataLoader 0:  98%|█████████▊| 112/114 [00:06<00:00, 17.15it/s]\n",
      "Testing DataLoader 0: 100%|██████████| 114/114 [00:06<00:00, 17.15it/s]\n",
      "Testing DataLoader 0: 100%|██████████| 114/114 [00:06<00:00, 17.01it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m │         test_loss         │    0.5700275301933289     │\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m └───────────────────────────┴───────────────────────────┘\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m TEST for FOLD 1\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m STARTING FOLD 2\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m TRAIN FOLD 2 16413\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m VALID FOLD 2 16412\n",
      "Epoch 0:   0%|          | 0/1026 [00:00<?, ?it/s]                \n",
      "Epoch 0:   0%|          | 2/1026 [00:01<10:39,  1.60it/s, loss=0.574, v_num=0, train_loss=0.652, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   0%|          | 4/1026 [00:01<06:53,  2.47it/s, loss=0.584, v_num=0, train_loss=0.652, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   1%|          | 6/1026 [00:01<05:38,  3.02it/s, loss=0.589, v_num=0, train_loss=0.651, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   1%|          | 8/1026 [00:02<05:00,  3.39it/s, loss=0.599, v_num=0, train_loss=0.657, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   1%|          | 10/1026 [00:02<04:37,  3.66it/s, loss=0.608, v_num=0, train_loss=0.612, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   1%|          | 12/1026 [00:03<04:21,  3.87it/s, loss=0.614, v_num=0, train_loss=0.613, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   1%|▏         | 14/1026 [00:03<04:10,  4.03it/s, loss=0.622, v_num=0, train_loss=0.661, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   2%|▏         | 16/1026 [00:03<04:02,  4.17it/s, loss=0.631, v_num=0, train_loss=0.651, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   2%|▏         | 18/1026 [00:04<03:55,  4.27it/s, loss=0.643, v_num=0, train_loss=0.674, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   2%|▏         | 20/1026 [00:04<03:50,  4.36it/s, loss=0.65, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:   2%|▏         | 22/1026 [00:04<03:46,  4.44it/s, loss=0.649, v_num=0, train_loss=0.648, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   2%|▏         | 24/1026 [00:05<03:42,  4.51it/s, loss=0.655, v_num=0, train_loss=0.719, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   3%|▎         | 26/1026 [00:05<03:39,  4.57it/s, loss=0.653, v_num=0, train_loss=0.635, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   3%|▎         | 28/1026 [00:06<03:36,  4.62it/s, loss=0.652, v_num=0, train_loss=0.653, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   3%|▎         | 30/1026 [00:06<03:33,  4.66it/s, loss=0.653, v_num=0, train_loss=0.659, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   3%|▎         | 32/1026 [00:06<03:31,  4.70it/s, loss=0.656, v_num=0, train_loss=0.656, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   3%|▎         | 34/1026 [00:07<03:29,  4.74it/s, loss=0.66, v_num=0, train_loss=0.680, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:   4%|▎         | 36/1026 [00:07<03:27,  4.77it/s, loss=0.656, v_num=0, train_loss=0.652, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   4%|▎         | 38/1026 [00:07<03:26,  4.79it/s, loss=0.657, v_num=0, train_loss=0.692, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   4%|▍         | 40/1026 [00:08<03:24,  4.82it/s, loss=0.66, v_num=0, train_loss=0.641, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:   4%|▍         | 42/1026 [00:08<03:23,  4.84it/s, loss=0.658, v_num=0, train_loss=0.601, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   4%|▍         | 44/1026 [00:09<03:21,  4.86it/s, loss=0.655, v_num=0, train_loss=0.687, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   4%|▍         | 46/1026 [00:09<03:20,  4.88it/s, loss=0.655, v_num=0, train_loss=0.609, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   5%|▍         | 48/1026 [00:09<03:19,  4.90it/s, loss=0.658, v_num=0, train_loss=0.684, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   5%|▍         | 50/1026 [00:10<03:18,  4.92it/s, loss=0.658, v_num=0, train_loss=0.692, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   5%|▌         | 52/1026 [00:10<03:17,  4.93it/s, loss=0.66, v_num=0, train_loss=0.667, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:   5%|▌         | 54/1026 [00:10<03:16,  4.95it/s, loss=0.657, v_num=0, train_loss=0.655, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   5%|▌         | 56/1026 [00:11<03:15,  4.96it/s, loss=0.658, v_num=0, train_loss=0.667, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   6%|▌         | 58/1026 [00:11<03:14,  4.97it/s, loss=0.657, v_num=0, train_loss=0.687, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   6%|▌         | 60/1026 [00:12<03:13,  4.98it/s, loss=0.654, v_num=0, train_loss=0.646, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   6%|▌         | 62/1026 [00:12<03:13,  4.99it/s, loss=0.662, v_num=0, train_loss=0.651, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   6%|▌         | 64/1026 [00:12<03:12,  5.01it/s, loss=0.66, v_num=0, train_loss=0.683, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:   6%|▋         | 66/1026 [00:13<03:11,  5.02it/s, loss=0.662, v_num=0, train_loss=0.650, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   7%|▋         | 68/1026 [00:13<03:10,  5.02it/s, loss=0.659, v_num=0, train_loss=0.650, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   7%|▋         | 70/1026 [00:13<03:09,  5.03it/s, loss=0.658, v_num=0, train_loss=0.657, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   7%|▋         | 72/1026 [00:14<03:09,  5.04it/s, loss=0.662, v_num=0, train_loss=0.702, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   7%|▋         | 74/1026 [00:14<03:08,  5.05it/s, loss=0.661, v_num=0, train_loss=0.612, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   7%|▋         | 76/1026 [00:15<03:08,  5.05it/s, loss=0.663, v_num=0, train_loss=0.671, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   8%|▊         | 78/1026 [00:15<03:07,  5.05it/s, loss=0.663, v_num=0, train_loss=0.688, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   8%|▊         | 80/1026 [00:15<03:07,  5.06it/s, loss=0.666, v_num=0, train_loss=0.659, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   8%|▊         | 82/1026 [00:16<03:06,  5.06it/s, loss=0.66, v_num=0, train_loss=0.631, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:   8%|▊         | 84/1026 [00:16<03:05,  5.07it/s, loss=0.658, v_num=0, train_loss=0.642, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   8%|▊         | 86/1026 [00:16<03:05,  5.07it/s, loss=0.658, v_num=0, train_loss=0.651, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   9%|▊         | 88/1026 [00:17<03:04,  5.07it/s, loss=0.657, v_num=0, train_loss=0.650, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   9%|▉         | 90/1026 [00:17<03:04,  5.08it/s, loss=0.659, v_num=0, train_loss=0.662, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   9%|▉         | 92/1026 [00:18<03:03,  5.08it/s, loss=0.653, v_num=0, train_loss=0.650, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   9%|▉         | 94/1026 [00:18<03:03,  5.08it/s, loss=0.654, v_num=0, train_loss=0.681, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:   9%|▉         | 96/1026 [00:18<03:02,  5.09it/s, loss=0.653, v_num=0, train_loss=0.678, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  10%|▉         | 98/1026 [00:19<03:02,  5.09it/s, loss=0.654, v_num=0, train_loss=0.681, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  10%|▉         | 100/1026 [00:19<03:01,  5.09it/s, loss=0.653, v_num=0, train_loss=0.615, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  10%|▉         | 102/1026 [00:20<03:01,  5.09it/s, loss=0.654, v_num=0, train_loss=0.645, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  10%|█         | 104/1026 [00:20<03:00,  5.10it/s, loss=0.655, v_num=0, train_loss=0.641, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  10%|█         | 106/1026 [00:20<03:00,  5.10it/s, loss=0.658, v_num=0, train_loss=0.673, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  11%|█         | 108/1026 [00:21<03:00,  5.10it/s, loss=0.658, v_num=0, train_loss=0.669, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  11%|█         | 110/1026 [00:21<02:59,  5.10it/s, loss=0.658, v_num=0, train_loss=0.646, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  11%|█         | 112/1026 [00:21<02:59,  5.10it/s, loss=0.661, v_num=0, train_loss=0.674, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  11%|█         | 114/1026 [00:22<02:58,  5.11it/s, loss=0.663, v_num=0, train_loss=0.658, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  11%|█▏        | 116/1026 [00:22<02:58,  5.11it/s, loss=0.66, v_num=0, train_loss=0.638, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  12%|█▏        | 118/1026 [00:23<02:57,  5.11it/s, loss=0.658, v_num=0, train_loss=0.659, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  12%|█▏        | 120/1026 [00:23<02:57,  5.11it/s, loss=0.66, v_num=0, train_loss=0.685, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  12%|█▏        | 122/1026 [00:23<02:56,  5.11it/s, loss=0.661, v_num=0, train_loss=0.688, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  12%|█▏        | 124/1026 [00:24<02:56,  5.12it/s, loss=0.66, v_num=0, train_loss=0.660, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  12%|█▏        | 126/1026 [00:24<02:55,  5.12it/s, loss=0.658, v_num=0, train_loss=0.672, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  12%|█▏        | 128/1026 [00:25<02:55,  5.12it/s, loss=0.659, v_num=0, train_loss=0.649, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  13%|█▎        | 130/1026 [00:25<02:54,  5.12it/s, loss=0.657, v_num=0, train_loss=0.653, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  13%|█▎        | 132/1026 [00:25<02:54,  5.12it/s, loss=0.653, v_num=0, train_loss=0.614, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  13%|█▎        | 134/1026 [00:26<02:54,  5.12it/s, loss=0.653, v_num=0, train_loss=0.667, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  13%|█▎        | 136/1026 [00:26<02:53,  5.13it/s, loss=0.65, v_num=0, train_loss=0.616, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  13%|█▎        | 138/1026 [00:26<02:53,  5.13it/s, loss=0.655, v_num=0, train_loss=0.698, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  14%|█▎        | 140/1026 [00:27<02:52,  5.13it/s, loss=0.654, v_num=0, train_loss=0.635, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  14%|█▍        | 142/1026 [00:27<02:52,  5.13it/s, loss=0.655, v_num=0, train_loss=0.670, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  14%|█▍        | 144/1026 [00:28<02:51,  5.13it/s, loss=0.654, v_num=0, train_loss=0.607, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  14%|█▍        | 146/1026 [00:28<02:51,  5.13it/s, loss=0.651, v_num=0, train_loss=0.631, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  14%|█▍        | 148/1026 [00:28<02:51,  5.13it/s, loss=0.65, v_num=0, train_loss=0.594, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  15%|█▍        | 150/1026 [00:29<02:50,  5.13it/s, loss=0.651, v_num=0, train_loss=0.682, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  15%|█▍        | 152/1026 [00:29<02:50,  5.14it/s, loss=0.651, v_num=0, train_loss=0.621, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  15%|█▌        | 154/1026 [00:29<02:49,  5.14it/s, loss=0.65, v_num=0, train_loss=0.643, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  15%|█▌        | 156/1026 [00:30<02:49,  5.14it/s, loss=0.654, v_num=0, train_loss=0.647, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  15%|█▌        | 158/1026 [00:30<02:48,  5.14it/s, loss=0.653, v_num=0, train_loss=0.693, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  16%|█▌        | 160/1026 [00:31<02:48,  5.14it/s, loss=0.652, v_num=0, train_loss=0.647, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  16%|█▌        | 162/1026 [00:31<02:48,  5.14it/s, loss=0.649, v_num=0, train_loss=0.613, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  16%|█▌        | 164/1026 [00:31<02:47,  5.14it/s, loss=0.647, v_num=0, train_loss=0.608, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  16%|█▌        | 166/1026 [00:32<02:47,  5.14it/s, loss=0.648, v_num=0, train_loss=0.644, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  16%|█▋        | 168/1026 [00:32<02:46,  5.15it/s, loss=0.649, v_num=0, train_loss=0.644, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  17%|█▋        | 170/1026 [00:33<02:46,  5.15it/s, loss=0.65, v_num=0, train_loss=0.626, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  17%|█▋        | 172/1026 [00:33<02:45,  5.15it/s, loss=0.657, v_num=0, train_loss=0.675, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  17%|█▋        | 174/1026 [00:33<02:45,  5.15it/s, loss=0.653, v_num=0, train_loss=0.618, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  17%|█▋        | 176/1026 [00:34<02:45,  5.15it/s, loss=0.653, v_num=0, train_loss=0.643, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  17%|█▋        | 178/1026 [00:34<02:44,  5.15it/s, loss=0.65, v_num=0, train_loss=0.663, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  18%|█▊        | 180/1026 [00:34<02:44,  5.15it/s, loss=0.65, v_num=0, train_loss=0.645, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  18%|█▊        | 182/1026 [00:35<02:43,  5.15it/s, loss=0.648, v_num=0, train_loss=0.613, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  18%|█▊        | 184/1026 [00:35<02:43,  5.15it/s, loss=0.652, v_num=0, train_loss=0.667, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  18%|█▊        | 186/1026 [00:36<02:43,  5.15it/s, loss=0.656, v_num=0, train_loss=0.710, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  18%|█▊        | 188/1026 [00:36<02:42,  5.15it/s, loss=0.653, v_num=0, train_loss=0.609, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  19%|█▊        | 190/1026 [00:36<02:42,  5.15it/s, loss=0.652, v_num=0, train_loss=0.639, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  19%|█▊        | 192/1026 [00:37<02:41,  5.15it/s, loss=0.643, v_num=0, train_loss=0.610, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  19%|█▉        | 194/1026 [00:37<02:41,  5.15it/s, loss=0.646, v_num=0, train_loss=0.682, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  19%|█▉        | 196/1026 [00:38<02:40,  5.16it/s, loss=0.645, v_num=0, train_loss=0.612, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  19%|█▉        | 198/1026 [00:38<02:40,  5.15it/s, loss=0.641, v_num=0, train_loss=0.626, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  19%|█▉        | 200/1026 [00:38<02:40,  5.16it/s, loss=0.64, v_num=0, train_loss=0.662, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  20%|█▉        | 202/1026 [00:39<02:39,  5.16it/s, loss=0.641, v_num=0, train_loss=0.627, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  20%|█▉        | 204/1026 [00:39<02:39,  5.16it/s, loss=0.636, v_num=0, train_loss=0.623, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  20%|██        | 206/1026 [00:39<02:38,  5.16it/s, loss=0.636, v_num=0, train_loss=0.707, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  20%|██        | 208/1026 [00:40<02:38,  5.16it/s, loss=0.637, v_num=0, train_loss=0.589, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  20%|██        | 210/1026 [00:40<02:38,  5.16it/s, loss=0.637, v_num=0, train_loss=0.641, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  21%|██        | 212/1026 [00:41<02:37,  5.16it/s, loss=0.64, v_num=0, train_loss=0.664, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  21%|██        | 214/1026 [00:41<02:37,  5.16it/s, loss=0.641, v_num=0, train_loss=0.646, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  21%|██        | 216/1026 [00:41<02:36,  5.16it/s, loss=0.644, v_num=0, train_loss=0.660, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  21%|██        | 218/1026 [00:42<02:36,  5.16it/s, loss=0.646, v_num=0, train_loss=0.668, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  21%|██▏       | 220/1026 [00:42<02:36,  5.16it/s, loss=0.649, v_num=0, train_loss=0.657, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  22%|██▏       | 222/1026 [00:42<02:35,  5.16it/s, loss=0.651, v_num=0, train_loss=0.648, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  22%|██▏       | 224/1026 [00:43<02:35,  5.16it/s, loss=0.654, v_num=0, train_loss=0.646, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  22%|██▏       | 226/1026 [00:43<02:34,  5.16it/s, loss=0.649, v_num=0, train_loss=0.639, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  22%|██▏       | 228/1026 [00:44<02:34,  5.16it/s, loss=0.651, v_num=0, train_loss=0.670, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  22%|██▏       | 230/1026 [00:44<02:34,  5.16it/s, loss=0.651, v_num=0, train_loss=0.639, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  23%|██▎       | 232/1026 [00:44<02:33,  5.17it/s, loss=0.653, v_num=0, train_loss=0.669, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  23%|██▎       | 234/1026 [00:45<02:33,  5.17it/s, loss=0.652, v_num=0, train_loss=0.655, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  23%|██▎       | 236/1026 [00:45<02:32,  5.17it/s, loss=0.647, v_num=0, train_loss=0.628, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  23%|██▎       | 238/1026 [00:46<02:32,  5.17it/s, loss=0.644, v_num=0, train_loss=0.603, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  23%|██▎       | 240/1026 [00:46<02:32,  5.17it/s, loss=0.641, v_num=0, train_loss=0.625, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  24%|██▎       | 242/1026 [00:46<02:31,  5.17it/s, loss=0.64, v_num=0, train_loss=0.625, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  24%|██▍       | 244/1026 [00:47<02:31,  5.17it/s, loss=0.637, v_num=0, train_loss=0.628, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  24%|██▍       | 246/1026 [00:47<02:30,  5.17it/s, loss=0.644, v_num=0, train_loss=0.708, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  24%|██▍       | 248/1026 [00:47<02:30,  5.17it/s, loss=0.646, v_num=0, train_loss=0.656, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  24%|██▍       | 250/1026 [00:48<02:30,  5.17it/s, loss=0.648, v_num=0, train_loss=0.644, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  25%|██▍       | 252/1026 [00:48<02:29,  5.17it/s, loss=0.645, v_num=0, train_loss=0.650, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  25%|██▍       | 254/1026 [00:49<02:29,  5.17it/s, loss=0.646, v_num=0, train_loss=0.655, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  25%|██▍       | 256/1026 [00:49<02:28,  5.17it/s, loss=0.65, v_num=0, train_loss=0.658, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  25%|██▌       | 258/1026 [00:49<02:28,  5.17it/s, loss=0.652, v_num=0, train_loss=0.630, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  25%|██▌       | 260/1026 [00:50<02:28,  5.17it/s, loss=0.651, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  26%|██▌       | 262/1026 [00:50<02:27,  5.17it/s, loss=0.652, v_num=0, train_loss=0.650, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  26%|██▌       | 264/1026 [00:51<02:27,  5.17it/s, loss=0.656, v_num=0, train_loss=0.648, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  26%|██▌       | 266/1026 [00:51<02:26,  5.17it/s, loss=0.654, v_num=0, train_loss=0.681, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  26%|██▌       | 268/1026 [00:51<02:26,  5.18it/s, loss=0.652, v_num=0, train_loss=0.644, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  26%|██▋       | 270/1026 [00:52<02:26,  5.18it/s, loss=0.651, v_num=0, train_loss=0.648, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  27%|██▋       | 272/1026 [00:52<02:25,  5.18it/s, loss=0.651, v_num=0, train_loss=0.659, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  27%|██▋       | 274/1026 [00:52<02:25,  5.18it/s, loss=0.651, v_num=0, train_loss=0.651, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  27%|██▋       | 276/1026 [00:53<02:24,  5.18it/s, loss=0.651, v_num=0, train_loss=0.671, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  27%|██▋       | 278/1026 [00:53<02:24,  5.18it/s, loss=0.654, v_num=0, train_loss=0.634, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  27%|██▋       | 280/1026 [00:54<02:24,  5.18it/s, loss=0.657, v_num=0, train_loss=0.654, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  27%|██▋       | 282/1026 [00:54<02:23,  5.18it/s, loss=0.658, v_num=0, train_loss=0.645, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  28%|██▊       | 284/1026 [00:54<02:23,  5.18it/s, loss=0.658, v_num=0, train_loss=0.683, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  28%|██▊       | 286/1026 [00:55<02:22,  5.18it/s, loss=0.652, v_num=0, train_loss=0.606, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  28%|██▊       | 288/1026 [00:55<02:22,  5.18it/s, loss=0.651, v_num=0, train_loss=0.616, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  28%|██▊       | 290/1026 [00:56<02:22,  5.18it/s, loss=0.65, v_num=0, train_loss=0.615, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  28%|██▊       | 292/1026 [00:56<02:21,  5.18it/s, loss=0.649, v_num=0, train_loss=0.619, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  29%|██▊       | 294/1026 [00:56<02:21,  5.18it/s, loss=0.648, v_num=0, train_loss=0.615, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  29%|██▉       | 296/1026 [00:57<02:20,  5.18it/s, loss=0.648, v_num=0, train_loss=0.680, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  29%|██▉       | 298/1026 [00:57<02:20,  5.18it/s, loss=0.648, v_num=0, train_loss=0.649, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  29%|██▉       | 300/1026 [00:57<02:20,  5.18it/s, loss=0.647, v_num=0, train_loss=0.654, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  29%|██▉       | 302/1026 [00:58<02:19,  5.18it/s, loss=0.647, v_num=0, train_loss=0.664, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  30%|██▉       | 304/1026 [00:58<02:19,  5.18it/s, loss=0.645, v_num=0, train_loss=0.616, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  30%|██▉       | 306/1026 [00:59<02:18,  5.18it/s, loss=0.648, v_num=0, train_loss=0.652, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  30%|███       | 308/1026 [00:59<02:18,  5.18it/s, loss=0.651, v_num=0, train_loss=0.653, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  30%|███       | 310/1026 [00:59<02:18,  5.18it/s, loss=0.651, v_num=0, train_loss=0.643, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  30%|███       | 312/1026 [01:00<02:17,  5.18it/s, loss=0.652, v_num=0, train_loss=0.653, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  31%|███       | 314/1026 [01:00<02:17,  5.18it/s, loss=0.651, v_num=0, train_loss=0.633, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  31%|███       | 316/1026 [01:00<02:16,  5.18it/s, loss=0.65, v_num=0, train_loss=0.635, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  31%|███       | 318/1026 [01:01<02:16,  5.18it/s, loss=0.644, v_num=0, train_loss=0.580, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  31%|███       | 320/1026 [01:01<02:16,  5.18it/s, loss=0.642, v_num=0, train_loss=0.610, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  31%|███▏      | 322/1026 [01:02<02:15,  5.18it/s, loss=0.641, v_num=0, train_loss=0.635, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  32%|███▏      | 324/1026 [01:02<02:15,  5.18it/s, loss=0.64, v_num=0, train_loss=0.604, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  32%|███▏      | 326/1026 [01:02<02:15,  5.18it/s, loss=0.637, v_num=0, train_loss=0.622, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  32%|███▏      | 328/1026 [01:03<02:14,  5.18it/s, loss=0.634, v_num=0, train_loss=0.606, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  32%|███▏      | 330/1026 [01:03<02:14,  5.18it/s, loss=0.633, v_num=0, train_loss=0.626, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  32%|███▏      | 332/1026 [01:04<02:13,  5.18it/s, loss=0.634, v_num=0, train_loss=0.666, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  33%|███▎      | 334/1026 [01:04<02:13,  5.19it/s, loss=0.636, v_num=0, train_loss=0.701, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  33%|███▎      | 336/1026 [01:04<02:13,  5.18it/s, loss=0.635, v_num=0, train_loss=0.639, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  33%|███▎      | 338/1026 [01:05<02:12,  5.19it/s, loss=0.636, v_num=0, train_loss=0.627, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  33%|███▎      | 340/1026 [01:05<02:12,  5.19it/s, loss=0.635, v_num=0, train_loss=0.609, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  33%|███▎      | 342/1026 [01:05<02:11,  5.19it/s, loss=0.633, v_num=0, train_loss=0.626, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  34%|███▎      | 344/1026 [01:06<02:11,  5.19it/s, loss=0.636, v_num=0, train_loss=0.615, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  34%|███▎      | 346/1026 [01:06<02:11,  5.19it/s, loss=0.638, v_num=0, train_loss=0.647, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  34%|███▍      | 348/1026 [01:07<02:10,  5.19it/s, loss=0.64, v_num=0, train_loss=0.636, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  34%|███▍      | 350/1026 [01:07<02:10,  5.19it/s, loss=0.643, v_num=0, train_loss=0.703, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  34%|███▍      | 352/1026 [01:07<02:09,  5.19it/s, loss=0.642, v_num=0, train_loss=0.636, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  35%|███▍      | 354/1026 [01:08<02:09,  5.19it/s, loss=0.642, v_num=0, train_loss=0.684, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  35%|███▍      | 356/1026 [01:08<02:09,  5.19it/s, loss=0.645, v_num=0, train_loss=0.661, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  35%|███▍      | 358/1026 [01:09<02:08,  5.19it/s, loss=0.65, v_num=0, train_loss=0.644, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  35%|███▌      | 360/1026 [01:09<02:08,  5.19it/s, loss=0.653, v_num=0, train_loss=0.622, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  35%|███▌      | 362/1026 [01:09<02:07,  5.19it/s, loss=0.653, v_num=0, train_loss=0.637, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  35%|███▌      | 364/1026 [01:10<02:07,  5.19it/s, loss=0.648, v_num=0, train_loss=0.584, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  36%|███▌      | 366/1026 [01:10<02:07,  5.19it/s, loss=0.65, v_num=0, train_loss=0.688, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  36%|███▌      | 368/1026 [01:10<02:06,  5.19it/s, loss=0.646, v_num=0, train_loss=0.598, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  36%|███▌      | 370/1026 [01:11<02:06,  5.19it/s, loss=0.645, v_num=0, train_loss=0.679, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  36%|███▋      | 372/1026 [01:11<02:06,  5.19it/s, loss=0.643, v_num=0, train_loss=0.630, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  36%|███▋      | 374/1026 [01:12<02:05,  5.19it/s, loss=0.64, v_num=0, train_loss=0.648, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  37%|███▋      | 376/1026 [01:12<02:05,  5.19it/s, loss=0.637, v_num=0, train_loss=0.663, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  37%|███▋      | 378/1026 [01:12<02:04,  5.19it/s, loss=0.634, v_num=0, train_loss=0.671, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  37%|███▋      | 380/1026 [01:13<02:04,  5.19it/s, loss=0.629, v_num=0, train_loss=0.635, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  37%|███▋      | 382/1026 [01:13<02:04,  5.19it/s, loss=0.633, v_num=0, train_loss=0.672, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  37%|███▋      | 384/1026 [01:13<02:03,  5.19it/s, loss=0.631, v_num=0, train_loss=0.588, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  38%|███▊      | 386/1026 [01:14<02:03,  5.19it/s, loss=0.628, v_num=0, train_loss=0.630, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  38%|███▊      | 388/1026 [01:14<02:02,  5.19it/s, loss=0.633, v_num=0, train_loss=0.641, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  38%|███▊      | 390/1026 [01:15<02:02,  5.19it/s, loss=0.632, v_num=0, train_loss=0.633, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  38%|███▊      | 392/1026 [01:15<02:02,  5.19it/s, loss=0.632, v_num=0, train_loss=0.665, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  38%|███▊      | 394/1026 [01:15<02:01,  5.19it/s, loss=0.632, v_num=0, train_loss=0.620, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  39%|███▊      | 396/1026 [01:16<02:01,  5.19it/s, loss=0.633, v_num=0, train_loss=0.637, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  39%|███▉      | 398/1026 [01:16<02:00,  5.19it/s, loss=0.633, v_num=0, train_loss=0.623, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  39%|███▉      | 400/1026 [01:17<02:00,  5.19it/s, loss=0.639, v_num=0, train_loss=0.618, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  39%|███▉      | 402/1026 [01:17<02:00,  5.19it/s, loss=0.632, v_num=0, train_loss=0.583, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  39%|███▉      | 404/1026 [01:17<01:59,  5.19it/s, loss=0.632, v_num=0, train_loss=0.605, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  40%|███▉      | 406/1026 [01:18<01:59,  5.19it/s, loss=0.633, v_num=0, train_loss=0.598, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  40%|███▉      | 408/1026 [01:18<01:59,  5.19it/s, loss=0.63, v_num=0, train_loss=0.657, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  40%|███▉      | 410/1026 [01:18<01:58,  5.19it/s, loss=0.632, v_num=0, train_loss=0.649, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  40%|████      | 412/1026 [01:19<01:58,  5.19it/s, loss=0.631, v_num=0, train_loss=0.592, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  40%|████      | 414/1026 [01:19<01:57,  5.19it/s, loss=0.628, v_num=0, train_loss=0.616, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  41%|████      | 416/1026 [01:20<01:57,  5.19it/s, loss=0.624, v_num=0, train_loss=0.613, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  41%|████      | 418/1026 [01:20<01:57,  5.19it/s, loss=0.625, v_num=0, train_loss=0.682, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  41%|████      | 420/1026 [01:20<01:56,  5.19it/s, loss=0.621, v_num=0, train_loss=0.607, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  41%|████      | 422/1026 [01:21<01:56,  5.19it/s, loss=0.626, v_num=0, train_loss=0.682, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  41%|████▏     | 424/1026 [01:21<01:55,  5.19it/s, loss=0.632, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  42%|████▏     | 426/1026 [01:22<01:55,  5.19it/s, loss=0.628, v_num=0, train_loss=0.582, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  42%|████▏     | 428/1026 [01:22<01:55,  5.19it/s, loss=0.628, v_num=0, train_loss=0.623, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  42%|████▏     | 430/1026 [01:22<01:54,  5.19it/s, loss=0.625, v_num=0, train_loss=0.619, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  42%|████▏     | 432/1026 [01:23<01:54,  5.19it/s, loss=0.627, v_num=0, train_loss=0.646, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  42%|████▏     | 434/1026 [01:23<01:53,  5.19it/s, loss=0.627, v_num=0, train_loss=0.605, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  42%|████▏     | 436/1026 [01:23<01:53,  5.19it/s, loss=0.629, v_num=0, train_loss=0.599, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  43%|████▎     | 438/1026 [01:24<01:53,  5.19it/s, loss=0.629, v_num=0, train_loss=0.615, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  43%|████▎     | 440/1026 [01:24<01:52,  5.20it/s, loss=0.628, v_num=0, train_loss=0.604, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  43%|████▎     | 442/1026 [01:25<01:52,  5.20it/s, loss=0.629, v_num=0, train_loss=0.607, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  43%|████▎     | 444/1026 [01:25<01:52,  5.20it/s, loss=0.626, v_num=0, train_loss=0.665, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  43%|████▎     | 446/1026 [01:25<01:51,  5.20it/s, loss=0.628, v_num=0, train_loss=0.619, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  44%|████▎     | 448/1026 [01:26<01:51,  5.20it/s, loss=0.629, v_num=0, train_loss=0.641, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  44%|████▍     | 450/1026 [01:26<01:50,  5.20it/s, loss=0.635, v_num=0, train_loss=0.656, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  44%|████▍     | 452/1026 [01:26<01:50,  5.20it/s, loss=0.632, v_num=0, train_loss=0.581, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  44%|████▍     | 454/1026 [01:27<01:50,  5.20it/s, loss=0.635, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  44%|████▍     | 456/1026 [01:27<01:49,  5.20it/s, loss=0.633, v_num=0, train_loss=0.595, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  45%|████▍     | 458/1026 [01:28<01:49,  5.20it/s, loss=0.633, v_num=0, train_loss=0.652, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  45%|████▍     | 460/1026 [01:28<01:48,  5.20it/s, loss=0.632, v_num=0, train_loss=0.591, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  45%|████▌     | 462/1026 [01:28<01:48,  5.20it/s, loss=0.628, v_num=0, train_loss=0.609, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  45%|████▌     | 464/1026 [01:29<01:48,  5.20it/s, loss=0.629, v_num=0, train_loss=0.647, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  45%|████▌     | 466/1026 [01:29<01:47,  5.20it/s, loss=0.628, v_num=0, train_loss=0.617, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  46%|████▌     | 468/1026 [01:30<01:47,  5.20it/s, loss=0.63, v_num=0, train_loss=0.634, val_loss=0.568, val_score=0.735, test_loss=0.570] \n",
      "Epoch 0:  46%|████▌     | 470/1026 [01:30<01:46,  5.20it/s, loss=0.622, v_num=0, train_loss=0.551, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  46%|████▌     | 472/1026 [01:30<01:46,  5.20it/s, loss=0.623, v_num=0, train_loss=0.619, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  46%|████▌     | 474/1026 [01:31<01:46,  5.20it/s, loss=0.624, v_num=0, train_loss=0.644, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  46%|████▋     | 476/1026 [01:31<01:45,  5.20it/s, loss=0.627, v_num=0, train_loss=0.612, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  47%|████▋     | 478/1026 [01:31<01:45,  5.20it/s, loss=0.628, v_num=0, train_loss=0.657, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  47%|████▋     | 480/1026 [01:32<01:45,  5.20it/s, loss=0.634, v_num=0, train_loss=0.671, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  47%|████▋     | 482/1026 [01:32<01:44,  5.20it/s, loss=0.635, v_num=0, train_loss=0.601, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  47%|████▋     | 484/1026 [01:33<01:44,  5.20it/s, loss=0.634, v_num=0, train_loss=0.655, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  47%|████▋     | 486/1026 [01:33<01:43,  5.20it/s, loss=0.636, v_num=0, train_loss=0.672, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  48%|████▊     | 488/1026 [01:33<01:43,  5.20it/s, loss=0.633, v_num=0, train_loss=0.658, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  48%|████▊     | 490/1026 [01:34<01:43,  5.20it/s, loss=0.635, v_num=0, train_loss=0.631, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  48%|████▊     | 492/1026 [01:34<01:42,  5.20it/s, loss=0.636, v_num=0, train_loss=0.602, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  48%|████▊     | 494/1026 [01:35<01:42,  5.20it/s, loss=0.632, v_num=0, train_loss=0.614, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  48%|████▊     | 496/1026 [01:35<01:41,  5.20it/s, loss=0.632, v_num=0, train_loss=0.626, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  49%|████▊     | 498/1026 [01:35<01:41,  5.20it/s, loss=0.629, v_num=0, train_loss=0.582, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  49%|████▊     | 500/1026 [01:36<01:41,  5.20it/s, loss=0.629, v_num=0, train_loss=0.652, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  49%|████▉     | 502/1026 [01:36<01:40,  5.20it/s, loss=0.628, v_num=0, train_loss=0.661, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  49%|████▉     | 504/1026 [01:36<01:40,  5.20it/s, loss=0.626, v_num=0, train_loss=0.637, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  49%|████▉     | 506/1026 [01:37<01:40,  5.20it/s, loss=0.629, v_num=0, train_loss=0.653, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  50%|████▉     | 508/1026 [01:37<01:39,  5.20it/s, loss=0.628, v_num=0, train_loss=0.629, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  50%|████▉     | 510/1026 [01:38<01:39,  5.20it/s, loss=0.627, v_num=0, train_loss=0.631, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Epoch 0:  50%|████▉     | 512/1026 [01:38<01:38,  5.20it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[0m \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation:   0%|          | 0/513 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 514/1026 [01:39<01:39,  5.16it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  50%|█████     | 516/1026 [01:39<01:38,  5.17it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  50%|█████     | 518/1026 [01:39<01:37,  5.19it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  51%|█████     | 520/1026 [01:39<01:37,  5.20it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  51%|█████     | 522/1026 [01:40<01:36,  5.22it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  51%|█████     | 524/1026 [01:40<01:36,  5.23it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  51%|█████▏    | 526/1026 [01:40<01:35,  5.24it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  51%|█████▏    | 528/1026 [01:40<01:34,  5.26it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  52%|█████▏    | 530/1026 [01:40<01:34,  5.27it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  52%|█████▏    | 532/1026 [01:40<01:33,  5.28it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  52%|█████▏    | 534/1026 [01:40<01:32,  5.30it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  52%|█████▏    | 536/1026 [01:40<01:32,  5.31it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  52%|█████▏    | 538/1026 [01:41<01:31,  5.33it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  53%|█████▎    | 540/1026 [01:41<01:31,  5.34it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  53%|█████▎    | 542/1026 [01:41<01:30,  5.35it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  53%|█████▎    | 544/1026 [01:41<01:29,  5.37it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  53%|█████▎    | 546/1026 [01:41<01:29,  5.38it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   7%|▋         | 34/513 [00:01<00:27, 17.52it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 548/1026 [01:41<01:28,  5.39it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   7%|▋         | 36/513 [00:02<00:27, 17.50it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▎    | 550/1026 [01:41<01:28,  5.41it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  54%|█████▍    | 552/1026 [01:41<01:27,  5.42it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   8%|▊         | 40/513 [00:02<00:27, 17.46it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 554/1026 [01:41<01:26,  5.43it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   8%|▊         | 42/513 [00:02<00:27, 17.44it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 556/1026 [01:42<01:26,  5.45it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   9%|▊         | 44/513 [00:02<00:26, 17.43it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 558/1026 [01:42<01:25,  5.46it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  55%|█████▍    | 560/1026 [01:42<01:25,  5.47it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   9%|▉         | 48/513 [00:02<00:26, 17.40it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 562/1026 [01:42<01:24,  5.49it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  10%|▉         | 50/513 [00:02<00:26, 17.39it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 564/1026 [01:42<01:24,  5.50it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  10%|█         | 52/513 [00:02<00:26, 17.37it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▌    | 566/1026 [01:42<01:23,  5.51it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  55%|█████▌    | 568/1026 [01:42<01:22,  5.53it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  11%|█         | 56/513 [00:03<00:26, 17.35it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 570/1026 [01:42<01:22,  5.54it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  11%|█▏        | 58/513 [00:03<00:26, 17.34it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 572/1026 [01:43<01:21,  5.55it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  56%|█████▌    | 574/1026 [01:43<01:21,  5.57it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  12%|█▏        | 62/513 [00:03<00:26, 17.33it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 576/1026 [01:43<01:20,  5.58it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  56%|█████▋    | 578/1026 [01:43<01:20,  5.59it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  13%|█▎        | 66/513 [00:03<00:25, 17.31it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 580/1026 [01:43<01:19,  5.60it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  13%|█▎        | 68/513 [00:03<00:25, 17.31it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 582/1026 [01:43<01:19,  5.62it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  14%|█▎        | 70/513 [00:04<00:25, 17.30it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 584/1026 [01:43<01:18,  5.63it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  14%|█▍        | 72/513 [00:04<00:25, 17.29it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 586/1026 [01:43<01:17,  5.64it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  14%|█▍        | 74/513 [00:04<00:25, 17.29it/s]\u001b[A\n",
      "Epoch 0:  57%|█████▋    | 588/1026 [01:43<01:17,  5.66it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  58%|█████▊    | 590/1026 [01:44<01:16,  5.67it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  15%|█▌        | 78/513 [00:04<00:25, 17.28it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 592/1026 [01:44<01:16,  5.68it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  16%|█▌        | 80/513 [00:04<00:25, 17.27it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 594/1026 [01:44<01:15,  5.69it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  58%|█████▊    | 596/1026 [01:44<01:15,  5.71it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  16%|█▋        | 84/513 [00:04<00:24, 17.26it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 598/1026 [01:44<01:14,  5.72it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  17%|█▋        | 86/513 [00:04<00:24, 17.26it/s]\u001b[A\n",
      "Epoch 0:  58%|█████▊    | 600/1026 [01:44<01:14,  5.73it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  17%|█▋        | 88/513 [00:05<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▊    | 602/1026 [01:44<01:13,  5.75it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  18%|█▊        | 90/513 [00:05<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 604/1026 [01:44<01:13,  5.76it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  18%|█▊        | 92/513 [00:05<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 606/1026 [01:45<01:12,  5.77it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  59%|█████▉    | 608/1026 [01:45<01:12,  5.78it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  19%|█▊        | 96/513 [00:05<00:24, 17.24it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 610/1026 [01:45<01:11,  5.80it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  19%|█▉        | 98/513 [00:05<00:24, 17.24it/s]\u001b[A\n",
      "Epoch 0:  60%|█████▉    | 612/1026 [01:45<01:11,  5.81it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  60%|█████▉    | 614/1026 [01:45<01:10,  5.82it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  20%|█▉        | 102/513 [00:05<00:23, 17.23it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 616/1026 [01:45<01:10,  5.83it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  20%|██        | 104/513 [00:06<00:23, 17.23it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 618/1026 [01:45<01:09,  5.85it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██        | 106/513 [00:06<00:23, 17.23it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 620/1026 [01:45<01:09,  5.86it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  61%|██████    | 622/1026 [01:45<01:08,  5.87it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  21%|██▏       | 110/513 [00:06<00:23, 17.22it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 624/1026 [01:46<01:08,  5.88it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  22%|██▏       | 112/513 [00:06<00:23, 17.22it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 626/1026 [01:46<01:07,  5.90it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  61%|██████    | 628/1026 [01:46<01:07,  5.91it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 116/513 [00:06<00:23, 17.21it/s]\u001b[A\n",
      "Epoch 0:  61%|██████▏   | 630/1026 [01:46<01:06,  5.92it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  23%|██▎       | 118/513 [00:06<00:22, 17.21it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 632/1026 [01:46<01:06,  5.93it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  62%|██████▏   | 634/1026 [01:46<01:05,  5.94it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  24%|██▍       | 122/513 [00:07<00:22, 17.21it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 636/1026 [01:46<01:05,  5.96it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  24%|██▍       | 124/513 [00:07<00:22, 17.21it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 638/1026 [01:46<01:04,  5.97it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  62%|██████▏   | 640/1026 [01:46<01:04,  5.98it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▍       | 128/513 [00:07<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 642/1026 [01:47<01:04,  5.99it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▌       | 130/513 [00:07<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 644/1026 [01:47<01:03,  6.01it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  26%|██▌       | 132/513 [00:07<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 646/1026 [01:47<01:03,  6.02it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  63%|██████▎   | 648/1026 [01:47<01:02,  6.03it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 136/513 [00:07<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 650/1026 [01:47<01:02,  6.04it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 138/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▎   | 652/1026 [01:47<01:01,  6.05it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  27%|██▋       | 140/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▎   | 654/1026 [01:47<01:01,  6.07it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  28%|██▊       | 142/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 656/1026 [01:47<01:00,  6.08it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  64%|██████▍   | 658/1026 [01:48<01:00,  6.09it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  28%|██▊       | 146/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 660/1026 [01:48<00:59,  6.10it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  65%|██████▍   | 662/1026 [01:48<00:59,  6.11it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  65%|██████▍   | 664/1026 [01:48<00:59,  6.13it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  30%|██▉       | 152/513 [00:08<00:21, 17.18it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 666/1026 [01:48<00:58,  6.14it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  65%|██████▌   | 668/1026 [01:48<00:58,  6.15it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  30%|███       | 156/513 [00:09<00:20, 17.18it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▌   | 670/1026 [01:48<00:57,  6.16it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  31%|███       | 158/513 [00:09<00:20, 17.18it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▌   | 672/1026 [01:48<00:57,  6.17it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  31%|███       | 160/513 [00:09<00:20, 17.18it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 674/1026 [01:48<00:56,  6.18it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  32%|███▏      | 162/513 [00:09<00:20, 17.18it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 676/1026 [01:49<00:56,  6.20it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  32%|███▏      | 164/513 [00:09<00:20, 17.18it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▌   | 678/1026 [01:49<00:56,  6.21it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  66%|██████▋   | 680/1026 [01:49<00:55,  6.22it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  33%|███▎      | 168/513 [00:09<00:20, 17.18it/s]\u001b[A\n",
      "Epoch 0:  66%|██████▋   | 682/1026 [01:49<00:55,  6.23it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  67%|██████▋   | 684/1026 [01:49<00:54,  6.24it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  34%|███▎      | 172/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 686/1026 [01:49<00:54,  6.25it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  34%|███▍      | 174/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 688/1026 [01:49<00:53,  6.27it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  34%|███▍      | 176/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 690/1026 [01:49<00:53,  6.28it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  67%|██████▋   | 692/1026 [01:50<00:53,  6.29it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  68%|██████▊   | 694/1026 [01:50<00:52,  6.30it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  68%|██████▊   | 696/1026 [01:50<00:52,  6.31it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  36%|███▌      | 184/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 698/1026 [01:50<00:51,  6.32it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  36%|███▋      | 186/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 700/1026 [01:50<00:51,  6.33it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 188/513 [00:10<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 702/1026 [01:50<00:51,  6.35it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  69%|██████▊   | 704/1026 [01:50<00:50,  6.36it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  37%|███▋      | 192/513 [00:11<00:18, 17.16it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 706/1026 [01:50<00:50,  6.37it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  38%|███▊      | 194/513 [00:11<00:18, 17.16it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 708/1026 [01:50<00:49,  6.38it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  69%|██████▉   | 710/1026 [01:51<00:49,  6.39it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▊      | 198/513 [00:11<00:18, 17.16it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 712/1026 [01:51<00:49,  6.40it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  39%|███▉      | 200/513 [00:11<00:18, 17.16it/s]\u001b[A\n",
      "Epoch 0:  70%|██████▉   | 714/1026 [01:51<00:48,  6.41it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  70%|██████▉   | 716/1026 [01:51<00:48,  6.42it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  40%|███▉      | 204/513 [00:11<00:18, 17.16it/s]\u001b[A\n",
      "Epoch 0:  70%|██████▉   | 718/1026 [01:51<00:47,  6.44it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  70%|███████   | 720/1026 [01:51<00:47,  6.45it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  41%|████      | 208/513 [00:12<00:17, 17.16it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 722/1026 [01:51<00:47,  6.46it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  41%|████      | 210/513 [00:12<00:17, 17.16it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 724/1026 [01:51<00:46,  6.47it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  71%|███████   | 726/1026 [01:52<00:46,  6.48it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  42%|████▏     | 214/513 [00:12<00:17, 17.16it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 728/1026 [01:52<00:45,  6.49it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  42%|████▏     | 216/513 [00:12<00:17, 17.16it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 730/1026 [01:52<00:45,  6.50it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  71%|███████▏  | 732/1026 [01:52<00:45,  6.51it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  43%|████▎     | 220/513 [00:12<00:17, 17.15it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 734/1026 [01:52<00:44,  6.52it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  43%|████▎     | 222/513 [00:12<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 736/1026 [01:52<00:44,  6.54it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  72%|███████▏  | 738/1026 [01:52<00:43,  6.55it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  44%|████▍     | 226/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 740/1026 [01:52<00:43,  6.56it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  44%|████▍     | 228/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 742/1026 [01:52<00:43,  6.57it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  73%|███████▎  | 744/1026 [01:53<00:42,  6.58it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  45%|████▌     | 232/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 746/1026 [01:53<00:42,  6.59it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  46%|████▌     | 234/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 748/1026 [01:53<00:42,  6.60it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  73%|███████▎  | 750/1026 [01:53<00:41,  6.61it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  46%|████▋     | 238/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 752/1026 [01:53<00:41,  6.62it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  47%|████▋     | 240/513 [00:13<00:15, 17.15it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 754/1026 [01:53<00:41,  6.63it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  74%|███████▎  | 756/1026 [01:53<00:40,  6.64it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 244/513 [00:14<00:15, 17.15it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 758/1026 [01:53<00:40,  6.65it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 246/513 [00:14<00:15, 17.15it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 760/1026 [01:54<00:39,  6.67it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  48%|████▊     | 248/513 [00:14<00:15, 17.15it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 762/1026 [01:54<00:39,  6.68it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  74%|███████▍  | 764/1026 [01:54<00:39,  6.69it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  49%|████▉     | 252/513 [00:14<00:15, 17.14it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▍  | 766/1026 [01:54<00:38,  6.70it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  75%|███████▍  | 768/1026 [01:54<00:38,  6.71it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  50%|████▉     | 256/513 [00:14<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▌  | 770/1026 [01:54<00:38,  6.72it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  50%|█████     | 258/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▌  | 772/1026 [01:54<00:37,  6.73it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  75%|███████▌  | 774/1026 [01:54<00:37,  6.74it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  76%|███████▌  | 776/1026 [01:54<00:37,  6.75it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  51%|█████▏    | 264/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 778/1026 [01:55<00:36,  6.76it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  52%|█████▏    | 266/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 780/1026 [01:55<00:36,  6.77it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  52%|█████▏    | 268/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▌  | 782/1026 [01:55<00:35,  6.78it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  53%|█████▎    | 270/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  76%|███████▋  | 784/1026 [01:55<00:35,  6.79it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  53%|█████▎    | 272/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 786/1026 [01:55<00:35,  6.80it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  77%|███████▋  | 788/1026 [01:55<00:34,  6.81it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  54%|█████▍    | 276/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 790/1026 [01:55<00:34,  6.82it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  54%|█████▍    | 278/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 792/1026 [01:55<00:34,  6.83it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▍    | 280/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 794/1026 [01:56<00:33,  6.84it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▍    | 282/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 796/1026 [01:56<00:33,  6.85it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▌    | 284/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 798/1026 [01:56<00:33,  6.86it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  78%|███████▊  | 800/1026 [01:56<00:32,  6.88it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  56%|█████▌    | 288/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 802/1026 [01:56<00:32,  6.89it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 290/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 804/1026 [01:56<00:32,  6.90it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 292/513 [00:17<00:12, 17.14it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▊  | 806/1026 [01:56<00:31,  6.91it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  57%|█████▋    | 294/513 [00:17<00:12, 17.14it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 808/1026 [01:56<00:31,  6.92it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 296/513 [00:17<00:12, 17.14it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 810/1026 [01:56<00:31,  6.93it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 298/513 [00:17<00:12, 17.14it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 812/1026 [01:57<00:30,  6.94it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  58%|█████▊    | 300/513 [00:17<00:12, 17.14it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 814/1026 [01:57<00:30,  6.95it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  59%|█████▉    | 302/513 [00:17<00:12, 17.14it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 816/1026 [01:57<00:30,  6.96it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  59%|█████▉    | 304/513 [00:17<00:12, 17.13it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 818/1026 [01:57<00:29,  6.97it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|█████▉    | 306/513 [00:17<00:12, 17.13it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 820/1026 [01:57<00:29,  6.98it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|██████    | 308/513 [00:17<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 822/1026 [01:57<00:29,  6.99it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|██████    | 310/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 824/1026 [01:57<00:28,  7.00it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  61%|██████    | 312/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 826/1026 [01:57<00:28,  7.01it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  61%|██████    | 314/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 828/1026 [01:58<00:28,  7.02it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  62%|██████▏   | 316/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 830/1026 [01:58<00:27,  7.03it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  62%|██████▏   | 318/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 832/1026 [01:58<00:27,  7.04it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  62%|██████▏   | 320/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 834/1026 [01:58<00:27,  7.05it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  81%|████████▏ | 836/1026 [01:58<00:26,  7.06it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  63%|██████▎   | 324/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 838/1026 [01:58<00:26,  7.07it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  82%|████████▏ | 840/1026 [01:58<00:26,  7.08it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  64%|██████▍   | 328/513 [00:19<00:10, 17.13it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 842/1026 [01:58<00:25,  7.09it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  64%|██████▍   | 330/513 [00:19<00:10, 17.13it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 844/1026 [01:58<00:25,  7.10it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  65%|██████▍   | 332/513 [00:19<00:10, 17.13it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 846/1026 [01:59<00:25,  7.11it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  65%|██████▌   | 334/513 [00:19<00:10, 17.13it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 848/1026 [01:59<00:25,  7.12it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  83%|████████▎ | 850/1026 [01:59<00:24,  7.13it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  66%|██████▌   | 338/513 [00:19<00:10, 17.13it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 852/1026 [01:59<00:24,  7.14it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  66%|██████▋   | 340/513 [00:19<00:10, 17.13it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 854/1026 [01:59<00:24,  7.15it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  83%|████████▎ | 856/1026 [01:59<00:23,  7.15it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 344/513 [00:20<00:09, 17.13it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 858/1026 [01:59<00:23,  7.16it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  67%|██████▋   | 346/513 [00:20<00:09, 17.13it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 860/1026 [01:59<00:23,  7.17it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  68%|██████▊   | 348/513 [00:20<00:09, 17.13it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 862/1026 [01:59<00:22,  7.18it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  84%|████████▍ | 864/1026 [02:00<00:22,  7.19it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▊   | 352/513 [00:20<00:09, 17.13it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 866/1026 [02:00<00:22,  7.20it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▉   | 354/513 [00:20<00:09, 17.13it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 868/1026 [02:00<00:21,  7.21it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  69%|██████▉   | 356/513 [00:20<00:09, 17.13it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 870/1026 [02:00<00:21,  7.22it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  85%|████████▍ | 872/1026 [02:00<00:21,  7.23it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  70%|███████   | 360/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 874/1026 [02:00<00:20,  7.24it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████   | 362/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 876/1026 [02:00<00:20,  7.25it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████   | 364/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 878/1026 [02:00<00:20,  7.26it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████▏  | 366/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 880/1026 [02:01<00:20,  7.27it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  72%|███████▏  | 368/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 882/1026 [02:01<00:19,  7.28it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  86%|████████▌ | 884/1026 [02:01<00:19,  7.29it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  73%|███████▎  | 372/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 886/1026 [02:01<00:19,  7.30it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  73%|███████▎  | 374/513 [00:21<00:08, 17.13it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 888/1026 [02:01<00:18,  7.31it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  73%|███████▎  | 376/513 [00:21<00:07, 17.13it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 890/1026 [02:01<00:18,  7.32it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▎  | 378/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 892/1026 [02:01<00:18,  7.33it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▍  | 380/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 894/1026 [02:01<00:17,  7.34it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  74%|███████▍  | 382/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 896/1026 [02:01<00:17,  7.35it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  88%|████████▊ | 898/1026 [02:02<00:17,  7.35it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  75%|███████▌  | 386/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 900/1026 [02:02<00:17,  7.36it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▌  | 388/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 902/1026 [02:02<00:16,  7.37it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  88%|████████▊ | 904/1026 [02:02<00:16,  7.38it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  76%|███████▋  | 392/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 906/1026 [02:02<00:16,  7.39it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  77%|███████▋  | 394/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 908/1026 [02:02<00:15,  7.40it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  77%|███████▋  | 396/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 910/1026 [02:02<00:15,  7.41it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  89%|████████▉ | 912/1026 [02:02<00:15,  7.42it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 400/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 914/1026 [02:03<00:15,  7.43it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 402/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 916/1026 [02:03<00:14,  7.44it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0:  89%|████████▉ | 918/1026 [02:03<00:14,  7.45it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  79%|███████▉  | 406/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 920/1026 [02:03<00:14,  7.46it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  80%|███████▉  | 408/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 922/1026 [02:03<00:13,  7.47it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  80%|███████▉  | 410/513 [00:23<00:06, 17.12it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 924/1026 [02:03<00:13,  7.47it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  80%|████████  | 412/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 926/1026 [02:03<00:13,  7.48it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  81%|████████  | 414/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 928/1026 [02:03<00:13,  7.49it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  81%|████████  | 416/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 930/1026 [02:03<00:12,  7.50it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  81%|████████▏ | 418/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 932/1026 [02:04<00:12,  7.51it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  82%|████████▏ | 420/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 934/1026 [02:04<00:12,  7.52it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  82%|████████▏ | 422/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 936/1026 [02:04<00:11,  7.53it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  83%|████████▎ | 424/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 938/1026 [02:04<00:11,  7.54it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  83%|████████▎ | 426/513 [00:24<00:05, 17.12it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 940/1026 [02:04<00:11,  7.55it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  83%|████████▎ | 428/513 [00:24<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 942/1026 [02:04<00:11,  7.56it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  84%|████████▍ | 430/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 944/1026 [02:04<00:10,  7.56it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  84%|████████▍ | 432/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 946/1026 [02:04<00:10,  7.57it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  85%|████████▍ | 434/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 948/1026 [02:05<00:10,  7.58it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  85%|████████▍ | 436/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 950/1026 [02:05<00:10,  7.59it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  85%|████████▌ | 438/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 952/1026 [02:05<00:09,  7.60it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  86%|████████▌ | 440/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 954/1026 [02:05<00:09,  7.61it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  86%|████████▌ | 442/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 956/1026 [02:05<00:09,  7.62it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 444/513 [00:25<00:04, 17.12it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 958/1026 [02:05<00:08,  7.63it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 446/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 960/1026 [02:05<00:08,  7.64it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  87%|████████▋ | 448/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 962/1026 [02:05<00:08,  7.64it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  88%|████████▊ | 450/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 964/1026 [02:05<00:08,  7.65it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 452/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 966/1026 [02:06<00:07,  7.66it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  88%|████████▊ | 454/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 968/1026 [02:06<00:07,  7.67it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  89%|████████▉ | 456/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 970/1026 [02:06<00:07,  7.68it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  89%|████████▉ | 458/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 972/1026 [02:06<00:07,  7.69it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  90%|████████▉ | 460/513 [00:26<00:03, 17.12it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 974/1026 [02:06<00:06,  7.70it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|█████████ | 462/513 [00:26<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 976/1026 [02:06<00:06,  7.71it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|█████████ | 464/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 978/1026 [02:06<00:06,  7.71it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  91%|█████████ | 466/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 980/1026 [02:06<00:05,  7.72it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  91%|█████████ | 468/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 982/1026 [02:07<00:05,  7.73it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  92%|█████████▏| 470/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 984/1026 [02:07<00:05,  7.74it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  92%|█████████▏| 472/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 986/1026 [02:07<00:05,  7.75it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  92%|█████████▏| 474/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 988/1026 [02:07<00:04,  7.76it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  93%|█████████▎| 476/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 990/1026 [02:07<00:04,  7.77it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  93%|█████████▎| 478/513 [00:27<00:02, 17.12it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 992/1026 [02:07<00:04,  7.77it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  94%|█████████▎| 480/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 994/1026 [02:07<00:04,  7.78it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  94%|█████████▍| 482/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 996/1026 [02:07<00:03,  7.79it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  94%|█████████▍| 484/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 998/1026 [02:07<00:03,  7.80it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  95%|█████████▍| 486/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 1000/1026 [02:08<00:03,  7.81it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  95%|█████████▌| 488/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1002/1026 [02:08<00:03,  7.82it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  96%|█████████▌| 490/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1004/1026 [02:08<00:02,  7.83it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▌| 492/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1006/1026 [02:08<00:02,  7.83it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▋| 494/513 [00:28<00:01, 17.12it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1008/1026 [02:08<00:02,  7.84it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 496/513 [00:28<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 1010/1026 [02:08<00:02,  7.85it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 498/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 1012/1026 [02:08<00:01,  7.86it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  97%|█████████▋| 500/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1014/1026 [02:08<00:01,  7.87it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  98%|█████████▊| 502/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1016/1026 [02:09<00:01,  7.88it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  98%|█████████▊| 504/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1018/1026 [02:09<00:01,  7.88it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Validation DataLoader 0:  99%|█████████▊| 506/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 1020/1026 [02:09<00:00,  7.89it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▉| 508/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1022/1026 [02:09<00:00,  7.90it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  99%|█████████▉| 510/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 1024/1026 [02:09<00:00,  7.91it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0: 100%|█████████▉| 512/513 [00:29<00:00, 17.12it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 0: 100%|██████████| 1026/1026 [02:09<00:00,  7.92it/s, loss=0.626, v_num=0, train_loss=0.632, val_loss=0.568, val_score=0.735, test_loss=0.570]\n",
      "Trial trainable_9a289_00000 reported val_score=0.51 with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 32, 'epochs': 2, 'n_fold': 2, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'distilbert-base-uncased'}.\n",
      "Epoch 0: 100%|██████████| 1026/1026 [02:09<00:00,  7.91it/s, loss=0.628, v_num=0, train_loss=0.602, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   0%|          | 0/1026 [00:00<?, ?it/s, loss=0.628, v_num=0, train_loss=0.602, val_loss=0.620, val_score=0.507, test_loss=0.570]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Epoch 0, global step 1539: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 2/1026 [00:01<11:39,  1.46it/s, loss=0.625, v_num=0, train_loss=0.620, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   0%|          | 4/1026 [00:01<07:27,  2.29it/s, loss=0.619, v_num=0, train_loss=0.604, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   1%|          | 6/1026 [00:02<06:02,  2.81it/s, loss=0.62, v_num=0, train_loss=0.602, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:   1%|          | 8/1026 [00:02<05:20,  3.18it/s, loss=0.622, v_num=0, train_loss=0.628, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   1%|          | 10/1026 [00:02<04:55,  3.44it/s, loss=0.618, v_num=0, train_loss=0.572, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   1%|          | 12/1026 [00:03<04:37,  3.65it/s, loss=0.612, v_num=0, train_loss=0.605, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   1%|▏         | 14/1026 [00:03<04:25,  3.82it/s, loss=0.61, v_num=0, train_loss=0.637, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:   2%|▏         | 16/1026 [00:04<04:16,  3.94it/s, loss=0.614, v_num=0, train_loss=0.605, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   2%|▏         | 18/1026 [00:04<04:08,  4.05it/s, loss=0.612, v_num=0, train_loss=0.591, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   2%|▏         | 20/1026 [00:04<04:02,  4.15it/s, loss=0.61, v_num=0, train_loss=0.597, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:   2%|▏         | 22/1026 [00:05<03:57,  4.23it/s, loss=0.61, v_num=0, train_loss=0.618, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   2%|▏         | 24/1026 [00:05<03:53,  4.29it/s, loss=0.618, v_num=0, train_loss=0.700, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   3%|▎         | 26/1026 [00:05<03:49,  4.35it/s, loss=0.618, v_num=0, train_loss=0.607, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   3%|▎         | 28/1026 [00:06<03:46,  4.40it/s, loss=0.617, v_num=0, train_loss=0.623, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   3%|▎         | 30/1026 [00:06<03:43,  4.45it/s, loss=0.619, v_num=0, train_loss=0.640, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   3%|▎         | 32/1026 [00:07<03:41,  4.48it/s, loss=0.621, v_num=0, train_loss=0.649, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   3%|▎         | 34/1026 [00:07<03:39,  4.53it/s, loss=0.623, v_num=0, train_loss=0.648, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   4%|▎         | 36/1026 [00:07<03:37,  4.56it/s, loss=0.621, v_num=0, train_loss=0.622, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   4%|▎         | 38/1026 [00:08<03:35,  4.59it/s, loss=0.624, v_num=0, train_loss=0.651, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   4%|▍         | 40/1026 [00:08<03:33,  4.62it/s, loss=0.624, v_num=0, train_loss=0.547, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   4%|▍         | 42/1026 [00:09<03:32,  4.64it/s, loss=0.625, v_num=0, train_loss=0.573, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   4%|▍         | 44/1026 [00:09<03:30,  4.66it/s, loss=0.622, v_num=0, train_loss=0.631, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   4%|▍         | 46/1026 [00:09<03:28,  4.69it/s, loss=0.622, v_num=0, train_loss=0.599, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   5%|▍         | 48/1026 [00:10<03:27,  4.71it/s, loss=0.622, v_num=0, train_loss=0.641, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   5%|▍         | 50/1026 [00:10<03:26,  4.73it/s, loss=0.618, v_num=0, train_loss=0.605, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   5%|▌         | 52/1026 [00:10<03:25,  4.75it/s, loss=0.62, v_num=0, train_loss=0.660, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:   5%|▌         | 54/1026 [00:11<03:24,  4.76it/s, loss=0.618, v_num=0, train_loss=0.604, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   5%|▌         | 56/1026 [00:11<03:23,  4.78it/s, loss=0.618, v_num=0, train_loss=0.618, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   6%|▌         | 58/1026 [00:12<03:22,  4.79it/s, loss=0.616, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   6%|▌         | 60/1026 [00:12<03:21,  4.80it/s, loss=0.616, v_num=0, train_loss=0.612, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   6%|▌         | 62/1026 [00:12<03:20,  4.82it/s, loss=0.62, v_num=0, train_loss=0.639, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:   6%|▌         | 64/1026 [00:13<03:19,  4.83it/s, loss=0.617, v_num=0, train_loss=0.607, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   6%|▋         | 66/1026 [00:13<03:18,  4.84it/s, loss=0.615, v_num=0, train_loss=0.569, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   7%|▋         | 68/1026 [00:14<03:17,  4.85it/s, loss=0.618, v_num=0, train_loss=0.664, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   7%|▋         | 70/1026 [00:14<03:16,  4.86it/s, loss=0.623, v_num=0, train_loss=0.640, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   7%|▋         | 72/1026 [00:14<03:15,  4.87it/s, loss=0.626, v_num=0, train_loss=0.627, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   7%|▋         | 74/1026 [00:15<03:15,  4.88it/s, loss=0.624, v_num=0, train_loss=0.574, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   7%|▋         | 76/1026 [00:15<03:14,  4.89it/s, loss=0.626, v_num=0, train_loss=0.637, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   8%|▊         | 78/1026 [00:15<03:13,  4.89it/s, loss=0.628, v_num=0, train_loss=0.649, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   8%|▊         | 80/1026 [00:16<03:13,  4.90it/s, loss=0.63, v_num=0, train_loss=0.622, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:   8%|▊         | 82/1026 [00:16<03:12,  4.91it/s, loss=0.626, v_num=0, train_loss=0.619, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   8%|▊         | 84/1026 [00:17<03:11,  4.92it/s, loss=0.628, v_num=0, train_loss=0.620, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   8%|▊         | 86/1026 [00:17<03:10,  4.92it/s, loss=0.629, v_num=0, train_loss=0.608, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   9%|▊         | 88/1026 [00:17<03:10,  4.93it/s, loss=0.625, v_num=0, train_loss=0.616, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   9%|▉         | 90/1026 [00:18<03:09,  4.93it/s, loss=0.626, v_num=0, train_loss=0.642, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   9%|▉         | 92/1026 [00:18<03:09,  4.94it/s, loss=0.621, v_num=0, train_loss=0.633, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   9%|▉         | 94/1026 [00:19<03:08,  4.95it/s, loss=0.623, v_num=0, train_loss=0.627, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:   9%|▉         | 96/1026 [00:19<03:07,  4.95it/s, loss=0.62, v_num=0, train_loss=0.645, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  10%|▉         | 98/1026 [00:19<03:07,  4.96it/s, loss=0.619, v_num=0, train_loss=0.608, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  10%|▉         | 100/1026 [00:20<03:06,  4.96it/s, loss=0.62, v_num=0, train_loss=0.578, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  10%|▉         | 102/1026 [00:20<03:06,  4.97it/s, loss=0.622, v_num=0, train_loss=0.613, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  10%|█         | 104/1026 [00:20<03:05,  4.97it/s, loss=0.623, v_num=0, train_loss=0.627, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  10%|█         | 106/1026 [00:21<03:04,  4.98it/s, loss=0.625, v_num=0, train_loss=0.652, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  11%|█         | 108/1026 [00:21<03:04,  4.98it/s, loss=0.628, v_num=0, train_loss=0.671, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  11%|█         | 110/1026 [00:22<03:03,  4.98it/s, loss=0.625, v_num=0, train_loss=0.581, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  11%|█         | 112/1026 [00:22<03:03,  4.99it/s, loss=0.626, v_num=0, train_loss=0.624, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  11%|█         | 114/1026 [00:22<03:02,  4.99it/s, loss=0.629, v_num=0, train_loss=0.616, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  11%|█▏        | 116/1026 [00:23<03:02,  5.00it/s, loss=0.628, v_num=0, train_loss=0.603, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  12%|█▏        | 118/1026 [00:23<03:01,  5.00it/s, loss=0.627, v_num=0, train_loss=0.619, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  12%|█▏        | 120/1026 [00:23<03:01,  5.00it/s, loss=0.626, v_num=0, train_loss=0.613, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  12%|█▏        | 122/1026 [00:24<03:00,  5.01it/s, loss=0.625, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  12%|█▏        | 124/1026 [00:24<02:59,  5.01it/s, loss=0.625, v_num=0, train_loss=0.621, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  12%|█▏        | 126/1026 [00:25<02:59,  5.02it/s, loss=0.624, v_num=0, train_loss=0.633, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  12%|█▏        | 128/1026 [00:25<02:58,  5.02it/s, loss=0.619, v_num=0, train_loss=0.577, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  13%|█▎        | 130/1026 [00:25<02:58,  5.02it/s, loss=0.621, v_num=0, train_loss=0.613, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  13%|█▎        | 132/1026 [00:26<02:57,  5.03it/s, loss=0.621, v_num=0, train_loss=0.613, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  13%|█▎        | 132/1026 [00:26<02:57,  5.03it/s, loss=0.617, v_num=0, train_loss=0.594, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  13%|█▎        | 134/1026 [00:26<02:57,  5.03it/s, loss=0.611, v_num=0, train_loss=0.562, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  13%|█▎        | 136/1026 [00:27<02:56,  5.03it/s, loss=0.609, v_num=0, train_loss=0.577, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  13%|█▎        | 138/1026 [00:27<02:56,  5.03it/s, loss=0.612, v_num=0, train_loss=0.694, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  14%|█▎        | 140/1026 [00:27<02:55,  5.04it/s, loss=0.61, v_num=0, train_loss=0.592, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  14%|█▍        | 142/1026 [00:28<02:55,  5.04it/s, loss=0.609, v_num=0, train_loss=0.657, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  14%|█▍        | 144/1026 [00:28<02:54,  5.04it/s, loss=0.605, v_num=0, train_loss=0.584, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  14%|█▍        | 146/1026 [00:28<02:54,  5.04it/s, loss=0.603, v_num=0, train_loss=0.606, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  14%|█▍        | 148/1026 [00:29<02:54,  5.05it/s, loss=0.602, v_num=0, train_loss=0.523, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  15%|█▍        | 150/1026 [00:29<02:53,  5.05it/s, loss=0.603, v_num=0, train_loss=0.648, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  15%|█▍        | 152/1026 [00:30<02:53,  5.05it/s, loss=0.605, v_num=0, train_loss=0.602, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  15%|█▌        | 154/1026 [00:30<02:52,  5.05it/s, loss=0.61, v_num=0, train_loss=0.628, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  15%|█▌        | 156/1026 [00:30<02:52,  5.05it/s, loss=0.613, v_num=0, train_loss=0.619, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  15%|█▌        | 158/1026 [00:31<02:51,  5.05it/s, loss=0.615, v_num=0, train_loss=0.645, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  16%|█▌        | 160/1026 [00:31<02:51,  5.06it/s, loss=0.614, v_num=0, train_loss=0.587, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  16%|█▌        | 162/1026 [00:32<02:50,  5.06it/s, loss=0.614, v_num=0, train_loss=0.610, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  16%|█▌        | 164/1026 [00:32<02:50,  5.06it/s, loss=0.615, v_num=0, train_loss=0.578, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  16%|█▌        | 166/1026 [00:32<02:49,  5.06it/s, loss=0.615, v_num=0, train_loss=0.614, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  16%|█▋        | 168/1026 [00:33<02:49,  5.06it/s, loss=0.618, v_num=0, train_loss=0.589, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  17%|█▋        | 170/1026 [00:33<02:49,  5.06it/s, loss=0.616, v_num=0, train_loss=0.583, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  17%|█▋        | 172/1026 [00:33<02:48,  5.07it/s, loss=0.619, v_num=0, train_loss=0.631, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  17%|█▋        | 174/1026 [00:34<02:48,  5.07it/s, loss=0.614, v_num=0, train_loss=0.577, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  17%|█▋        | 176/1026 [00:34<02:47,  5.07it/s, loss=0.612, v_num=0, train_loss=0.571, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  17%|█▋        | 178/1026 [00:35<02:47,  5.07it/s, loss=0.603, v_num=0, train_loss=0.556, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  18%|█▊        | 180/1026 [00:35<02:46,  5.07it/s, loss=0.606, v_num=0, train_loss=0.643, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  18%|█▊        | 182/1026 [00:35<02:46,  5.08it/s, loss=0.602, v_num=0, train_loss=0.567, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  18%|█▊        | 184/1026 [00:36<02:45,  5.08it/s, loss=0.606, v_num=0, train_loss=0.595, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  18%|█▊        | 186/1026 [00:36<02:45,  5.08it/s, loss=0.609, v_num=0, train_loss=0.655, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  18%|█▊        | 188/1026 [00:37<02:44,  5.08it/s, loss=0.609, v_num=0, train_loss=0.600, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  19%|█▊        | 190/1026 [00:37<02:44,  5.08it/s, loss=0.609, v_num=0, train_loss=0.576, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  19%|█▊        | 192/1026 [00:37<02:44,  5.08it/s, loss=0.602, v_num=0, train_loss=0.566, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  19%|█▉        | 194/1026 [00:38<02:43,  5.09it/s, loss=0.606, v_num=0, train_loss=0.627, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  19%|█▉        | 196/1026 [00:38<02:43,  5.09it/s, loss=0.606, v_num=0, train_loss=0.595, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  19%|█▉        | 198/1026 [00:38<02:42,  5.09it/s, loss=0.607, v_num=0, train_loss=0.616, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  19%|█▉        | 200/1026 [00:39<02:42,  5.09it/s, loss=0.605, v_num=0, train_loss=0.628, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  20%|█▉        | 202/1026 [00:39<02:41,  5.09it/s, loss=0.603, v_num=0, train_loss=0.564, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  20%|█▉        | 204/1026 [00:40<02:41,  5.09it/s, loss=0.596, v_num=0, train_loss=0.570, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  20%|██        | 206/1026 [00:40<02:41,  5.09it/s, loss=0.594, v_num=0, train_loss=0.666, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  20%|██        | 208/1026 [00:40<02:40,  5.09it/s, loss=0.592, v_num=0, train_loss=0.528, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  20%|██        | 210/1026 [00:41<02:40,  5.09it/s, loss=0.592, v_num=0, train_loss=0.603, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  21%|██        | 212/1026 [00:41<02:39,  5.09it/s, loss=0.597, v_num=0, train_loss=0.669, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  21%|██        | 214/1026 [00:41<02:39,  5.10it/s, loss=0.595, v_num=0, train_loss=0.610, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  21%|██        | 216/1026 [00:42<02:38,  5.09it/s, loss=0.597, v_num=0, train_loss=0.614, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  21%|██        | 218/1026 [00:42<02:38,  5.10it/s, loss=0.598, v_num=0, train_loss=0.665, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  21%|██▏       | 220/1026 [00:43<02:38,  5.10it/s, loss=0.6, v_num=0, train_loss=0.628, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  22%|██▏       | 222/1026 [00:43<02:37,  5.10it/s, loss=0.605, v_num=0, train_loss=0.654, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  22%|██▏       | 224/1026 [00:43<02:37,  5.10it/s, loss=0.609, v_num=0, train_loss=0.626, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  22%|██▏       | 226/1026 [00:44<02:36,  5.10it/s, loss=0.602, v_num=0, train_loss=0.564, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  22%|██▏       | 228/1026 [00:44<02:36,  5.10it/s, loss=0.606, v_num=0, train_loss=0.662, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  22%|██▏       | 230/1026 [00:45<02:35,  5.10it/s, loss=0.607, v_num=0, train_loss=0.611, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  23%|██▎       | 232/1026 [00:45<02:35,  5.10it/s, loss=0.607, v_num=0, train_loss=0.641, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  23%|██▎       | 234/1026 [00:45<02:35,  5.10it/s, loss=0.607, v_num=0, train_loss=0.572, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  23%|██▎       | 236/1026 [00:46<02:34,  5.10it/s, loss=0.604, v_num=0, train_loss=0.583, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  23%|██▎       | 238/1026 [00:46<02:34,  5.11it/s, loss=0.6, v_num=0, train_loss=0.538, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  23%|██▎       | 240/1026 [00:46<02:33,  5.11it/s, loss=0.596, v_num=0, train_loss=0.575, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  24%|██▎       | 242/1026 [00:47<02:33,  5.11it/s, loss=0.595, v_num=0, train_loss=0.594, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  24%|██▍       | 244/1026 [00:47<02:33,  5.11it/s, loss=0.593, v_num=0, train_loss=0.597, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  24%|██▍       | 246/1026 [00:48<02:32,  5.11it/s, loss=0.604, v_num=0, train_loss=0.705, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  24%|██▍       | 248/1026 [00:48<02:32,  5.11it/s, loss=0.606, v_num=0, train_loss=0.616, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  24%|██▍       | 250/1026 [00:48<02:31,  5.11it/s, loss=0.606, v_num=0, train_loss=0.587, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  25%|██▍       | 252/1026 [00:49<02:31,  5.11it/s, loss=0.607, v_num=0, train_loss=0.656, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  25%|██▍       | 254/1026 [00:49<02:30,  5.11it/s, loss=0.61, v_num=0, train_loss=0.662, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  25%|██▍       | 256/1026 [00:50<02:30,  5.11it/s, loss=0.612, v_num=0, train_loss=0.586, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  25%|██▌       | 258/1026 [00:50<02:30,  5.12it/s, loss=0.616, v_num=0, train_loss=0.621, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  25%|██▌       | 260/1026 [00:50<02:29,  5.12it/s, loss=0.618, v_num=0, train_loss=0.592, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  26%|██▌       | 262/1026 [00:51<02:29,  5.12it/s, loss=0.618, v_num=0, train_loss=0.604, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  26%|██▌       | 264/1026 [00:51<02:28,  5.12it/s, loss=0.621, v_num=0, train_loss=0.588, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  26%|██▌       | 266/1026 [00:51<02:28,  5.12it/s, loss=0.615, v_num=0, train_loss=0.616, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  26%|██▌       | 268/1026 [00:52<02:28,  5.12it/s, loss=0.616, v_num=0, train_loss=0.621, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  26%|██▋       | 270/1026 [00:52<02:27,  5.12it/s, loss=0.612, v_num=0, train_loss=0.536, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  27%|██▋       | 272/1026 [00:53<02:27,  5.12it/s, loss=0.61, v_num=0, train_loss=0.620, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  27%|██▋       | 274/1026 [00:53<02:26,  5.12it/s, loss=0.61, v_num=0, train_loss=0.640, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  27%|██▋       | 276/1026 [00:53<02:26,  5.12it/s, loss=0.612, v_num=0, train_loss=0.676, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  27%|██▋       | 278/1026 [00:54<02:26,  5.12it/s, loss=0.612, v_num=0, train_loss=0.571, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  27%|██▋       | 280/1026 [00:54<02:25,  5.12it/s, loss=0.612, v_num=0, train_loss=0.601, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  27%|██▋       | 282/1026 [00:55<02:25,  5.12it/s, loss=0.614, v_num=0, train_loss=0.640, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  28%|██▊       | 284/1026 [00:55<02:24,  5.12it/s, loss=0.616, v_num=0, train_loss=0.651, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  28%|██▊       | 286/1026 [00:55<02:24,  5.12it/s, loss=0.613, v_num=0, train_loss=0.561, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  28%|██▊       | 288/1026 [00:56<02:24,  5.12it/s, loss=0.61, v_num=0, train_loss=0.619, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  28%|██▊       | 290/1026 [00:56<02:23,  5.12it/s, loss=0.614, v_num=0, train_loss=0.591, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  28%|██▊       | 292/1026 [00:56<02:23,  5.13it/s, loss=0.614, v_num=0, train_loss=0.569, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  29%|██▊       | 294/1026 [00:57<02:22,  5.13it/s, loss=0.611, v_num=0, train_loss=0.579, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  29%|██▉       | 296/1026 [00:57<02:22,  5.13it/s, loss=0.609, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  29%|██▉       | 298/1026 [00:58<02:21,  5.13it/s, loss=0.611, v_num=0, train_loss=0.597, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  29%|██▉       | 300/1026 [00:58<02:21,  5.13it/s, loss=0.615, v_num=0, train_loss=0.636, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  29%|██▉       | 302/1026 [00:58<02:21,  5.13it/s, loss=0.612, v_num=0, train_loss=0.641, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  30%|██▉       | 304/1026 [00:59<02:20,  5.13it/s, loss=0.611, v_num=0, train_loss=0.591, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  30%|██▉       | 306/1026 [00:59<02:20,  5.13it/s, loss=0.611, v_num=0, train_loss=0.599, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  30%|███       | 308/1026 [01:00<02:19,  5.13it/s, loss=0.612, v_num=0, train_loss=0.594, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  30%|███       | 310/1026 [01:00<02:19,  5.13it/s, loss=0.612, v_num=0, train_loss=0.622, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  30%|███       | 312/1026 [01:00<02:19,  5.13it/s, loss=0.611, v_num=0, train_loss=0.577, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  31%|███       | 314/1026 [01:01<02:18,  5.13it/s, loss=0.614, v_num=0, train_loss=0.639, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  31%|███       | 316/1026 [01:01<02:18,  5.13it/s, loss=0.614, v_num=0, train_loss=0.599, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  31%|███       | 318/1026 [01:01<02:17,  5.13it/s, loss=0.61, v_num=0, train_loss=0.548, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  31%|███       | 320/1026 [01:02<02:17,  5.13it/s, loss=0.607, v_num=0, train_loss=0.606, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  31%|███▏      | 322/1026 [01:02<02:17,  5.13it/s, loss=0.608, v_num=0, train_loss=0.604, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  32%|███▏      | 324/1026 [01:03<02:16,  5.14it/s, loss=0.605, v_num=0, train_loss=0.576, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  32%|███▏      | 326/1026 [01:03<02:16,  5.14it/s, loss=0.605, v_num=0, train_loss=0.597, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  32%|███▏      | 328/1026 [01:03<02:15,  5.14it/s, loss=0.601, v_num=0, train_loss=0.555, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  32%|███▏      | 330/1026 [01:04<02:15,  5.14it/s, loss=0.599, v_num=0, train_loss=0.591, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  32%|███▏      | 332/1026 [01:04<02:15,  5.14it/s, loss=0.6, v_num=0, train_loss=0.621, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  33%|███▎      | 334/1026 [01:05<02:14,  5.14it/s, loss=0.599, v_num=0, train_loss=0.661, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  33%|███▎      | 336/1026 [01:05<02:14,  5.14it/s, loss=0.598, v_num=0, train_loss=0.609, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  33%|███▎      | 338/1026 [01:05<02:13,  5.14it/s, loss=0.6, v_num=0, train_loss=0.613, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  33%|███▎      | 340/1026 [01:06<02:13,  5.14it/s, loss=0.599, v_num=0, train_loss=0.602, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  33%|███▎      | 342/1026 [01:06<02:13,  5.14it/s, loss=0.597, v_num=0, train_loss=0.592, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  34%|███▎      | 344/1026 [01:06<02:12,  5.14it/s, loss=0.597, v_num=0, train_loss=0.589, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  34%|███▎      | 346/1026 [01:07<02:12,  5.14it/s, loss=0.601, v_num=0, train_loss=0.640, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  34%|███▍      | 348/1026 [01:07<02:11,  5.14it/s, loss=0.605, v_num=0, train_loss=0.612, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  34%|███▍      | 350/1026 [01:08<02:11,  5.14it/s, loss=0.607, v_num=0, train_loss=0.698, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  34%|███▍      | 352/1026 [01:08<02:11,  5.14it/s, loss=0.605, v_num=0, train_loss=0.597, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  35%|███▍      | 354/1026 [01:08<02:10,  5.14it/s, loss=0.604, v_num=0, train_loss=0.649, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  35%|███▍      | 356/1026 [01:09<02:10,  5.14it/s, loss=0.608, v_num=0, train_loss=0.626, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  35%|███▍      | 358/1026 [01:09<02:09,  5.14it/s, loss=0.608, v_num=0, train_loss=0.585, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  35%|███▌      | 360/1026 [01:09<02:09,  5.14it/s, loss=0.61, v_num=0, train_loss=0.599, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  35%|███▌      | 362/1026 [01:10<02:09,  5.14it/s, loss=0.611, v_num=0, train_loss=0.607, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  35%|███▌      | 364/1026 [01:10<02:08,  5.14it/s, loss=0.61, v_num=0, train_loss=0.541, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  36%|███▌      | 366/1026 [01:11<02:08,  5.15it/s, loss=0.611, v_num=0, train_loss=0.655, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  36%|███▌      | 368/1026 [01:11<02:07,  5.15it/s, loss=0.607, v_num=0, train_loss=0.572, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  36%|███▌      | 370/1026 [01:11<02:07,  5.15it/s, loss=0.607, v_num=0, train_loss=0.636, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  36%|███▋      | 372/1026 [01:12<02:07,  5.15it/s, loss=0.607, v_num=0, train_loss=0.584, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  36%|███▋      | 374/1026 [01:12<02:06,  5.15it/s, loss=0.601, v_num=0, train_loss=0.595, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  37%|███▋      | 376/1026 [01:13<02:06,  5.15it/s, loss=0.6, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  37%|███▋      | 378/1026 [01:13<02:05,  5.15it/s, loss=0.599, v_num=0, train_loss=0.623, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  37%|███▋      | 380/1026 [01:13<02:05,  5.15it/s, loss=0.594, v_num=0, train_loss=0.614, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  37%|███▋      | 382/1026 [01:14<02:05,  5.15it/s, loss=0.597, v_num=0, train_loss=0.656, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  37%|███▋      | 384/1026 [01:14<02:04,  5.15it/s, loss=0.595, v_num=0, train_loss=0.543, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  38%|███▊      | 386/1026 [01:14<02:04,  5.15it/s, loss=0.594, v_num=0, train_loss=0.622, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  38%|███▊      | 388/1026 [01:15<02:03,  5.15it/s, loss=0.6, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  38%|███▊      | 390/1026 [01:15<02:03,  5.15it/s, loss=0.602, v_num=0, train_loss=0.639, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  38%|███▊      | 392/1026 [01:16<02:03,  5.15it/s, loss=0.603, v_num=0, train_loss=0.631, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  38%|███▊      | 394/1026 [01:16<02:02,  5.15it/s, loss=0.604, v_num=0, train_loss=0.572, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  39%|███▊      | 396/1026 [01:16<02:02,  5.15it/s, loss=0.608, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  39%|███▉      | 398/1026 [01:17<02:01,  5.15it/s, loss=0.609, v_num=0, train_loss=0.595, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  39%|███▉      | 400/1026 [01:17<02:01,  5.15it/s, loss=0.614, v_num=0, train_loss=0.608, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  39%|███▉      | 402/1026 [01:18<02:01,  5.15it/s, loss=0.607, v_num=0, train_loss=0.570, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  39%|███▉      | 404/1026 [01:18<02:00,  5.15it/s, loss=0.608, v_num=0, train_loss=0.580, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  40%|███▉      | 406/1026 [01:18<02:00,  5.15it/s, loss=0.607, v_num=0, train_loss=0.561, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  40%|███▉      | 408/1026 [01:19<01:59,  5.15it/s, loss=0.602, v_num=0, train_loss=0.607, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  40%|███▉      | 410/1026 [01:19<01:59,  5.15it/s, loss=0.601, v_num=0, train_loss=0.605, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  40%|████      | 412/1026 [01:19<01:59,  5.15it/s, loss=0.603, v_num=0, train_loss=0.588, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  40%|████      | 414/1026 [01:20<01:58,  5.15it/s, loss=0.603, v_num=0, train_loss=0.600, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  41%|████      | 416/1026 [01:20<01:58,  5.15it/s, loss=0.598, v_num=0, train_loss=0.572, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  41%|████      | 418/1026 [01:21<01:57,  5.15it/s, loss=0.599, v_num=0, train_loss=0.656, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  41%|████      | 420/1026 [01:21<01:57,  5.15it/s, loss=0.594, v_num=0, train_loss=0.568, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  41%|████      | 422/1026 [01:21<01:57,  5.15it/s, loss=0.596, v_num=0, train_loss=0.631, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  41%|████▏     | 424/1026 [01:22<01:56,  5.15it/s, loss=0.604, v_num=0, train_loss=0.623, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  42%|████▏     | 426/1026 [01:22<01:56,  5.15it/s, loss=0.6, v_num=0, train_loss=0.542, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  42%|████▏     | 428/1026 [01:23<01:56,  5.15it/s, loss=0.602, v_num=0, train_loss=0.591, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  42%|████▏     | 430/1026 [01:23<01:55,  5.16it/s, loss=0.599, v_num=0, train_loss=0.589, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  42%|████▏     | 432/1026 [01:23<01:55,  5.16it/s, loss=0.6, v_num=0, train_loss=0.644, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  42%|████▏     | 434/1026 [01:24<01:54,  5.16it/s, loss=0.599, v_num=0, train_loss=0.545, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  42%|████▏     | 436/1026 [01:24<01:54,  5.16it/s, loss=0.599, v_num=0, train_loss=0.555, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  43%|████▎     | 438/1026 [01:24<01:54,  5.16it/s, loss=0.599, v_num=0, train_loss=0.580, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  43%|████▎     | 440/1026 [01:25<01:53,  5.16it/s, loss=0.598, v_num=0, train_loss=0.543, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  43%|████▎     | 442/1026 [01:25<01:53,  5.16it/s, loss=0.603, v_num=0, train_loss=0.588, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  43%|████▎     | 444/1026 [01:26<01:52,  5.16it/s, loss=0.598, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  43%|████▎     | 446/1026 [01:26<01:52,  5.16it/s, loss=0.6, v_num=0, train_loss=0.572, val_loss=0.620, val_score=0.507, test_loss=0.570]  \n",
      "Epoch 1:  44%|████▎     | 448/1026 [01:26<01:52,  5.16it/s, loss=0.602, v_num=0, train_loss=0.622, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  44%|████▍     | 450/1026 [01:27<01:51,  5.16it/s, loss=0.608, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  44%|████▍     | 452/1026 [01:27<01:51,  5.16it/s, loss=0.603, v_num=0, train_loss=0.558, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  44%|████▍     | 454/1026 [01:28<01:50,  5.16it/s, loss=0.607, v_num=0, train_loss=0.610, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  44%|████▍     | 456/1026 [01:28<01:50,  5.16it/s, loss=0.604, v_num=0, train_loss=0.539, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  45%|████▍     | 458/1026 [01:28<01:50,  5.16it/s, loss=0.606, v_num=0, train_loss=0.632, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  45%|████▍     | 460/1026 [01:29<01:49,  5.16it/s, loss=0.604, v_num=0, train_loss=0.547, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  45%|████▌     | 462/1026 [01:29<01:49,  5.16it/s, loss=0.601, v_num=0, train_loss=0.599, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  45%|████▌     | 464/1026 [01:29<01:48,  5.16it/s, loss=0.603, v_num=0, train_loss=0.623, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  45%|████▌     | 466/1026 [01:30<01:48,  5.16it/s, loss=0.602, v_num=0, train_loss=0.595, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  46%|████▌     | 468/1026 [01:30<01:48,  5.16it/s, loss=0.601, v_num=0, train_loss=0.598, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  46%|████▌     | 470/1026 [01:31<01:47,  5.16it/s, loss=0.594, v_num=0, train_loss=0.543, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  46%|████▌     | 472/1026 [01:31<01:47,  5.16it/s, loss=0.594, v_num=0, train_loss=0.601, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  46%|████▌     | 474/1026 [01:31<01:46,  5.16it/s, loss=0.597, v_num=0, train_loss=0.641, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  46%|████▋     | 476/1026 [01:32<01:46,  5.16it/s, loss=0.601, v_num=0, train_loss=0.592, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  47%|████▋     | 478/1026 [01:32<01:46,  5.16it/s, loss=0.602, v_num=0, train_loss=0.624, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  47%|████▋     | 480/1026 [01:32<01:45,  5.16it/s, loss=0.608, v_num=0, train_loss=0.651, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  47%|████▋     | 482/1026 [01:33<01:45,  5.16it/s, loss=0.607, v_num=0, train_loss=0.548, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  47%|████▋     | 484/1026 [01:33<01:44,  5.16it/s, loss=0.606, v_num=0, train_loss=0.629, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  47%|████▋     | 486/1026 [01:34<01:44,  5.16it/s, loss=0.609, v_num=0, train_loss=0.655, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  48%|████▊     | 488/1026 [01:34<01:44,  5.16it/s, loss=0.608, v_num=0, train_loss=0.627, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  48%|████▊     | 490/1026 [01:34<01:43,  5.16it/s, loss=0.61, v_num=0, train_loss=0.625, val_loss=0.620, val_score=0.507, test_loss=0.570] \n",
      "Epoch 1:  48%|████▊     | 492/1026 [01:35<01:43,  5.16it/s, loss=0.615, v_num=0, train_loss=0.601, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  48%|████▊     | 494/1026 [01:35<01:43,  5.16it/s, loss=0.606, v_num=0, train_loss=0.546, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  48%|████▊     | 496/1026 [01:36<01:42,  5.16it/s, loss=0.607, v_num=0, train_loss=0.610, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  49%|████▊     | 498/1026 [01:36<01:42,  5.16it/s, loss=0.603, v_num=0, train_loss=0.570, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  49%|████▊     | 500/1026 [01:36<01:41,  5.17it/s, loss=0.605, v_num=0, train_loss=0.628, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  49%|████▉     | 502/1026 [01:37<01:41,  5.17it/s, loss=0.607, v_num=0, train_loss=0.681, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  49%|████▉     | 504/1026 [01:37<01:41,  5.17it/s, loss=0.604, v_num=0, train_loss=0.629, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  49%|████▉     | 506/1026 [01:37<01:40,  5.17it/s, loss=0.607, v_num=0, train_loss=0.629, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  50%|████▉     | 508/1026 [01:38<01:40,  5.17it/s, loss=0.609, v_num=0, train_loss=0.662, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  50%|████▉     | 510/1026 [01:38<01:39,  5.17it/s, loss=0.607, v_num=0, train_loss=0.591, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Epoch 1:  50%|████▉     | 512/1026 [01:39<01:39,  5.17it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[0m \n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation:   0%|          | 0/513 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 514/1026 [01:40<01:39,  5.13it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   0%|          | 2/513 [00:00<00:16, 30.26it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 516/1026 [01:40<01:39,  5.14it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   1%|          | 4/513 [00:00<00:23, 21.84it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 518/1026 [01:40<01:38,  5.15it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   1%|          | 6/513 [00:00<00:25, 19.98it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 520/1026 [01:40<01:37,  5.17it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   2%|▏         | 8/513 [00:00<00:26, 19.19it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 522/1026 [01:40<01:37,  5.18it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   2%|▏         | 10/513 [00:00<00:26, 18.73it/s]\u001b[A\n",
      "Epoch 1:  51%|█████     | 524/1026 [01:40<01:36,  5.19it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   2%|▏         | 12/513 [00:00<00:27, 18.43it/s]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 526/1026 [01:40<01:35,  5.21it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   3%|▎         | 14/513 [00:00<00:27, 18.23it/s]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 528/1026 [01:41<01:35,  5.22it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   3%|▎         | 16/513 [00:00<00:27, 18.07it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 530/1026 [01:41<01:34,  5.24it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   4%|▎         | 18/513 [00:01<00:27, 17.95it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 532/1026 [01:41<01:34,  5.25it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   4%|▍         | 20/513 [00:01<00:27, 17.86it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 534/1026 [01:41<01:33,  5.26it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   4%|▍         | 22/513 [00:01<00:27, 17.79it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 536/1026 [01:41<01:32,  5.28it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   5%|▍         | 24/513 [00:01<00:27, 17.74it/s]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 538/1026 [01:41<01:32,  5.29it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   5%|▌         | 26/513 [00:01<00:27, 17.69it/s]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 540/1026 [01:41<01:31,  5.30it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   5%|▌         | 28/513 [00:01<00:27, 17.64it/s]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 542/1026 [01:41<01:31,  5.32it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   6%|▌         | 30/513 [00:01<00:27, 17.60it/s]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 544/1026 [01:42<01:30,  5.33it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   6%|▌         | 32/513 [00:01<00:27, 17.57it/s]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 546/1026 [01:42<01:29,  5.34it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   7%|▋         | 34/513 [00:01<00:27, 17.54it/s]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 548/1026 [01:42<01:29,  5.36it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   7%|▋         | 36/513 [00:02<00:27, 17.51it/s]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 550/1026 [01:42<01:28,  5.37it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:   7%|▋         | 38/513 [00:02<00:27, 17.49it/s]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 552/1026 [01:42<01:28,  5.38it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   8%|▊         | 40/513 [00:02<00:27, 17.47it/s]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 554/1026 [01:42<01:27,  5.40it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   8%|▊         | 42/513 [00:02<00:26, 17.46it/s]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 556/1026 [01:42<01:26,  5.41it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   9%|▊         | 44/513 [00:02<00:26, 17.44it/s]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 558/1026 [01:42<01:26,  5.42it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   9%|▉         | 46/513 [00:02<00:26, 17.42it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 560/1026 [01:42<01:25,  5.44it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:   9%|▉         | 48/513 [00:02<00:26, 17.41it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 562/1026 [01:43<01:25,  5.45it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  10%|▉         | 50/513 [00:02<00:26, 17.40it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 564/1026 [01:43<01:24,  5.46it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  10%|█         | 52/513 [00:02<00:26, 17.38it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 566/1026 [01:43<01:23,  5.48it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  11%|█         | 54/513 [00:03<00:26, 17.37it/s]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 568/1026 [01:43<01:23,  5.49it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  11%|█         | 56/513 [00:03<00:26, 17.36it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 570/1026 [01:43<01:22,  5.50it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  11%|█▏        | 58/513 [00:03<00:26, 17.36it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 572/1026 [01:43<01:22,  5.52it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  12%|█▏        | 60/513 [00:03<00:26, 17.35it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 574/1026 [01:43<01:21,  5.53it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  56%|█████▌    | 576/1026 [01:43<01:21,  5.54it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  56%|█████▋    | 578/1026 [01:44<01:20,  5.56it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  57%|█████▋    | 580/1026 [01:44<01:20,  5.57it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  57%|█████▋    | 582/1026 [01:44<01:19,  5.58it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  57%|█████▋    | 584/1026 [01:44<01:18,  5.59it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  57%|█████▋    | 586/1026 [01:44<01:18,  5.61it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  57%|█████▋    | 588/1026 [01:44<01:17,  5.62it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 590/1026 [01:44<01:17,  5.63it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 592/1026 [01:44<01:16,  5.65it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 594/1026 [01:44<01:16,  5.66it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  58%|█████▊    | 596/1026 [01:45<01:15,  5.67it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  16%|█▋        | 84/513 [00:04<00:24, 17.27it/s]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 598/1026 [01:45<01:15,  5.68it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  17%|█▋        | 86/513 [00:04<00:24, 17.27it/s]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 600/1026 [01:45<01:14,  5.70it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  17%|█▋        | 88/513 [00:05<00:24, 17.26it/s]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 602/1026 [01:45<01:14,  5.71it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  18%|█▊        | 90/513 [00:05<00:24, 17.26it/s]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 604/1026 [01:45<01:13,  5.72it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  18%|█▊        | 92/513 [00:05<00:24, 17.26it/s]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 606/1026 [01:45<01:13,  5.74it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  18%|█▊        | 94/513 [00:05<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 608/1026 [01:45<01:12,  5.75it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  19%|█▊        | 96/513 [00:05<00:24, 17.25it/s]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 610/1026 [01:45<01:12,  5.76it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  19%|█▉        | 98/513 [00:05<00:24, 17.24it/s]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 612/1026 [01:46<01:11,  5.77it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  19%|█▉        | 100/513 [00:05<00:23, 17.24it/s]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 614/1026 [01:46<01:11,  5.79it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  20%|█▉        | 102/513 [00:05<00:23, 17.24it/s]\u001b[A\n",
      "Epoch 1:  60%|██████    | 616/1026 [01:46<01:10,  5.80it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  20%|██        | 104/513 [00:06<00:23, 17.24it/s]\u001b[A\n",
      "Epoch 1:  60%|██████    | 618/1026 [01:46<01:10,  5.81it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  60%|██████    | 620/1026 [01:46<01:09,  5.82it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████    | 622/1026 [01:46<01:09,  5.83it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████    | 624/1026 [01:46<01:08,  5.85it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████    | 626/1026 [01:46<01:08,  5.86it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████    | 628/1026 [01:46<01:07,  5.87it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  61%|██████▏   | 630/1026 [01:47<01:07,  5.88it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  62%|██████▏   | 632/1026 [01:47<01:06,  5.90it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  62%|██████▏   | 634/1026 [01:47<01:06,  5.91it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  62%|██████▏   | 636/1026 [01:47<01:05,  5.92it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  62%|██████▏   | 638/1026 [01:47<01:05,  5.93it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  62%|██████▏   | 640/1026 [01:47<01:04,  5.94it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  63%|██████▎   | 642/1026 [01:47<01:04,  5.96it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  25%|██▌       | 130/513 [00:07<00:22, 17.21it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 644/1026 [01:47<01:03,  5.97it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  26%|██▌       | 132/513 [00:07<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 646/1026 [01:48<01:03,  5.98it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  26%|██▌       | 134/513 [00:07<00:22, 17.20it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 648/1026 [01:48<01:03,  5.99it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  27%|██▋       | 136/513 [00:07<00:21, 17.20it/s]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 650/1026 [01:48<01:02,  6.01it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  27%|██▋       | 138/513 [00:08<00:21, 17.20it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 652/1026 [01:48<01:02,  6.02it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  27%|██▋       | 140/513 [00:08<00:21, 17.20it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 654/1026 [01:48<01:01,  6.03it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  28%|██▊       | 142/513 [00:08<00:21, 17.20it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 656/1026 [01:48<01:01,  6.04it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  28%|██▊       | 144/513 [00:08<00:21, 17.20it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 658/1026 [01:48<01:00,  6.05it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  28%|██▊       | 146/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 660/1026 [01:48<01:00,  6.06it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  29%|██▉       | 148/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 662/1026 [01:48<00:59,  6.08it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  29%|██▉       | 150/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 664/1026 [01:49<00:59,  6.09it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  30%|██▉       | 152/513 [00:08<00:21, 17.19it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 666/1026 [01:49<00:59,  6.10it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  30%|███       | 154/513 [00:08<00:20, 17.19it/s]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 668/1026 [01:49<00:58,  6.11it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  65%|██████▌   | 670/1026 [01:49<00:58,  6.12it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  65%|██████▌   | 672/1026 [01:49<00:57,  6.14it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▌   | 674/1026 [01:49<00:57,  6.15it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▌   | 676/1026 [01:49<00:56,  6.16it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▌   | 678/1026 [01:49<00:56,  6.17it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▋   | 680/1026 [01:49<00:55,  6.18it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  66%|██████▋   | 682/1026 [01:50<00:55,  6.19it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  67%|██████▋   | 684/1026 [01:50<00:55,  6.21it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  67%|██████▋   | 686/1026 [01:50<00:54,  6.22it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  67%|██████▋   | 688/1026 [01:50<00:54,  6.23it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  67%|██████▋   | 690/1026 [01:50<00:53,  6.24it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  35%|███▍      | 178/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 692/1026 [01:50<00:53,  6.25it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  35%|███▌      | 180/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 694/1026 [01:50<00:53,  6.26it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  35%|███▌      | 182/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 696/1026 [01:50<00:52,  6.27it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  36%|███▌      | 184/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 698/1026 [01:51<00:52,  6.29it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  36%|███▋      | 186/513 [00:10<00:19, 17.17it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 700/1026 [01:51<00:51,  6.30it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  37%|███▋      | 188/513 [00:10<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 702/1026 [01:51<00:51,  6.31it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  37%|███▋      | 190/513 [00:11<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 704/1026 [01:51<00:50,  6.32it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  37%|███▋      | 192/513 [00:11<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 706/1026 [01:51<00:50,  6.33it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  38%|███▊      | 194/513 [00:11<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 708/1026 [01:51<00:50,  6.34it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  38%|███▊      | 196/513 [00:11<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 710/1026 [01:51<00:49,  6.35it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  39%|███▊      | 198/513 [00:11<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 712/1026 [01:51<00:49,  6.36it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  39%|███▉      | 200/513 [00:11<00:18, 17.17it/s]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 714/1026 [01:51<00:48,  6.38it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  70%|██████▉   | 716/1026 [01:52<00:48,  6.39it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  70%|██████▉   | 718/1026 [01:52<00:48,  6.40it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  70%|███████   | 720/1026 [01:52<00:47,  6.41it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  70%|███████   | 722/1026 [01:52<00:47,  6.42it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████   | 724/1026 [01:52<00:46,  6.43it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████   | 726/1026 [01:52<00:46,  6.44it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████   | 728/1026 [01:52<00:46,  6.45it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████   | 730/1026 [01:52<00:45,  6.46it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  71%|███████▏  | 732/1026 [01:53<00:45,  6.48it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  43%|████▎     | 220/513 [00:12<00:17, 17.16it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 734/1026 [01:53<00:45,  6.49it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  43%|████▎     | 222/513 [00:12<00:16, 17.16it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 736/1026 [01:53<00:44,  6.50it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  44%|████▎     | 224/513 [00:13<00:16, 17.16it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 738/1026 [01:53<00:44,  6.51it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  44%|████▍     | 226/513 [00:13<00:16, 17.16it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 740/1026 [01:53<00:43,  6.52it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  44%|████▍     | 228/513 [00:13<00:16, 17.16it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 742/1026 [01:53<00:43,  6.53it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  45%|████▍     | 230/513 [00:13<00:16, 17.16it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 744/1026 [01:53<00:43,  6.54it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  45%|████▌     | 232/513 [00:13<00:16, 17.16it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 746/1026 [01:53<00:42,  6.55it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  46%|████▌     | 234/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 748/1026 [01:53<00:42,  6.56it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  46%|████▌     | 236/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 750/1026 [01:54<00:41,  6.57it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  46%|████▋     | 238/513 [00:13<00:16, 17.15it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 752/1026 [01:54<00:41,  6.58it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  47%|████▋     | 240/513 [00:13<00:15, 17.15it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 754/1026 [01:54<00:41,  6.60it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  74%|███████▎  | 756/1026 [01:54<00:40,  6.61it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  74%|███████▍  | 758/1026 [01:54<00:40,  6.62it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  74%|███████▍  | 760/1026 [01:54<00:40,  6.63it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  74%|███████▍  | 762/1026 [01:54<00:39,  6.64it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  74%|███████▍  | 764/1026 [01:54<00:39,  6.65it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  75%|███████▍  | 766/1026 [01:55<00:39,  6.66it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  75%|███████▍  | 768/1026 [01:55<00:38,  6.67it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  50%|████▉     | 256/513 [00:14<00:14, 17.15it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 770/1026 [01:55<00:38,  6.68it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  50%|█████     | 258/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 772/1026 [01:55<00:37,  6.69it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  51%|█████     | 260/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 774/1026 [01:55<00:37,  6.70it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  51%|█████     | 262/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 776/1026 [01:55<00:37,  6.71it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  51%|█████▏    | 264/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 778/1026 [01:55<00:36,  6.72it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  52%|█████▏    | 266/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 780/1026 [01:55<00:36,  6.73it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  52%|█████▏    | 268/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 782/1026 [01:55<00:36,  6.74it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  53%|█████▎    | 270/513 [00:15<00:14, 17.14it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 784/1026 [01:56<00:35,  6.75it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  77%|███████▋  | 786/1026 [01:56<00:35,  6.76it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  77%|███████▋  | 788/1026 [01:56<00:35,  6.77it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  77%|███████▋  | 790/1026 [01:56<00:34,  6.78it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  77%|███████▋  | 792/1026 [01:56<00:34,  6.80it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  55%|█████▍    | 280/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 794/1026 [01:56<00:34,  6.81it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  55%|█████▍    | 282/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 796/1026 [01:56<00:33,  6.82it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  55%|█████▌    | 284/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 798/1026 [01:56<00:33,  6.83it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  56%|█████▌    | 286/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 800/1026 [01:57<00:33,  6.84it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  56%|█████▌    | 288/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 802/1026 [01:57<00:32,  6.85it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  57%|█████▋    | 290/513 [00:16<00:13, 17.14it/s]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 804/1026 [01:57<00:32,  6.86it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  57%|█████▋    | 292/513 [00:17<00:12, 17.13it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 806/1026 [01:57<00:32,  6.87it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  79%|███████▉  | 808/1026 [01:57<00:31,  6.88it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  79%|███████▉  | 810/1026 [01:57<00:31,  6.89it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  79%|███████▉  | 812/1026 [01:57<00:31,  6.90it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  79%|███████▉  | 814/1026 [01:57<00:30,  6.91it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  80%|███████▉  | 816/1026 [01:57<00:30,  6.92it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  80%|███████▉  | 818/1026 [01:58<00:30,  6.93it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  60%|█████▉    | 306/513 [00:17<00:12, 17.13it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 820/1026 [01:58<00:29,  6.94it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  60%|██████    | 308/513 [00:17<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 822/1026 [01:58<00:29,  6.95it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  60%|██████    | 310/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 824/1026 [01:58<00:29,  6.96it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  61%|██████    | 312/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 826/1026 [01:58<00:28,  6.97it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  61%|██████    | 314/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 828/1026 [01:58<00:28,  6.98it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  62%|██████▏   | 316/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 830/1026 [01:58<00:28,  6.99it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  62%|██████▏   | 318/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 832/1026 [01:58<00:27,  7.00it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  62%|██████▏   | 320/513 [00:18<00:11, 17.13it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 834/1026 [01:59<00:27,  7.01it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  81%|████████▏ | 836/1026 [01:59<00:27,  7.02it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  82%|████████▏ | 838/1026 [01:59<00:26,  7.03it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  82%|████████▏ | 840/1026 [01:59<00:26,  7.04it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  82%|████████▏ | 842/1026 [01:59<00:26,  7.05it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  82%|████████▏ | 844/1026 [01:59<00:25,  7.06it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  82%|████████▏ | 846/1026 [01:59<00:25,  7.07it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  83%|████████▎ | 848/1026 [01:59<00:25,  7.08it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  83%|████████▎ | 850/1026 [01:59<00:24,  7.09it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  66%|██████▌   | 338/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 852/1026 [02:00<00:24,  7.10it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  66%|██████▋   | 340/513 [00:19<00:10, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 854/1026 [02:00<00:24,  7.11it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  67%|██████▋   | 342/513 [00:19<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 856/1026 [02:00<00:23,  7.12it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  67%|██████▋   | 344/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 858/1026 [02:00<00:23,  7.12it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  67%|██████▋   | 346/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 860/1026 [02:00<00:23,  7.13it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  68%|██████▊   | 348/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 862/1026 [02:00<00:22,  7.14it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  68%|██████▊   | 350/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 864/1026 [02:00<00:22,  7.15it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  69%|██████▊   | 352/513 [00:20<00:09, 17.12it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 866/1026 [02:00<00:22,  7.16it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  85%|████████▍ | 868/1026 [02:01<00:22,  7.17it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  85%|████████▍ | 870/1026 [02:01<00:21,  7.18it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  85%|████████▍ | 872/1026 [02:01<00:21,  7.19it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  85%|████████▌ | 874/1026 [02:01<00:21,  7.20it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  85%|████████▌ | 876/1026 [02:01<00:20,  7.21it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  86%|████████▌ | 878/1026 [02:01<00:20,  7.22it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  71%|███████▏  | 366/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 880/1026 [02:01<00:20,  7.23it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  72%|███████▏  | 368/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 882/1026 [02:01<00:19,  7.24it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  72%|███████▏  | 370/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 884/1026 [02:01<00:19,  7.25it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  73%|███████▎  | 372/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 886/1026 [02:02<00:19,  7.26it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  73%|███████▎  | 374/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 888/1026 [02:02<00:18,  7.27it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  73%|███████▎  | 376/513 [00:21<00:08, 17.12it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 890/1026 [02:02<00:18,  7.28it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  74%|███████▎  | 378/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 892/1026 [02:02<00:18,  7.29it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  74%|███████▍  | 380/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 894/1026 [02:02<00:18,  7.30it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  74%|███████▍  | 382/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 896/1026 [02:02<00:17,  7.31it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  75%|███████▍  | 384/513 [00:22<00:07, 17.12it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 898/1026 [02:02<00:17,  7.31it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  88%|████████▊ | 900/1026 [02:02<00:17,  7.32it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  88%|████████▊ | 902/1026 [02:03<00:16,  7.33it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  88%|████████▊ | 904/1026 [02:03<00:16,  7.34it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  88%|████████▊ | 906/1026 [02:03<00:16,  7.35it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  88%|████████▊ | 908/1026 [02:03<00:16,  7.36it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  89%|████████▊ | 910/1026 [02:03<00:15,  7.37it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  89%|████████▉ | 912/1026 [02:03<00:15,  7.38it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  89%|████████▉ | 914/1026 [02:03<00:15,  7.39it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  78%|███████▊  | 402/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 916/1026 [02:03<00:14,  7.40it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  79%|███████▉  | 404/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 918/1026 [02:03<00:14,  7.41it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  79%|███████▉  | 406/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 920/1026 [02:04<00:14,  7.42it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  80%|███████▉  | 408/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 922/1026 [02:04<00:14,  7.42it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  80%|███████▉  | 410/513 [00:23<00:06, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 924/1026 [02:04<00:13,  7.43it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  80%|████████  | 412/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 926/1026 [02:04<00:13,  7.44it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  81%|████████  | 414/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 928/1026 [02:04<00:13,  7.45it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  81%|████████  | 416/513 [00:24<00:05, 17.11it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 930/1026 [02:04<00:12,  7.46it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  91%|█████████ | 932/1026 [02:04<00:12,  7.47it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  91%|█████████ | 934/1026 [02:04<00:12,  7.48it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  91%|█████████ | 936/1026 [02:04<00:12,  7.49it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  91%|█████████▏| 938/1026 [02:05<00:11,  7.50it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  92%|█████████▏| 940/1026 [02:05<00:11,  7.51it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  92%|█████████▏| 942/1026 [02:05<00:11,  7.51it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  92%|█████████▏| 944/1026 [02:05<00:10,  7.52it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  84%|████████▍ | 432/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 946/1026 [02:05<00:10,  7.53it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  85%|████████▍ | 434/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 948/1026 [02:05<00:10,  7.54it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  85%|████████▍ | 436/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 950/1026 [02:05<00:10,  7.55it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  85%|████████▌ | 438/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 952/1026 [02:05<00:09,  7.56it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  86%|████████▌ | 440/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 954/1026 [02:06<00:09,  7.57it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  86%|████████▌ | 442/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 956/1026 [02:06<00:09,  7.58it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  87%|████████▋ | 444/513 [00:25<00:04, 17.11it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 958/1026 [02:06<00:08,  7.59it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  87%|████████▋ | 446/513 [00:26<00:03, 17.11it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 960/1026 [02:06<00:08,  7.59it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  94%|█████████▍| 962/1026 [02:06<00:08,  7.60it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  94%|█████████▍| 964/1026 [02:06<00:08,  7.61it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  94%|█████████▍| 966/1026 [02:06<00:07,  7.62it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  94%|█████████▍| 968/1026 [02:06<00:07,  7.63it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  95%|█████████▍| 970/1026 [02:06<00:07,  7.64it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  95%|█████████▍| 972/1026 [02:07<00:07,  7.65it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  95%|█████████▍| 974/1026 [02:07<00:06,  7.66it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  90%|█████████ | 462/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 976/1026 [02:07<00:06,  7.66it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  90%|█████████ | 464/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 978/1026 [02:07<00:06,  7.67it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  91%|█████████ | 466/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 980/1026 [02:07<00:05,  7.68it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  91%|█████████ | 468/513 [00:27<00:02, 17.11it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 982/1026 [02:07<00:05,  7.69it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  92%|█████████▏| 470/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 984/1026 [02:07<00:05,  7.70it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  92%|█████████▏| 472/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 986/1026 [02:07<00:05,  7.71it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  92%|█████████▏| 474/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 988/1026 [02:08<00:04,  7.72it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  93%|█████████▎| 476/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 990/1026 [02:08<00:04,  7.72it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  93%|█████████▎| 478/513 [00:27<00:02, 17.10it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 992/1026 [02:08<00:04,  7.73it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  97%|█████████▋| 994/1026 [02:08<00:04,  7.74it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  97%|█████████▋| 996/1026 [02:08<00:03,  7.75it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  97%|█████████▋| 998/1026 [02:08<00:03,  7.76it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  97%|█████████▋| 1000/1026 [02:08<00:03,  7.77it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  98%|█████████▊| 1002/1026 [02:08<00:03,  7.78it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  98%|█████████▊| 1004/1026 [02:08<00:02,  7.78it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Epoch 1:  98%|█████████▊| 1006/1026 [02:09<00:02,  7.79it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0:  96%|█████████▋| 494/513 [00:28<00:01, 17.10it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1008/1026 [02:09<00:02,  7.80it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  97%|█████████▋| 496/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 1010/1026 [02:09<00:02,  7.81it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  97%|█████████▋| 498/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 1012/1026 [02:09<00:01,  7.82it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  97%|█████████▋| 500/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1014/1026 [02:09<00:01,  7.83it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  98%|█████████▊| 502/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1016/1026 [02:09<00:01,  7.83it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  98%|█████████▊| 504/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1018/1026 [02:09<00:01,  7.84it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  99%|█████████▊| 506/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 1020/1026 [02:09<00:00,  7.85it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  99%|█████████▉| 508/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1022/1026 [02:10<00:00,  7.86it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Validation DataLoader 0:  99%|█████████▉| 510/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 1024/1026 [02:10<00:00,  7.87it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m \n",
      "Validation DataLoader 0: 100%|█████████▉| 512/513 [00:29<00:00, 17.10it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 1026/1026 [02:10<00:00,  7.88it/s, loss=0.605, v_num=0, train_loss=0.635, val_loss=0.620, val_score=0.507, test_loss=0.570]\n",
      "Trial trainable_9a289_00000 reported val_score=0.61 with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 32, 'epochs': 2, 'n_fold': 2, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'distilbert-base-uncased'}.\n",
      "Epoch 1: 100%|██████████| 1026/1026 [02:10<00:00,  7.87it/s, loss=0.607, v_num=0, train_loss=0.577, val_loss=0.600, val_score=0.613, test_loss=0.570]\n",
      "Epoch 1: 100%|██████████| 1026/1026 [02:10<00:00,  7.87it/s, loss=0.607, v_num=0, train_loss=0.577, val_loss=0.600, val_score=0.613, test_loss=0.570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Epoch 1, global step 2052: 'val_loss' was not in top 1\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m `Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]0669)\u001b[0m \n",
      "Testing DataLoader 0:   2%|▏         | 2/114 [00:00<00:03, 29.50it/s]\n",
      "Testing DataLoader 0:   4%|▎         | 4/114 [00:00<00:05, 21.62it/s]\n",
      "Testing DataLoader 0:   5%|▌         | 6/114 [00:00<00:05, 19.85it/s]\n",
      "Testing DataLoader 0:   7%|▋         | 8/114 [00:00<00:05, 19.07it/s]\n",
      "Testing DataLoader 0:   9%|▉         | 10/114 [00:00<00:05, 18.64it/s]\n",
      "Testing DataLoader 0:  11%|█         | 12/114 [00:00<00:05, 18.34it/s]\n",
      "Testing DataLoader 0:  12%|█▏        | 14/114 [00:00<00:05, 18.15it/s]\n",
      "Testing DataLoader 0:  14%|█▍        | 16/114 [00:00<00:05, 17.99it/s]\n",
      "Testing DataLoader 0:  16%|█▌        | 18/114 [00:01<00:05, 17.89it/s]\n",
      "Testing DataLoader 0:  18%|█▊        | 20/114 [00:01<00:05, 17.81it/s]\n",
      "Testing DataLoader 0:  19%|█▉        | 22/114 [00:01<00:05, 17.74it/s]\n",
      "Testing DataLoader 0:  21%|██        | 24/114 [00:01<00:05, 17.68it/s]\n",
      "Testing DataLoader 0:  23%|██▎       | 26/114 [00:01<00:04, 17.63it/s]\n",
      "Testing DataLoader 0:  25%|██▍       | 28/114 [00:01<00:04, 17.59it/s]\n",
      "Testing DataLoader 0:  26%|██▋       | 30/114 [00:01<00:04, 17.55it/s]\n",
      "Testing DataLoader 0:  28%|██▊       | 32/114 [00:01<00:04, 17.52it/s]\n",
      "Testing DataLoader 0:  30%|██▉       | 34/114 [00:01<00:04, 17.49it/s]\n",
      "Testing DataLoader 0:  32%|███▏      | 36/114 [00:02<00:04, 17.47it/s]\n",
      "Testing DataLoader 0:  33%|███▎      | 38/114 [00:02<00:04, 17.44it/s]\n",
      "Testing DataLoader 0:  35%|███▌      | 40/114 [00:02<00:04, 17.42it/s]\n",
      "Testing DataLoader 0:  37%|███▋      | 42/114 [00:02<00:04, 17.40it/s]\n",
      "Testing DataLoader 0:  39%|███▊      | 44/114 [00:02<00:04, 17.39it/s]\n",
      "Testing DataLoader 0:  40%|████      | 46/114 [00:02<00:03, 17.38it/s]\n",
      "Testing DataLoader 0:  42%|████▏     | 48/114 [00:02<00:03, 17.36it/s]\n",
      "Testing DataLoader 0:  44%|████▍     | 50/114 [00:02<00:03, 17.34it/s]\n",
      "Testing DataLoader 0:  46%|████▌     | 52/114 [00:03<00:03, 17.33it/s]\n",
      "Testing DataLoader 0:  47%|████▋     | 54/114 [00:03<00:03, 17.32it/s]\n",
      "Testing DataLoader 0:  49%|████▉     | 56/114 [00:03<00:03, 17.31it/s]\n",
      "Testing DataLoader 0:  51%|█████     | 58/114 [00:03<00:03, 17.30it/s]\n",
      "Testing DataLoader 0:  53%|█████▎    | 60/114 [00:03<00:03, 17.29it/s]\n",
      "Testing DataLoader 0:  54%|█████▍    | 62/114 [00:03<00:03, 17.28it/s]\n",
      "Testing DataLoader 0:  56%|█████▌    | 64/114 [00:03<00:02, 17.27it/s]\n",
      "Testing DataLoader 0:  58%|█████▊    | 66/114 [00:03<00:02, 17.27it/s]\n",
      "Testing DataLoader 0:  60%|█████▉    | 68/114 [00:03<00:02, 17.26it/s]\n",
      "Testing DataLoader 0:  61%|██████▏   | 70/114 [00:04<00:02, 17.26it/s]\n",
      "Testing DataLoader 0:  63%|██████▎   | 72/114 [00:04<00:02, 17.25it/s]\n",
      "Testing DataLoader 0:  65%|██████▍   | 74/114 [00:04<00:02, 17.24it/s]\n",
      "Testing DataLoader 0:  67%|██████▋   | 76/114 [00:04<00:02, 17.24it/s]\n",
      "Testing DataLoader 0:  68%|██████▊   | 78/114 [00:04<00:02, 17.23it/s]\n",
      "Testing DataLoader 0:  70%|███████   | 80/114 [00:04<00:01, 17.23it/s]\n",
      "Testing DataLoader 0:  72%|███████▏  | 82/114 [00:04<00:01, 17.22it/s]\n",
      "Testing DataLoader 0:  74%|███████▎  | 84/114 [00:04<00:01, 17.22it/s]\n",
      "Testing DataLoader 0:  75%|███████▌  | 86/114 [00:04<00:01, 17.22it/s]\n",
      "Testing DataLoader 0:  77%|███████▋  | 88/114 [00:05<00:01, 17.22it/s]\n",
      "Testing DataLoader 0:  79%|███████▉  | 90/114 [00:05<00:01, 17.21it/s]\n",
      "Testing DataLoader 0:  81%|████████  | 92/114 [00:05<00:01, 17.21it/s]\n",
      "Testing DataLoader 0:  82%|████████▏ | 94/114 [00:05<00:01, 17.21it/s]\n",
      "Testing DataLoader 0:  84%|████████▍ | 96/114 [00:05<00:01, 17.20it/s]\n",
      "Testing DataLoader 0:  86%|████████▌ | 98/114 [00:05<00:00, 17.20it/s]\n",
      "Testing DataLoader 0:  88%|████████▊ | 100/114 [00:05<00:00, 17.20it/s]\n",
      "Testing DataLoader 0:  89%|████████▉ | 102/114 [00:05<00:00, 17.19it/s]\n",
      "Testing DataLoader 0:  91%|█████████ | 104/114 [00:06<00:00, 17.19it/s]\n",
      "Testing DataLoader 0:  93%|█████████▎| 106/114 [00:06<00:00, 17.19it/s]\n",
      "Testing DataLoader 0:  95%|█████████▍| 108/114 [00:06<00:00, 17.19it/s]\n",
      "Testing DataLoader 0:  96%|█████████▋| 110/114 [00:06<00:00, 17.18it/s]\n",
      "Testing DataLoader 0:  98%|█████████▊| 112/114 [00:06<00:00, 17.18it/s]\n",
      "Testing DataLoader 0: 100%|██████████| 114/114 [00:06<00:00, 17.03it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m │         test_loss         │    0.5968436002731323     │\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m └───────────────────────────┴───────────────────────────┘\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m TEST for FOLD 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m - This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m - This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m - This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m - This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]0669)\u001b[0m \n",
      "Testing DataLoader 0:   0%|          | 0/114 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.56372154\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7995018533256664\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.60622925\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6143701551356964\n",
      "Testing DataLoader 0:   2%|▏         | 2/114 [00:00<00:14,  7.52it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5947206\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6905487889089901\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.62885976\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6951448590934086\n",
      "Testing DataLoader 0:   4%|▎         | 4/114 [00:00<00:14,  7.59it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.57747805\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7470142109821758\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61968285\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6464418795335194\n",
      "Testing DataLoader 0:   5%|▌         | 6/114 [00:00<00:13,  7.82it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.52742344\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7624055492552358\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5574943\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7959086341026769\n",
      "Testing DataLoader 0:   7%|▋         | 8/114 [00:01<00:13,  7.96it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5519791\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.776006078706355\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5707735\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6587381453053931\n",
      "Testing DataLoader 0:   9%|▉         | 10/114 [00:01<00:12,  8.04it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6460458\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6911105988976524\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5867444\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7365621040614582\n",
      "Testing DataLoader 0:  11%|█         | 12/114 [00:01<00:12,  8.07it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.60661453\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6380739092122383\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6348861\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5416709594764133\n",
      "Testing DataLoader 0:  12%|█▏        | 14/114 [00:01<00:12,  8.05it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5141532\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8324666106569214\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.58467054\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6113362394923867\n",
      "Testing DataLoader 0:  14%|█▍        | 16/114 [00:01<00:12,  8.08it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5889641\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.727216476618279\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61287344\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5837472206072184\n",
      "Testing DataLoader 0:  16%|█▌        | 18/114 [00:02<00:11,  8.11it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5588083\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7837597225870201\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.54442585\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6924507658636421\n",
      "Testing DataLoader 0:  18%|█▊        | 20/114 [00:02<00:11,  8.07it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5693605\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6934047367000704\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.54699445\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7719354011871927\n",
      "Testing DataLoader 0:  19%|█▉        | 22/114 [00:02<00:11,  8.09it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.58155423\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5981393895363497\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.589734\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7029642658021626\n",
      "Testing DataLoader 0:  21%|██        | 24/114 [00:02<00:11,  8.12it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6103052\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5540204139282383\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5827919\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7094405133590196\n",
      "Testing DataLoader 0:  23%|██▎       | 26/114 [00:03<00:10,  8.14it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5790449\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.44540099190774995\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.56044054\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7317403896317545\n",
      "Testing DataLoader 0:  25%|██▍       | 28/114 [00:03<00:10,  8.14it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6370608\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5976539933214857\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6260666\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7450332779746954\n",
      "Testing DataLoader 0:  26%|██▋       | 30/114 [00:03<00:10,  8.13it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61799216\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5973578193031832\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5849086\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7361420816584461\n",
      "Testing DataLoader 0:  28%|██▊       | 32/114 [00:03<00:10,  8.13it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.4851179\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8458827405390228\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5761217\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5963719369218361\n",
      "Testing DataLoader 0:  30%|██▉       | 34/114 [00:04<00:09,  8.15it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.51442266\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7089022751924235\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.582636\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6212699136641509\n",
      "Testing DataLoader 0:  32%|███▏      | 36/114 [00:04<00:09,  8.14it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6420854\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5169774318401142\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.59378874\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5202037176404098\n",
      "Testing DataLoader 0:  33%|███▎      | 38/114 [00:04<00:09,  8.15it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5140041\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6693073588720555\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5669507\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7139611605858975\n",
      "Testing DataLoader 0:  35%|███▌      | 40/114 [00:04<00:09,  8.16it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5352197\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7193439132179344\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5802454\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5379965626291927\n",
      "Testing DataLoader 0:  37%|███▋      | 42/114 [00:05<00:08,  8.17it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.52449775\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7013886332819732\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6401652\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5943193758969502\n",
      "Testing DataLoader 0:  39%|███▊      | 44/114 [00:05<00:08,  8.17it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5536356\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5630160148981778\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.51974344\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8268603473373518\n",
      "Testing DataLoader 0:  40%|████      | 46/114 [00:05<00:08,  8.16it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.58418673\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6718487522846864\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.63320017\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5328575038389531\n",
      "Testing DataLoader 0:  42%|████▏     | 48/114 [00:05<00:08,  8.16it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6454369\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6289443987440264\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6557056\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5341603313666926\n",
      "Testing DataLoader 0:  44%|████▍     | 50/114 [00:06<00:07,  8.17it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5639777\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8053947290553876\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.56734675\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7500429923759343\n",
      "Testing DataLoader 0:  46%|████▌     | 52/114 [00:06<00:07,  8.17it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6462195\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5795597106683541\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.533116\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8154834336044277\n",
      "Testing DataLoader 0:  47%|████▋     | 54/114 [00:06<00:07,  8.17it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.564154\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8355980127621572\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.579546\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6242200346915987\n",
      "Testing DataLoader 0:  49%|████▉     | 56/114 [00:06<00:07,  8.18it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6208875\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6069784328735508\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5976836\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5363440132174054\n",
      "Testing DataLoader 0:  51%|█████     | 58/114 [00:07<00:06,  8.19it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.56680834\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.757311562182682\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.590969\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6839499713340005\n",
      "Testing DataLoader 0:  53%|█████▎    | 60/114 [00:07<00:06,  8.19it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.58707786\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6740786436545663\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5583507\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6907389451295748\n",
      "Testing DataLoader 0:  54%|█████▍    | 62/114 [00:07<00:06,  8.18it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5967401\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6240567745482899\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5718072\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8503036520598702\n",
      "Testing DataLoader 0:  56%|█████▌    | 64/114 [00:07<00:06,  8.18it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.48667258\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7651769184673629\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6270546\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5727151311226454\n",
      "Testing DataLoader 0:  58%|█████▊    | 66/114 [00:08<00:05,  8.19it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5684981\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6862692438110438\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.60041356\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5506666083215004\n",
      "Testing DataLoader 0:  60%|█████▉    | 68/114 [00:08<00:05,  8.19it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.64465946\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.634565054177884\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.60660976\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6660083360132569\n",
      "Testing DataLoader 0:  61%|██████▏   | 70/114 [00:08<00:05,  8.20it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61935854\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5597118494360804\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.57790124\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5794075839059958\n",
      "Testing DataLoader 0:  63%|██████▎   | 72/114 [00:08<00:05,  8.20it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5727595\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7747781853352713\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5983629\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.49437829812980455\n",
      "Testing DataLoader 0:  65%|██████▍   | 74/114 [00:09<00:04,  8.20it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6009151\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.743124449463723\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.57899666\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7737881338738524\n",
      "Testing DataLoader 0:  67%|██████▋   | 76/114 [00:09<00:04,  8.20it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5816925\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7302992546405046\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5700966\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.617355767391636\n",
      "Testing DataLoader 0:  68%|██████▊   | 78/114 [00:09<00:04,  8.19it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6188682\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5641020018527066\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5519804\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.665615718164025\n",
      "Testing DataLoader 0:  70%|███████   | 80/114 [00:09<00:04,  8.19it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.60376966\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7165930314202225\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6948011\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.19478358635274656\n",
      "Testing DataLoader 0:  72%|███████▏  | 82/114 [00:10<00:03,  8.20it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.58919317\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6642453765616163\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5620145\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7222030002441702\n",
      "Testing DataLoader 0:  74%|███████▎  | 84/114 [00:10<00:03,  8.20it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.55388933\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6845537947989235\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.4961779\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8698831757123857\n",
      "Testing DataLoader 0:  75%|███████▌  | 86/114 [00:10<00:03,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.57209367\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6836046389489363\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5929377\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7372215591069291\n",
      "Testing DataLoader 0:  77%|███████▋  | 88/114 [00:10<00:03,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5899585\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7650102157067908\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6599338\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5466266805515658\n",
      "Testing DataLoader 0:  79%|███████▉  | 90/114 [00:10<00:02,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5805741\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7925469983101812\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61508894\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.46665879071740746\n",
      "Testing DataLoader 0:  81%|████████  | 92/114 [00:11<00:02,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6003444\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7642610951484623\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61722755\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5658496854813402\n",
      "Testing DataLoader 0:  82%|████████▏ | 94/114 [00:11<00:02,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.546939\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7061891767224042\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5190737\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6258757064348246\n",
      "Testing DataLoader 0:  84%|████████▍ | 96/114 [00:11<00:02,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5086726\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7486636862664664\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5989636\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6533920715019654\n",
      "Testing DataLoader 0:  86%|████████▌ | 98/114 [00:11<00:01,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.51394916\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.715377330968353\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.59415483\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7672535913969915\n",
      "Testing DataLoader 0:  88%|████████▊ | 100/114 [00:12<00:01,  8.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5809133\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6661226828598662\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5728631\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7095393008361819\n",
      "Testing DataLoader 0:  89%|████████▉ | 102/114 [00:12<00:01,  8.22it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.64951617\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.48724470947096193\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.49596938\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.8549663012496048\n",
      "Testing DataLoader 0:  91%|█████████ | 104/114 [00:12<00:01,  8.22it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.63215435\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.4800657099071967\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5458527\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7965742738660637\n",
      "Testing DataLoader 0:  93%|█████████▎| 106/114 [00:12<00:00,  8.22it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5836866\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5510194203650596\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5822118\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7846390865081427\n",
      "Testing DataLoader 0:  95%|█████████▍| 108/114 [00:13<00:00,  8.22it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.59368616\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7477542823461168\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.61502194\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.6674037417551347\n",
      "Testing DataLoader 0:  96%|█████████▋| 110/114 [00:13<00:00,  8.22it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.5628225\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5638395538597589\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.57812774\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.7450282228295876\n",
      "Testing DataLoader 0:  98%|█████████▊| 112/114 [00:13<00:00,  8.23it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6195612\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.586087162614728\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_loss 0.6300204\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ensemble_avg_score 0.5650148045872492\n",
      "Testing DataLoader 0: 100%|██████████| 114/114 [00:13<00:00,  8.23it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┃        Test metric        ┃       DataLoader 0        ┃\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m │     ensemble_avg_loss     │    0.5834354758262634     │\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m │    ensemble_avg_score     │     0.668591546425947     │\n",
      "\u001b[2m\u001b[36m(trainable pid=3350669)\u001b[0m └───────────────────────────┴───────────────────────────┘\n",
      "Trial trainable_9a289_00000 completed. Last result: val_score=0.6134706616697575,train_loss=0.5767638087272644,val_loss=0.6001981496810913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 00:01:10,495\tINFO tune.py:758 -- Total run time: 628.11 seconds (627.63 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'val_score': 0.6134706616697575, 'train_loss': 0.5767638087272644, 'val_loss': 0.6001981496810913, 'done': True, 'trial_id': '9a289_00000', 'experiment_tag': '0_model=distilbert-base-uncased'}, error=None, log_dir=PosixPath('/storagenfs/m.petix/ray_results/tune_uspppm/trainable_9a289_00000_0_model=distilbert-base-uncased_2022-11-13_23-50-43'))\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result()  # Get best result object\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf0fc4bd-5ca4-43a1-af65-ac34eb9205ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46525d24-c57d-445c-9781-5af54ca0b8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebc2fef-2f13-4d18-93dc-a56a8ddcc7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe for the last reported results of all of the trials \n",
    "df = results.get_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a16ec5b2-9599-4530-84ce-b569fd51481a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('grid_search_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
