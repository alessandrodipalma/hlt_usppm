{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2239c1-e1b6-46be-8734-f1a3298fb062",
   "metadata": {},
   "source": [
    "# Pip Wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddb3b1f-8cf9-4ead-895f-9a5768440183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pytorch_lightning\\n!pip install torchmetrics\\n!pip install tokenizers\\n!pip install transformers\\n!pip install ray[tune]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install pytorch_lightning\n",
    "!pip install torchmetrics\n",
    "!pip install tokenizers\n",
    "!pip install transformers\n",
    "!pip install ray[tune]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc890c3d-d9af-45d0-a1df-36462ffdf4b7",
   "metadata": {
    "id": "ICgrtlaznr7F"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba724d89-aea8-4bf1-bd16-1380bcdce9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUiP-rVLnr7H",
    "outputId": "79dc16d8-54ad-42df-a406-ef7564341a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar \n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ray[Tune]\n",
    "import ray\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "\n",
    "import torch\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "#out code \n",
    "from kfold_loop import KFoldLoop\n",
    "from USPPM_model import USPPPM_model\n",
    "from USPPM_dataset import set_tokenizer, set_max_len\n",
    "from USPPM_kfold_datamodule import USPPPM_kf_datamodule\n",
    "\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.utilities.memory import garbage_collection_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62987669-6371-4c97-ad66-daaa32aa12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afdc09-2e7d-412d-9cbf-39e104819dad",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5fc28-1a0b-4c86-9da6-e156d4e88d13",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Class: notebook-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca2dbb5-92b6-4d04-b479-223aaeb390d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # General\n",
    "    seed = 42\n",
    "    \n",
    "    # Debug \n",
    "    debug = False\n",
    "    debug_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ccc5e-ced9-4c6b-ba6c-29e7ed9ffbac",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Dictionary: trial-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9985db04-ae1c-492c-9cca-eeac1b209381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a search space!\n",
    "config_dict = {\n",
    "    \"target_size\" : 1,\n",
    "    \"num_workers\" : 16,\n",
    "    \n",
    "    # Training parameters\n",
    "    \"batch_size\" : tune.grid_search([4,8,16,32,64,128]),\n",
    "    \"epochs\" : 2,\n",
    "    \"n_fold\" : tune.grid_search([8,16,32]),\n",
    "    \"warmup_steps\" : 0,\n",
    "    \"min_lr\" : 1e-6,\n",
    "    \"encoder_lr\" : 2e-5,\n",
    "    \"decoder_lr\" : 2e-5,\n",
    "    \"eps\" : 1e-6,\n",
    "    \"betas\" : (0.9, 0.999),\n",
    "    \"weight_decay\" : 0.01,\n",
    "    \"fc_dropout\" : 0.2,\n",
    "    \"seed\" : 42,\n",
    "\n",
    "    # Transformers\n",
    "    # \"model\" : tune.choice([\"microsoft/deberta-v3-large\"]),\n",
    "    #\"model\" : tune.choice([\"distilbert-base-uncased\"]),\n",
    "    \"model\" : tune.grid_search([\"AI-Growth-Lab/PatentSBERTa\",\"distilbert-base-uncased\",\"ahotrod/electra_large_discriminator_squad2_512\",\n",
    "                                \"Yanhao/simcse-bert-for-patent\",\"microsoft/deberta-v3-large\",\"anferico/bert-for-patents\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd0738-9bbe-4d25-8510-aaf5a7110750",
   "metadata": {
    "id": "iIVnbwmdnr7K"
   },
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5da60d-3f9b-4ea6-9254-dc40d402afce",
   "metadata": {
    "id": "JaQ5oUkRnr7N"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../dataset/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f8751-79fe-492a-a1c8-eb35867f3909",
   "metadata": {
    "id": "IeqIEukjnr7W"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca74519-9ccd-48be-ba61-67466fceea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id     anchor                  target context  \\\n",
       "0           0  37d61fd2272659b1  abatement  abatement of pollution     A47   \n",
       "1           1  7b9652b17b68b7a4  abatement          act of abating     A47   \n",
       "2           2  36d72442aefd8232  abatement         active catalyst     A47   \n",
       "3           3  5296b0c19e1ce60e  abatement     eliminating process     A47   \n",
       "4           4  54c1e3b9184cb5b6  abatement           forest region     A47   \n",
       "\n",
       "   score                                       context_text  \\\n",
       "0   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "1   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "2   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "3   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "4   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "\n",
       "                                                text  score_map  \n",
       "0  abatement[SEP]abatement of pollution[SEP]HUMAN...          2  \n",
       "1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...          3  \n",
       "2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...          1  \n",
       "3  abatement[SEP]eliminating process[SEP]HUMAN NE...          2  \n",
       "4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc_texts = torch.load('cpc_texts.pth')\n",
    "dataframe = pd.read_csv(\"dataframe.csv\")\n",
    "display(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17be84-7e8e-4cc8-99a5-5b5835d9984c",
   "metadata": {},
   "source": [
    "## Debug Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8036555-0930-4a1e-a4e6-fb088d201ced",
   "metadata": {
    "id": "6zeWhBTmvC2N"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    dataframe = dataframe.iloc[:CFG.debug_samples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc687c3-b2d5-4ad1-b872-bc08c0edea4e",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f8730b-3f39-46bb-ad8d-28521a3aa08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9900</td>\n",
       "      <td>0dbb44b9a145edec</td>\n",
       "      <td>distributor pipe</td>\n",
       "      <td>pipe</td>\n",
       "      <td>B01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...</td>\n",
       "      <td>distributor pipe[SEP]pipe[SEP]PERFORMING OPERA...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1303</td>\n",
       "      <td>74afca34a5439c23</td>\n",
       "      <td>ammonia recovery</td>\n",
       "      <td>recovery of water</td>\n",
       "      <td>C01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HEMISTRY; METALLURGY. INORGANIC CHEMISTRY</td>\n",
       "      <td>ammonia recovery[SEP]recovery of water[SEP]HEM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16591</th>\n",
       "      <td>16591</td>\n",
       "      <td>6371befc3ee1b0f2</td>\n",
       "      <td>inner closed</td>\n",
       "      <td>cylindrical inner member</td>\n",
       "      <td>E04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>FIXED CONSTRUCTIONS. BUILDING</td>\n",
       "      <td>inner closed[SEP]cylindrical inner member[SEP]...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25822</th>\n",
       "      <td>25822</td>\n",
       "      <td>20489196c73bd86b</td>\n",
       "      <td>produce thin layers</td>\n",
       "      <td>produce layers</td>\n",
       "      <td>G01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PHYSICS. MEASURING; TESTING</td>\n",
       "      <td>produce thin layers[SEP]produce layers[SEP]PHY...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23640</th>\n",
       "      <td>23640</td>\n",
       "      <td>9af994b21c892022</td>\n",
       "      <td>parallel orientation</td>\n",
       "      <td>zero angle</td>\n",
       "      <td>G06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>PHYSICS. COMPUTING; CALCULATING; COUNTING</td>\n",
       "      <td>parallel orientation[SEP]zero angle[SEP]PHYSIC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                id                anchor  \\\n",
       "9900         9900  0dbb44b9a145edec      distributor pipe   \n",
       "1303         1303  74afca34a5439c23      ammonia recovery   \n",
       "16591       16591  6371befc3ee1b0f2          inner closed   \n",
       "25822       25822  20489196c73bd86b   produce thin layers   \n",
       "23640       23640  9af994b21c892022  parallel orientation   \n",
       "\n",
       "                         target context  score  \\\n",
       "9900                       pipe     B01   0.50   \n",
       "1303          recovery of water     C01   0.25   \n",
       "16591  cylindrical inner member     E04   0.50   \n",
       "25822            produce layers     G01   0.50   \n",
       "23640                zero angle     G06   0.25   \n",
       "\n",
       "                                            context_text  \\\n",
       "9900   PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...   \n",
       "1303           HEMISTRY; METALLURGY. INORGANIC CHEMISTRY   \n",
       "16591                      FIXED CONSTRUCTIONS. BUILDING   \n",
       "25822                        PHYSICS. MEASURING; TESTING   \n",
       "23640          PHYSICS. COMPUTING; CALCULATING; COUNTING   \n",
       "\n",
       "                                                    text  score_map  \n",
       "9900   distributor pipe[SEP]pipe[SEP]PERFORMING OPERA...          2  \n",
       "1303   ammonia recovery[SEP]recovery of water[SEP]HEM...          1  \n",
       "16591  inner closed[SEP]cylindrical inner member[SEP]...          2  \n",
       "25822  produce thin layers[SEP]produce layers[SEP]PHY...          2  \n",
       "23640  parallel orientation[SEP]zero angle[SEP]PHYSIC...          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33511</th>\n",
       "      <td>33511</td>\n",
       "      <td>ed1c4e525eb105fe</td>\n",
       "      <td>transmit alarm</td>\n",
       "      <td>display indicator</td>\n",
       "      <td>G08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PHYSICS. SIGNALLING</td>\n",
       "      <td>transmit alarm[SEP]display indicator[SEP]PHYSI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18670</th>\n",
       "      <td>18670</td>\n",
       "      <td>5386316f318f5221</td>\n",
       "      <td>locking formation</td>\n",
       "      <td>retaining element</td>\n",
       "      <td>B60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n",
       "      <td>locking formation[SEP]retaining element[SEP]PE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>1544ca6753fcbddd</td>\n",
       "      <td>lateral power</td>\n",
       "      <td>transducer</td>\n",
       "      <td>H01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ELECTRICITY. BASIC ELECTRIC ELEMENTS</td>\n",
       "      <td>lateral power[SEP]transducer[SEP]ELECTRICITY. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>31660</td>\n",
       "      <td>f9d8979b94cec923</td>\n",
       "      <td>spreader body</td>\n",
       "      <td>spreader</td>\n",
       "      <td>A01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>HUMAN NECESSITIES. GRICULTURE; FORESTRY; ANIMA...</td>\n",
       "      <td>spreader body[SEP]spreader[SEP]HUMAN NECESSITI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15573</th>\n",
       "      <td>15573</td>\n",
       "      <td>e151ca5ea5cc0f08</td>\n",
       "      <td>high gradient magnetic separators</td>\n",
       "      <td>magnetic filtration</td>\n",
       "      <td>B03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. SEPARATIO...</td>\n",
       "      <td>high gradient magnetic separators[SEP]magnetic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                id                             anchor  \\\n",
       "33511       33511  ed1c4e525eb105fe                     transmit alarm   \n",
       "18670       18670  5386316f318f5221                  locking formation   \n",
       "18049       18049  1544ca6753fcbddd                      lateral power   \n",
       "31660       31660  f9d8979b94cec923                      spreader body   \n",
       "15573       15573  e151ca5ea5cc0f08  high gradient magnetic separators   \n",
       "\n",
       "                    target context  score  \\\n",
       "33511    display indicator     G08   0.00   \n",
       "18670    retaining element     B60   0.25   \n",
       "18049           transducer     H01   0.25   \n",
       "31660             spreader     A01   0.75   \n",
       "15573  magnetic filtration     B03   0.50   \n",
       "\n",
       "                                            context_text  \\\n",
       "33511                                PHYSICS. SIGNALLING   \n",
       "18670  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...   \n",
       "18049               ELECTRICITY. BASIC ELECTRIC ELEMENTS   \n",
       "31660  HUMAN NECESSITIES. GRICULTURE; FORESTRY; ANIMA...   \n",
       "15573  PERFORMING OPERATIONS; TRANSPORTING. SEPARATIO...   \n",
       "\n",
       "                                                    text  score_map  \n",
       "33511  transmit alarm[SEP]display indicator[SEP]PHYSI...          0  \n",
       "18670  locking formation[SEP]retaining element[SEP]PE...          1  \n",
       "18049  lateral power[SEP]transducer[SEP]ELECTRICITY. ...          1  \n",
       "31660  spreader body[SEP]spreader[SEP]HUMAN NECESSITI...          3  \n",
       "15573  high gradient magnetic separators[SEP]magnetic...          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed, stratify = dataframe.score_map)\n",
    "train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563fc01-1170-43cf-ac1b-f577730cf1a6",
   "metadata": {
    "id": "fK6gpNx1nr7q"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b10ba-6205-419f-844f-0fe5b9dc07d0",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990e45de-3f45-42f3-b6d9-37e5bfad651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 16:48:31,824\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '131.114.50.210', 'raylet_ip_address': '131.114.50.210', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-14_16-48-30_317841_4154123/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-14_16-48-30_317841_4154123/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-14_16-48-30_317841_4154123', 'metrics_export_port': 64079, 'gcs_address': '131.114.50.210:57631', 'address': '131.114.50.210:57631', 'dashboard_agent_listen_port': 52365, 'node_id': '1e25dc4746387810fe6469f5b9bb5999fedf5a2d593054ba2d341b65'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f7ea00-b260-41fd-a636-159e38b66fa8",
   "metadata": {
    "id": "fAEhe31znr7q"
   },
   "outputs": [],
   "source": [
    "metrics = {\"val_score\": \"val_score\", \"train_loss\" : \"train_loss\", \"val_loss\" : \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "143d9932-bb80-433c-b534-9464d9729443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config_dict):  # Pass a \"config\" dictionary into your trainable.\n",
    "    garbage_collection_cuda()\n",
    "    \n",
    "    trial_id = ray.air.session.get_trial_id()\n",
    "    logging_dir = f\"USPPPM_{trial_id}\"\n",
    "    \n",
    "    export_path = f'./ensemble_checkpoints/{trial_id}'\n",
    "    \n",
    "    for d in [\"ensemble_checkpoints/\",export_path,\"lightning_logs\",f\"lightning_logs/{logging_dir}\"]:\n",
    "        try:\n",
    "            os.mkdir(d)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "    \n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=logging_dir)\n",
    "    pl.seed_everything(CFG.seed)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"checkpoints/{trial_id}_checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    steps_per_epoch = len(train_df) // config_dict['batch_size']\n",
    "    config_dict['training_steps'] = steps_per_epoch * config_dict['epochs']\n",
    "    \n",
    "    set_tokenizer(config_dict, OUTPUT_DIR)\n",
    "    set_max_len(config_dict, cpc_texts, dataframe)\n",
    "    # train_dataset = USPPM_dataset(config_dict)\n",
    "    datamodule = USPPPM_kf_datamodule(config_dict, dataframe)\n",
    "    \n",
    "    model = USPPPM_model(config_dict)\n",
    "    \n",
    "    callbacks = [TuneReportCallback(metrics, on=\"validation_end\"), checkpoint_callback, early_stopping_callback]\n",
    "    trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            check_val_every_n_epoch=1,\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=config_dict['epochs'],\n",
    "            #devices=[1],\n",
    "            accelerator=\"gpu\",\n",
    "            )\n",
    "    \n",
    "    internal_fit_loop = trainer.fit_loop\n",
    "    trainer.fit_loop = KFoldLoop(config_dict['n_fold'], config_dict, export_path=export_path)\n",
    "    trainer.fit_loop.connect(internal_fit_loop)\n",
    "    \n",
    "    trainer.fit(model, datamodule)\n",
    "    garbage_collection_cuda()\n",
    "    del model\n",
    "    del datamodule\n",
    "    del trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb538c9-a170-402e-9f9e-9065038755e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-14 16:55:23 (running for 00:06:49.02)<br>Memory usage on this node: 123.8/503.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/80 CPUs, 4.0/4 GPUs, 0.0/264.54 GiB heap, 0.0/117.36 GiB objects (0.0/1.0 accelerator_type:P100)<br>Result logdir: /storagenfs/m.petix/ray_results/tune_uspppm<br>Number of trials: 7/108 (3 ERROR, 4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  batch_size</th><th>model               </th><th style=\"text-align: right;\">  n_fold</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_cbdd2_00000</td><td>RUNNING </td><td>131.114.50.210:4156531</td><td style=\"text-align: right;\">           4</td><td>AI-Growth-Lab/P_b3f0</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "<tr><td>trainable_cbdd2_00001</td><td>RUNNING </td><td>131.114.50.210:4156575</td><td style=\"text-align: right;\">           8</td><td>AI-Growth-Lab/P_b3f0</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "<tr><td>trainable_cbdd2_00002</td><td>RUNNING </td><td>131.114.50.210:4156753</td><td style=\"text-align: right;\">          16</td><td>AI-Growth-Lab/P_b3f0</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "<tr><td>trainable_cbdd2_00006</td><td>RUNNING </td><td>131.114.50.210:4157739</td><td style=\"text-align: right;\">           4</td><td>distilbert-base_b710</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "<tr><td>trainable_cbdd2_00003</td><td>ERROR   </td><td>131.114.50.210:4156925</td><td style=\"text-align: right;\">          32</td><td>AI-Growth-Lab/P_b3f0</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "<tr><td>trainable_cbdd2_00004</td><td>ERROR   </td><td>131.114.50.210:4157292</td><td style=\"text-align: right;\">          64</td><td>AI-Growth-Lab/P_b3f0</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "<tr><td>trainable_cbdd2_00005</td><td>ERROR   </td><td>131.114.50.210:4157517</td><td style=\"text-align: right;\">         128</td><td>AI-Growth-Lab/P_b3f0</td><td style=\"text-align: right;\">       8</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 3<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_cbdd2_00003</td><td style=\"text-align: right;\">           1</td><td>/storagenfs/m.petix/ray_results/tune_uspppm/trainable_cbdd2_00003_3_batch_size=32,model=AI-Growth-Lab_PatentSBERTa,n_fold=8_2022-11-14_16-48-57/error.txt </td></tr>\n",
       "<tr><td>trainable_cbdd2_00004</td><td style=\"text-align: right;\">           1</td><td>/storagenfs/m.petix/ray_results/tune_uspppm/trainable_cbdd2_00004_4_batch_size=64,model=AI-Growth-Lab_PatentSBERTa,n_fold=8_2022-11-14_16-49-14/error.txt </td></tr>\n",
       "<tr><td>trainable_cbdd2_00005</td><td style=\"text-align: right;\">           1</td><td>/storagenfs/m.petix/ray_results/tune_uspppm/trainable_cbdd2_00005_5_batch_size=128,model=AI-Growth-Lab_PatentSBERTa,n_fold=8_2022-11-14_16-49-31/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner = tune.Tuner(tune.with_resources(trainable, \n",
    "                                       {\"cpu\":0.25,\"gpu\":1}),\n",
    "                                       param_space = config_dict,\n",
    "                                       tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\",max_concurrent_trials=4),\n",
    "                                       # tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\"),\n",
    "                                       run_config = air.RunConfig(name=\"tune_uspppm\", verbose=2, progress_reporter=tune.JupyterNotebookReporter(overwrite=True))\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a8c09-0fc2-4c9d-955c-cd00f881d558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 16:48:34,314\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156531)\u001b[0m Global seed set to 42\n",
      "100%|██████████| 136/136 [00:00<00:00, 4695.28it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1532/36473 [00:00<00:02, 15311.69it/s]\n",
      "  9%|▊         | 3145/36473 [00:00<00:02, 15791.29it/s]\n",
      " 13%|█▎        | 4744/36473 [00:00<00:01, 15880.53it/s]\n",
      " 17%|█▋        | 6333/36473 [00:00<00:01, 15644.18it/s]\n",
      " 26%|██▌       | 9467/36473 [00:00<00:01, 15637.35it/s]\n",
      " 30%|███       | 11123/36473 [00:00<00:01, 15934.97it/s]\n",
      " 35%|███▍      | 12717/36473 [00:00<00:01, 15920.98it/s]\n",
      " 39%|███▉      | 14310/36473 [00:00<00:01, 15842.11it/s]\n",
      " 44%|████▎     | 15909/36473 [00:01<00:01, 15884.33it/s]\n",
      " 48%|████▊     | 17506/36473 [00:01<00:01, 15907.55it/s]\n",
      " 52%|█████▏    | 19134/36473 [00:01<00:01, 16017.37it/s]\n",
      " 57%|█████▋    | 20736/36473 [00:01<00:00, 15836.05it/s]\n",
      " 61%|██████    | 22321/36473 [00:01<00:00, 15610.77it/s]\n",
      " 66%|██████▌   | 23923/36473 [00:01<00:00, 15731.96it/s]\n",
      " 70%|██████▉   | 25498/36473 [00:01<00:00, 15545.68it/s]\n",
      " 74%|███████▍  | 27054/36473 [00:01<00:00, 15361.01it/s]\n",
      " 78%|███████▊  | 28591/36473 [00:01<00:00, 15180.71it/s]\n",
      " 83%|████████▎ | 30124/36473 [00:01<00:00, 15223.71it/s]\n",
      " 87%|████████▋ | 31647/36473 [00:02<00:00, 15212.17it/s]\n",
      " 91%|█████████ | 33264/36473 [00:02<00:00, 15495.38it/s]\n",
      "100%|█████████▉| 36392/36473 [00:02<00:00, 15564.86it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15626.60it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1432/36473 [00:00<00:02, 14312.30it/s]\n",
      "  8%|▊         | 2905/36473 [00:00<00:02, 14548.84it/s]\n",
      " 12%|█▏        | 4435/36473 [00:00<00:02, 14886.87it/s]\n",
      " 16%|█▋        | 6009/36473 [00:00<00:02, 15220.55it/s]\n",
      " 21%|██        | 7532/36473 [00:00<00:01, 15145.15it/s]\n",
      " 25%|██▌       | 9147/36473 [00:00<00:01, 15484.88it/s]\n",
      " 29%|██▉       | 10752/36473 [00:00<00:01, 15667.83it/s]\n",
      " 34%|███▍      | 12340/36473 [00:00<00:01, 15732.16it/s]\n",
      " 38%|███▊      | 13937/36473 [00:00<00:01, 15804.85it/s]\n",
      " 43%|████▎     | 15518/36473 [00:01<00:01, 15748.08it/s]\n",
      " 47%|████▋     | 17093/36473 [00:01<00:01, 15416.60it/s]\n",
      " 51%|█████     | 18637/36473 [00:01<00:01, 15158.99it/s]\n",
      " 55%|█████▌    | 20155/36473 [00:01<00:01, 14936.88it/s]\n",
      " 59%|█████▉    | 21651/36473 [00:01<00:01, 14786.07it/s]\n",
      " 64%|██████▎   | 23223/36473 [00:01<00:00, 15060.03it/s]\n",
      " 68%|██████▊   | 24789/36473 [00:01<00:00, 15234.71it/s]\n",
      " 72%|███████▏  | 26358/36473 [00:01<00:00, 15369.56it/s]\n",
      " 77%|███████▋  | 27951/36473 [00:01<00:00, 15534.23it/s]\n",
      " 81%|████████  | 29518/36473 [00:01<00:00, 15574.36it/s]\n",
      " 85%|████████▌ | 31077/36473 [00:02<00:00, 15370.84it/s]\n",
      " 89%|████████▉ | 32616/36473 [00:02<00:00, 15336.12it/s]\n",
      " 94%|█████████▎| 34151/36473 [00:02<00:00, 15318.49it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15329.05it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4156575)\u001b[0m Global seed set to 42\n",
      "100%|██████████| 136/136 [00:00<00:00, 4654.41it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1412/36473 [00:00<00:02, 14115.37it/s]\n",
      "  8%|▊         | 3034/36473 [00:00<00:02, 15352.52it/s]\n",
      " 13%|█▎        | 4592/36473 [00:00<00:02, 15455.71it/s]\n",
      " 17%|█▋        | 6138/36473 [00:00<00:02, 15068.65it/s]\n",
      " 21%|██        | 7647/36473 [00:00<00:01, 14830.81it/s]\n",
      " 29%|██▉       | 10671/36473 [00:00<00:01, 14609.48it/s]\n",
      " 33%|███▎      | 12137/36473 [00:00<00:01, 14539.29it/s]\n",
      " 37%|███▋      | 13594/36473 [00:00<00:01, 14470.68it/s]\n",
      " 41%|████      | 15043/36473 [00:01<00:01, 14451.68it/s]\n",
      " 46%|████▌     | 16597/36473 [00:01<00:01, 14779.02it/s]\n",
      " 50%|████▉     | 18142/36473 [00:01<00:01, 14979.75it/s]\n",
      " 54%|█████▍    | 19692/36473 [00:01<00:01, 15133.48it/s]\n",
      " 58%|█████▊    | 21207/36473 [00:01<00:01, 14940.03it/s]\n",
      " 62%|██████▏   | 22703/36473 [00:01<00:00, 14685.32it/s]\n",
      " 66%|██████▋   | 24173/36473 [00:01<00:00, 14506.66it/s]\n",
      " 70%|███████   | 25625/36473 [00:01<00:00, 14044.45it/s]\n",
      " 74%|███████▍  | 27136/36473 [00:01<00:00, 14350.07it/s]\n",
      " 79%|███████▊  | 28638/36473 [00:01<00:00, 14542.83it/s]\n",
      " 83%|████████▎ | 30272/36473 [00:02<00:00, 15070.14it/s]\n",
      " 87%|████████▋ | 31830/36473 [00:02<00:00, 15220.58it/s]\n",
      " 92%|█████████▏| 33471/36473 [00:02<00:00, 15571.76it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 14843.27it/s]\n",
      "  4%|▎         | 1343/36473 [00:00<00:02, 13421.60it/s]\n",
      "  8%|▊         | 2846/36473 [00:00<00:02, 14364.62it/s]\n",
      " 12%|█▏        | 4410/36473 [00:00<00:02, 14943.71it/s]\n",
      " 16%|█▋        | 6014/36473 [00:00<00:01, 15373.42it/s]\n",
      " 21%|██        | 7641/36473 [00:00<00:01, 15695.82it/s]\n",
      " 25%|██▌       | 9244/36473 [00:00<00:01, 15807.61it/s]\n",
      " 34%|███▍      | 12522/36473 [00:00<00:01, 16098.51it/s]\n",
      " 39%|███▉      | 14182/36473 [00:00<00:01, 16254.02it/s]\n",
      " 43%|████▎     | 15808/36473 [00:01<00:01, 16200.95it/s]\n",
      " 48%|████▊     | 17429/36473 [00:01<00:01, 15950.30it/s]\n",
      " 52%|█████▏    | 19025/36473 [00:01<00:01, 15833.28it/s]\n",
      " 57%|█████▋    | 20613/36473 [00:01<00:01, 15846.61it/s]\n",
      " 61%|██████    | 22221/36473 [00:01<00:00, 15914.88it/s]\n",
      " 65%|██████▌   | 23813/36473 [00:01<00:00, 15775.60it/s]\n",
      " 74%|███████▍  | 26952/36473 [00:01<00:00, 15471.63it/s]\n",
      " 78%|███████▊  | 28500/36473 [00:01<00:00, 15048.17it/s]\n",
      " 82%|████████▏ | 30008/36473 [00:01<00:00, 14909.35it/s]\n",
      " 86%|████████▋ | 31517/36473 [00:02<00:00, 14960.21it/s]\n",
      " 91%|█████████ | 33015/36473 [00:02<00:00, 14957.04it/s]\n",
      " 95%|█████████▍| 34512/36473 [00:02<00:00, 14794.39it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15367.43it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4156753)\u001b[0m Global seed set to 42\n",
      "100%|██████████| 136/136 [00:00<00:00, 4324.45it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1418/36473 [00:00<00:02, 14173.80it/s]\n",
      "  8%|▊         | 3002/36473 [00:00<00:02, 15149.73it/s]\n",
      " 13%|█▎        | 4610/36473 [00:00<00:02, 15572.13it/s]\n",
      " 17%|█▋        | 6168/36473 [00:00<00:01, 15444.45it/s]\n",
      " 21%|██        | 7748/36473 [00:00<00:01, 15570.40it/s]\n",
      " 26%|██▌       | 9322/36473 [00:00<00:01, 15626.17it/s]\n",
      " 30%|██▉       | 10930/36473 [00:00<00:01, 15771.81it/s]\n",
      " 34%|███▍      | 12508/36473 [00:00<00:01, 15583.07it/s]\n",
      " 39%|███▊      | 14067/36473 [00:00<00:01, 15415.33it/s]\n",
      " 43%|████▎     | 15610/36473 [00:01<00:01, 15293.76it/s]\n",
      " 47%|████▋     | 17140/36473 [00:01<00:01, 15212.75it/s]\n",
      " 51%|█████▏    | 18712/36473 [00:01<00:01, 15364.42it/s]\n",
      " 60%|█████▉    | 21857/36473 [00:01<00:00, 15560.07it/s]\n",
      " 64%|██████▍   | 23454/36473 [00:01<00:00, 15681.56it/s]\n",
      " 69%|██████▊   | 25023/36473 [00:01<00:00, 15296.98it/s]\n",
      " 73%|███████▎  | 26555/36473 [00:01<00:00, 15097.51it/s]\n",
      " 77%|███████▋  | 28067/36473 [00:01<00:00, 15034.49it/s]\n",
      " 81%|████████  | 29596/36473 [00:01<00:00, 15109.16it/s]\n",
      " 85%|████████▌ | 31108/36473 [00:02<00:00, 14880.47it/s]\n",
      " 89%|████████▉ | 32598/36473 [00:02<00:00, 14878.54it/s]\n",
      " 98%|█████████▊| 35654/36473 [00:02<00:00, 14950.54it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15245.21it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1501/36473 [00:00<00:02, 15005.33it/s]\n",
      "  8%|▊         | 3053/36473 [00:00<00:02, 15305.45it/s]\n",
      " 17%|█▋        | 6247/36473 [00:00<00:01, 15758.65it/s]\n",
      " 21%|██▏       | 7823/36473 [00:00<00:01, 15730.26it/s]\n",
      " 26%|██▌       | 9397/36473 [00:00<00:01, 15564.94it/s]\n",
      " 30%|███       | 10954/36473 [00:00<00:01, 15290.42it/s]\n",
      " 34%|███▍      | 12485/36473 [00:00<00:01, 15111.17it/s]\n",
      " 38%|███▊      | 14035/36473 [00:00<00:01, 15228.29it/s]\n",
      " 43%|████▎     | 15618/36473 [00:01<00:01, 15411.11it/s]\n",
      " 47%|████▋     | 17176/36473 [00:01<00:01, 15459.80it/s]\n",
      " 52%|█████▏    | 18785/36473 [00:01<00:01, 15648.16it/s]\n",
      " 56%|█████▌    | 20406/36473 [00:01<00:01, 15815.48it/s]\n",
      " 60%|██████    | 21989/36473 [00:01<00:00, 15697.28it/s]\n",
      " 65%|██████▍   | 23560/36473 [00:01<00:00, 15689.05it/s]\n",
      " 69%|██████▉   | 25130/36473 [00:01<00:00, 15242.66it/s]\n",
      " 73%|███████▎  | 26658/36473 [00:01<00:00, 15064.18it/s]\n",
      " 77%|███████▋  | 28167/36473 [00:01<00:00, 14928.31it/s]\n",
      " 81%|████████▏ | 29697/36473 [00:01<00:00, 15036.64it/s]\n",
      " 90%|████████▉ | 32807/36473 [00:02<00:00, 15327.89it/s]\n",
      " 94%|█████████▍| 34372/36473 [00:02<00:00, 15421.35it/s]\n",
      " 99%|█████████▊| 35962/36473 [00:02<00:00, 15563.74it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15416.21it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m Global seed set to 42\n",
      "  0%|          | 0/136 [00:00<?, ?it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 4531.90it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  5%|▍         | 1664/36473 [00:00<00:02, 16631.21it/s]\n",
      "  9%|▉         | 3430/36473 [00:00<00:01, 17235.66it/s]\n",
      " 14%|█▍        | 5199/36473 [00:00<00:01, 17441.07it/s]\n",
      " 19%|█▉        | 6947/36473 [00:00<00:01, 17455.05it/s]\n",
      " 24%|██▍       | 8693/36473 [00:00<00:01, 17278.53it/s]\n",
      " 29%|██▊       | 10422/36473 [00:00<00:01, 17007.58it/s]\n",
      " 33%|███▎      | 12124/36473 [00:00<00:01, 16878.74it/s]\n",
      " 38%|███▊      | 13813/36473 [00:00<00:01, 16792.31it/s]\n",
      " 43%|████▎     | 15593/36473 [00:00<00:01, 17097.36it/s]\n",
      " 47%|████▋     | 17304/36473 [00:01<00:01, 17051.48it/s]\n",
      " 52%|█████▏    | 19089/36473 [00:01<00:01, 17290.94it/s]\n",
      " 57%|█████▋    | 20819/36473 [00:01<00:00, 17227.62it/s]\n",
      " 62%|██████▏   | 22576/36473 [00:01<00:00, 17329.39it/s]\n",
      " 67%|██████▋   | 24310/36473 [00:01<00:00, 17267.15it/s]\n",
      " 71%|███████▏  | 26037/36473 [00:01<00:00, 17046.90it/s]\n",
      " 76%|███████▌  | 27743/36473 [00:01<00:00, 16539.72it/s]\n",
      " 81%|████████  | 29416/36473 [00:01<00:00, 16593.84it/s]\n",
      " 85%|████████▌ | 31078/36473 [00:01<00:00, 16419.35it/s]\n",
      " 90%|████████▉ | 32793/36473 [00:01<00:00, 16631.22it/s]\n",
      " 95%|█████████▍| 34468/36473 [00:02<00:00, 16662.87it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 16947.78it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1637/36473 [00:00<00:02, 16366.27it/s]\n",
      "  9%|▉         | 3359/36473 [00:00<00:01, 16864.69it/s]\n",
      " 14%|█▍        | 5061/36473 [00:00<00:01, 16933.98it/s]\n",
      " 19%|█▊        | 6755/36473 [00:00<00:01, 16571.94it/s]\n",
      " 28%|██▊       | 10123/36473 [00:00<00:01, 16704.69it/s]\n",
      " 32%|███▏      | 11814/36473 [00:00<00:01, 16771.04it/s]\n",
      " 37%|███▋      | 13532/36473 [00:00<00:01, 16900.00it/s]\n",
      " 42%|████▏     | 15241/36473 [00:00<00:01, 16957.94it/s]\n",
      " 47%|████▋     | 16975/36473 [00:01<00:01, 17075.31it/s]\n",
      " 51%|█████     | 18692/36473 [00:01<00:01, 17103.14it/s]\n",
      " 56%|█████▌    | 20437/36473 [00:01<00:00, 17207.43it/s]\n",
      " 65%|██████▌   | 23865/36473 [00:01<00:00, 16829.12it/s]\n",
      " 70%|███████   | 25549/36473 [00:01<00:00, 16822.31it/s]\n",
      " 75%|███████▍  | 27238/36473 [00:01<00:00, 16841.55it/s]\n",
      " 79%|███████▉  | 28929/36473 [00:01<00:00, 16860.39it/s]\n",
      " 84%|████████▍ | 30628/36473 [00:01<00:00, 16898.74it/s]\n",
      " 89%|████████▊ | 32326/36473 [00:01<00:00, 16922.82it/s]\n",
      " 93%|█████████▎| 34063/36473 [00:02<00:00, 17051.04it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 16930.34it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   rank_zero_deprecation(\n",
      "2022-11-14 16:49:13,616\tERROR trial_runner.py:987 -- Trial trainable_cbdd2_00003: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4156925, ip=131.114.50.210, repr=trainable)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 349, in train\n",
      "    result = self.step()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 417, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 589, in _report_thread_runner_error\n",
      "    raise e\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "    self._entrypoint()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-12-e2cb2cdb91d7>\", line 54, in trainable\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1147, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 73, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 70, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\", line 113, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 927, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 602, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 925, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m 2022-11-14 16:49:13,599\tERROR function_trainable.py:298 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"<ipython-input-12-e2cb2cdb91d7>\", line 54, in trainable\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     self._call_and_handle_interrupt(\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1147, in _run\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     self.strategy.setup(self)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 73, in setup\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     self.model_to_device()\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 70, in model_to_device\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     self.model.to(self.root_device)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\", line 113, in to\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     return super().to(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 927, in to\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     return self._apply(convert)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 602, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     param_applied = fn(param)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 925, in convert\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m RuntimeError: CUDA error: out of memory\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "\u001b[2m\u001b[36m(trainable pid=4156925)\u001b[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trial trainable_cbdd2_00003 errored with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 32, 'epochs': 2, 'n_fold': 8, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'AI-Growth-Lab/PatentSBERTa'}. Error file: /storagenfs/m.petix/ray_results/tune_uspppm/trainable_cbdd2_00003_3_batch_size=32,model=AI-Growth-Lab_PatentSBERTa,n_fold=8_2022-11-14_16-48-57/error.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m Global seed set to 42\n",
      "  0%|          | 0/136 [00:00<?, ?it/s]\n",
      "100%|██████████| 136/136 [00:00<00:00, 4183.14it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1537/36473 [00:00<00:02, 15348.39it/s]\n",
      "  9%|▊         | 3181/36473 [00:00<00:02, 15985.11it/s]\n",
      " 13%|█▎        | 4876/36473 [00:00<00:01, 16418.83it/s]\n",
      " 18%|█▊        | 6518/36473 [00:00<00:01, 16362.63it/s]\n",
      " 22%|██▏       | 8182/36473 [00:00<00:01, 16461.76it/s]\n",
      " 27%|██▋       | 9829/36473 [00:00<00:01, 16295.39it/s]\n",
      " 31%|███▏      | 11459/36473 [00:00<00:01, 16077.56it/s]\n",
      " 36%|███▌      | 13068/36473 [00:00<00:01, 15712.67it/s]\n",
      " 40%|████      | 14702/36473 [00:00<00:01, 15903.33it/s]\n",
      " 49%|████▉     | 17953/36473 [00:01<00:01, 16079.21it/s]\n",
      " 54%|█████▎    | 19586/36473 [00:01<00:01, 16152.97it/s]\n",
      " 58%|█████▊    | 21203/36473 [00:01<00:00, 16150.19it/s]\n",
      " 63%|██████▎   | 22881/36473 [00:01<00:00, 16337.23it/s]\n",
      " 67%|██████▋   | 24516/36473 [00:01<00:00, 16247.68it/s]\n",
      " 72%|███████▏  | 26142/36473 [00:01<00:00, 16187.42it/s]\n",
      " 76%|███████▌  | 27762/36473 [00:01<00:00, 16048.84it/s]\n",
      " 85%|████████▍ | 30952/36473 [00:01<00:00, 15805.88it/s]\n",
      " 89%|████████▉ | 32563/36473 [00:02<00:00, 15895.40it/s]\n",
      " 94%|█████████▍| 34201/36473 [00:02<00:00, 16037.94it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 16116.43it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1606/36473 [00:00<00:02, 16050.52it/s]\n",
      "  9%|▉         | 3212/36473 [00:00<00:02, 15898.46it/s]\n",
      " 13%|█▎        | 4809/36473 [00:00<00:01, 15929.52it/s]\n",
      " 18%|█▊        | 6438/36473 [00:00<00:01, 16069.54it/s]\n",
      " 22%|██▏       | 8046/36473 [00:00<00:01, 15975.02it/s]\n",
      " 26%|██▋       | 9644/36473 [00:00<00:01, 15850.07it/s]\n",
      " 35%|███▌      | 12873/36473 [00:00<00:01, 15981.05it/s]\n",
      " 40%|███▉      | 14473/36473 [00:00<00:01, 15986.79it/s]\n",
      " 44%|████▍     | 16081/36473 [00:01<00:01, 16014.10it/s]\n",
      " 48%|████▊     | 17683/36473 [00:01<00:01, 16001.06it/s]\n",
      " 53%|█████▎    | 19301/36473 [00:01<00:01, 16052.95it/s]\n",
      " 57%|█████▋    | 20939/36473 [00:01<00:00, 16149.53it/s]\n",
      " 62%|██████▏   | 22570/36473 [00:01<00:00, 16194.99it/s]\n",
      " 71%|███████   | 25798/36473 [00:01<00:00, 15792.15it/s]\n",
      " 75%|███████▌  | 27379/36473 [00:01<00:00, 15753.99it/s]\n",
      " 79%|███████▉  | 28969/36473 [00:01<00:00, 15796.01it/s]\n",
      " 84%|████████▍ | 30593/36473 [00:01<00:00, 15925.51it/s]\n",
      " 88%|████████▊ | 32198/36473 [00:02<00:00, 15960.89it/s]\n",
      " 93%|█████████▎| 33803/36473 [00:02<00:00, 15987.19it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15973.65it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m 2022-11-14 16:49:30,761\tERROR function_trainable.py:298 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"<ipython-input-12-e2cb2cdb91d7>\", line 54, in trainable\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     self._call_and_handle_interrupt(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1147, in _run\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     self.strategy.setup(self)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 73, in setup\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     self.model_to_device()\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 70, in model_to_device\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     self.model.to(self.root_device)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\", line 113, in to\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     return super().to(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 927, in to\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     return self._apply(convert)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 602, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     param_applied = fn(param)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 925, in convert\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m RuntimeError: CUDA error: out of memory\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157292)\u001b[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "2022-11-14 16:49:30,959\tERROR trial_runner.py:987 -- Trial trainable_cbdd2_00004: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4157292, ip=131.114.50.210, repr=trainable)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 349, in train\n",
      "    result = self.step()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 417, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 589, in _report_thread_runner_error\n",
      "    raise e\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "    self._entrypoint()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-12-e2cb2cdb91d7>\", line 54, in trainable\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1147, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 73, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 70, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\", line 113, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 927, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 602, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 925, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trial trainable_cbdd2_00004 errored with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 64, 'epochs': 2, 'n_fold': 8, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'AI-Growth-Lab/PatentSBERTa'}. Error file: /storagenfs/m.petix/ray_results/tune_uspppm/trainable_cbdd2_00004_4_batch_size=64,model=AI-Growth-Lab_PatentSBERTa,n_fold=8_2022-11-14_16-49-14/error.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m Global seed set to 42\n",
      "100%|██████████| 136/136 [00:00<00:00, 4766.02it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1461/36473 [00:00<00:02, 14604.20it/s]\n",
      "  8%|▊         | 3035/36473 [00:00<00:02, 15270.50it/s]\n",
      " 13%|█▎        | 4621/36473 [00:00<00:02, 15539.22it/s]\n",
      " 21%|██        | 7747/36473 [00:00<00:01, 15525.78it/s]\n",
      " 25%|██▌       | 9300/36473 [00:00<00:01, 15425.77it/s]\n",
      " 30%|██▉       | 10843/36473 [00:00<00:01, 15369.20it/s]\n",
      " 34%|███▍      | 12381/36473 [00:00<00:01, 15018.69it/s]\n",
      " 38%|███▊      | 13885/36473 [00:00<00:01, 14961.89it/s]\n",
      " 42%|████▏     | 15383/36473 [00:01<00:01, 14929.59it/s]\n",
      " 46%|████▋     | 16936/36473 [00:01<00:01, 15109.85it/s]\n",
      " 51%|█████     | 18482/36473 [00:01<00:01, 15211.82it/s]\n",
      " 55%|█████▍    | 20004/36473 [00:01<00:01, 15072.33it/s]\n",
      " 59%|█████▉    | 21514/36473 [00:01<00:00, 15078.80it/s]\n",
      " 63%|██████▎   | 23081/36473 [00:01<00:00, 15254.04it/s]\n",
      " 68%|██████▊   | 24645/36473 [00:01<00:00, 15369.08it/s]\n",
      " 72%|███████▏  | 26183/36473 [00:01<00:00, 15032.02it/s]\n",
      " 76%|███████▌  | 27688/36473 [00:01<00:00, 14810.65it/s]\n",
      " 80%|███████▉  | 29171/36473 [00:01<00:00, 14693.47it/s]\n",
      " 88%|████████▊ | 32182/36473 [00:02<00:00, 14902.56it/s]\n",
      " 92%|█████████▏| 33695/36473 [00:02<00:00, 14967.50it/s]\n",
      " 97%|█████████▋| 35250/36473 [00:02<00:00, 15137.13it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15140.34it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1513/36473 [00:00<00:02, 15122.80it/s]\n",
      "  8%|▊         | 3060/36473 [00:00<00:02, 15321.98it/s]\n",
      " 13%|█▎        | 4593/36473 [00:00<00:02, 15283.71it/s]\n",
      " 17%|█▋        | 6122/36473 [00:00<00:02, 15026.58it/s]\n",
      " 21%|██        | 7626/36473 [00:00<00:01, 14670.87it/s]\n",
      " 29%|██▉       | 10554/36473 [00:00<00:01, 14575.90it/s]\n",
      " 33%|███▎      | 12013/36473 [00:00<00:01, 14567.81it/s]\n",
      " 37%|███▋      | 13502/36473 [00:00<00:01, 14667.06it/s]\n",
      " 41%|████      | 15001/36473 [00:01<00:01, 14764.59it/s]\n",
      " 49%|████▉     | 18019/36473 [00:01<00:01, 14957.01it/s]\n",
      " 54%|█████▎    | 19515/36473 [00:01<00:01, 14904.01it/s]\n",
      " 58%|█████▊    | 21006/36473 [00:01<00:01, 14618.58it/s]\n",
      " 62%|██████▏   | 22479/36473 [00:01<00:00, 14649.86it/s]\n",
      " 66%|██████▌   | 23952/36473 [00:01<00:00, 14671.71it/s]\n",
      " 74%|███████▍  | 26948/36473 [00:01<00:00, 14818.83it/s]\n",
      " 78%|███████▊  | 28431/36473 [00:01<00:00, 14710.80it/s]\n",
      " 82%|████████▏ | 29938/36473 [00:02<00:00, 14816.59it/s]\n",
      " 86%|████████▌ | 31421/36473 [00:02<00:00, 14749.45it/s]\n",
      " 90%|█████████ | 32914/36473 [00:02<00:00, 14801.62it/s]\n",
      " 94%|█████████▍| 34395/36473 [00:02<00:00, 14708.03it/s]\n",
      " 98%|█████████▊| 35867/36473 [00:02<00:00, 14555.78it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 14750.43it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m 2022-11-14 16:49:48,191\tERROR function_trainable.py:298 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"<ipython-input-12-e2cb2cdb91d7>\", line 54, in trainable\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     self._call_and_handle_interrupt(\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1147, in _run\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     self.strategy.setup(self)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 73, in setup\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     self.model_to_device()\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 70, in model_to_device\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     self.model.to(self.root_device)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\", line 113, in to\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     return super().to(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 927, in to\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     return self._apply(convert)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     module._apply(fn)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 602, in _apply\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     param_applied = fn(param)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 925, in convert\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m RuntimeError: CUDA error: out of memory\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "\u001b[2m\u001b[36m(trainable pid=4157517)\u001b[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "2022-11-14 16:49:48,343\tERROR trial_runner.py:987 -- Trial trainable_cbdd2_00005: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4157517, ip=131.114.50.210, repr=trainable)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 349, in train\n",
      "    result = self.step()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 417, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 589, in _report_thread_runner_error\n",
      "    raise e\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "    self._entrypoint()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-12-e2cb2cdb91d7>\", line 54, in trainable\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1147, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 73, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 70, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\", line 113, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 927, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 579, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 602, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 925, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trial trainable_cbdd2_00005 errored with parameters={'target_size': 1, 'num_workers': 16, 'batch_size': 128, 'epochs': 2, 'n_fold': 8, 'warmup_steps': 0, 'min_lr': 1e-06, 'encoder_lr': 2e-05, 'decoder_lr': 2e-05, 'eps': 1e-06, 'betas': (0.9, 0.999), 'weight_decay': 0.01, 'fc_dropout': 0.2, 'seed': 42, 'model': 'AI-Growth-Lab/PatentSBERTa'}. Error file: /storagenfs/m.petix/ray_results/tune_uspppm/trainable_cbdd2_00005_5_batch_size=128,model=AI-Growth-Lab_PatentSBERTa,n_fold=8_2022-11-14_16-49-31/error.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=4157739)\u001b[0m Global seed set to 42\n",
      "100%|██████████| 136/136 [00:00<00:00, 4353.26it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1570/36473 [00:00<00:02, 15695.56it/s]\n",
      "  9%|▉         | 3229/36473 [00:00<00:02, 16218.81it/s]\n",
      " 13%|█▎        | 4851/36473 [00:00<00:01, 16172.99it/s]\n",
      " 18%|█▊        | 6477/36473 [00:00<00:01, 16205.20it/s]\n",
      " 22%|██▏       | 8098/36473 [00:00<00:01, 15905.43it/s]\n",
      " 27%|██▋       | 9690/36473 [00:00<00:01, 15328.98it/s]\n",
      " 31%|███       | 11227/36473 [00:00<00:01, 15254.45it/s]\n",
      " 35%|███▍      | 12755/36473 [00:00<00:01, 15187.46it/s]\n",
      " 39%|███▉      | 14339/36473 [00:00<00:01, 15384.35it/s]\n",
      " 48%|████▊     | 17585/36473 [00:01<00:01, 15818.94it/s]\n",
      " 53%|█████▎    | 19231/36473 [00:01<00:01, 16009.88it/s]\n",
      " 57%|█████▋    | 20833/36473 [00:01<00:00, 15868.64it/s]\n",
      " 62%|██████▏   | 22436/36473 [00:01<00:00, 15916.64it/s]\n",
      " 66%|██████▌   | 24029/36473 [00:01<00:00, 15650.90it/s]\n",
      " 74%|███████▍  | 27141/36473 [00:01<00:00, 15383.47it/s]\n",
      " 79%|███████▊  | 28681/36473 [00:01<00:00, 15265.80it/s]\n",
      " 83%|████████▎ | 30265/36473 [00:01<00:00, 15433.32it/s]\n",
      " 87%|████████▋ | 31854/36473 [00:02<00:00, 15563.75it/s]\n",
      " 92%|█████████▏| 33456/36473 [00:02<00:00, 15697.48it/s]\n",
      " 96%|█████████▌| 35045/36473 [00:02<00:00, 15752.84it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15680.97it/s]\n",
      "  0%|          | 0/36473 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1509/36473 [00:00<00:02, 15087.42it/s]\n",
      "  8%|▊         | 3018/36473 [00:00<00:02, 15083.72it/s]\n",
      " 17%|█▋        | 6068/36473 [00:00<00:02, 15195.15it/s]\n",
      " 21%|██        | 7597/36473 [00:00<00:01, 15226.26it/s]\n",
      " 25%|██▌       | 9143/36473 [00:00<00:01, 15304.55it/s]\n",
      " 29%|██▉       | 10682/36473 [00:00<00:01, 15329.92it/s]\n",
      " 34%|███▎      | 12227/36473 [00:00<00:01, 15364.92it/s]\n",
      " 38%|███▊      | 13770/36473 [00:00<00:01, 15383.85it/s]\n",
      " 42%|████▏     | 15329/36473 [00:01<00:01, 15446.56it/s]\n",
      " 46%|████▋     | 16874/36473 [00:01<00:01, 15444.35it/s]\n",
      " 51%|█████     | 18419/36473 [00:01<00:01, 15320.12it/s]\n",
      " 55%|█████▍    | 19952/36473 [00:01<00:01, 15279.76it/s]\n",
      " 59%|█████▉    | 21481/36473 [00:01<00:01, 14986.05it/s]\n",
      " 63%|██████▎   | 23038/36473 [00:01<00:00, 15155.51it/s]\n",
      " 67%|██████▋   | 24555/36473 [00:01<00:00, 14839.75it/s]\n",
      " 72%|███████▏  | 26089/36473 [00:01<00:00, 14984.82it/s]\n",
      " 76%|███████▌  | 27660/36473 [00:01<00:00, 15198.98it/s]\n",
      " 84%|████████▍ | 30799/36473 [00:02<00:00, 15455.86it/s]\n",
      " 89%|████████▊ | 32346/36473 [00:02<00:00, 15447.40it/s]\n",
      " 93%|█████████▎| 33892/36473 [00:02<00:00, 15241.82it/s]\n",
      "100%|██████████| 36473/36473 [00:02<00:00, 15245.04it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=4157739)\u001b[0m Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "\u001b[2m\u001b[36m(trainable pid=4157739)\u001b[0m - This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(trainable pid=4157739)\u001b[0m - This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result()  # Get best result object\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0fc4bd-5ca4-43a1-af65-ac34eb9205ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46525d24-c57d-445c-9781-5af54ca0b8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc2fef-2f13-4d18-93dc-a56a8ddcc7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe for the last reported results of all of the trials \n",
    "df = results.get_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ec5b2-9599-4530-84ce-b569fd51481a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('grid_search_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
