{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2239c1-e1b6-46be-8734-f1a3298fb062",
   "metadata": {},
   "source": [
    "# Pip Wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddb3b1f-8cf9-4ead-895f-9a5768440183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pytorch_lightning\\n!pip install torchmetrics\\n!pip install tokenizers\\n!pip install transformers\\n!pip install ray[tune]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install pytorch_lightning\n",
    "!pip install torchmetrics\n",
    "!pip install tokenizers\n",
    "!pip install transformers\n",
    "!pip install ray[tune]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc890c3d-d9af-45d0-a1df-36462ffdf4b7",
   "metadata": {
    "id": "ICgrtlaznr7F"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba724d89-aea8-4bf1-bd16-1380bcdce9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUiP-rVLnr7H",
    "outputId": "79dc16d8-54ad-42df-a406-ef7564341a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from tqdm.auto import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Type\n",
    "from copy import deepcopy\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, seed_everything, Trainer, LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.functional import f1_score, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loops.loop import Loop\n",
    "from pytorch_lightning.loops.fit_loop import FitLoop\n",
    "from pytorch_lightning.trainer.states import TrainerFn\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "# Ray[Tune]\n",
    "import ray\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "\n",
    "\n",
    "# HuggingFace Libraries\n",
    "import tokenizers\n",
    "import transformers \n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990e45de-3f45-42f3-b6d9-37e5bfad651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 18:58:00,523\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '131.114.50.210', 'raylet_ip_address': '131.114.50.210', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-06_18-57-57_521457_276521/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-06_18-57-57_521457_276521/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-06_18-57-57_521457_276521', 'metrics_export_port': 50411, 'gcs_address': '131.114.50.210:50995', 'address': '131.114.50.210:50995', 'dashboard_agent_listen_port': 52365, 'node_id': 'df198591cc5bed44238375cef5d62c5ae22abf63fe0279693f284390'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_gpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afdc09-2e7d-412d-9cbf-39e104819dad",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5fc28-1a0b-4c86-9da6-e156d4e88d13",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Class: notebook-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca2dbb5-92b6-4d04-b479-223aaeb390d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # General\n",
    "    seed = 42\n",
    "    \n",
    "    # Debug \n",
    "    debug = True\n",
    "    debug_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ccc5e-ced9-4c6b-ba6c-29e7ed9ffbac",
   "metadata": {
    "id": "E6Qw8gpgnr7N"
   },
   "source": [
    "## Configuration Dictionary: trial-specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9985db04-ae1c-492c-9cca-eeac1b209381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a search space!\n",
    "config_dict = {\n",
    "    \"target_size\" : 1,\n",
    "    \"num_workers\" : 8,\n",
    "    \n",
    "    # Training parameters\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 2,\n",
    "    \"n_fold\" : 2,\n",
    "    \"warmup_steps\" : 0,\n",
    "    \"min_lr\" : 1e-6,\n",
    "    \"encoder_lr\" : 2e-5,\n",
    "    \"decoder_lr\" : 2e-5,\n",
    "    \"eps\" : 1e-6,\n",
    "    \"betas\" : (0.9, 0.999),\n",
    "    \"weight_decay\" : 0.01,\n",
    "    \"fc_dropout\" : 0.2,\n",
    "\n",
    "    # Transformers\n",
    "    # \"model\" : tune.grid_search([\"distilbert-base-uncased\", \"microsoft/deberta-v3-large\"]),\n",
    "    # \"model\" : tune.choice([\"microsoft/deberta-v3-large\"]),\n",
    "    # \"model\" : tune.choice([\"distilbert-base-uncased\"]),\n",
    "    \"model\" : \"distilbert-base-uncased\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd0738-9bbe-4d25-8510-aaf5a7110750",
   "metadata": {
    "id": "iIVnbwmdnr7K"
   },
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5da60d-3f9b-4ea6-9254-dc40d402afce",
   "metadata": {
    "id": "JaQ5oUkRnr7N"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../dataset/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38b47b-7a99-4942-b910-c0e7cac5cebf",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8398a15a-644b-4e83-8d46-543e37ed59d8",
   "metadata": {
    "id": "T-mYdoUjnr7R"
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"USPPPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384aa55c-0f30-4569-9300-3c2a3430727b",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00781e09-61ab-49ea-a16e-212fb8683047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeDb5W-Wnr7U",
    "outputId": "9efeb745-33a8-42c9-a578-3de670bc7cb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2b97f-909f-455b-b81d-b90a366b2676",
   "metadata": {},
   "source": [
    "## Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8e52ee-27e5-4260-90a1-684468fa2599",
   "metadata": {
    "id": "PWOAoAcCnr7W"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    score = sp.stats.pearsonr(y_true, y_pred)[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f8751-79fe-492a-a1c8-eb35867f3909",
   "metadata": {
    "id": "IeqIEukjnr7W"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca74519-9ccd-48be-ba61-67466fceea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id     anchor                  target context  \\\n",
       "0           0  37d61fd2272659b1  abatement  abatement of pollution     A47   \n",
       "1           1  7b9652b17b68b7a4  abatement          act of abating     A47   \n",
       "2           2  36d72442aefd8232  abatement         active catalyst     A47   \n",
       "3           3  5296b0c19e1ce60e  abatement     eliminating process     A47   \n",
       "4           4  54c1e3b9184cb5b6  abatement           forest region     A47   \n",
       "\n",
       "   score                                       context_text  \\\n",
       "0   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "1   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "2   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "3   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "4   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "\n",
       "                                                text  score_map  \n",
       "0  abatement[SEP]abatement of pollution[SEP]HUMAN...          2  \n",
       "1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...          3  \n",
       "2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...          1  \n",
       "3  abatement[SEP]eliminating process[SEP]HUMAN NE...          2  \n",
       "4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc_texts = torch.load('cpc_texts.pth')\n",
    "dataframe = pd.read_csv(\"dataframe.csv\")\n",
    "display(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17be84-7e8e-4cc8-99a5-5b5835d9984c",
   "metadata": {},
   "source": [
    "## Debug Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8036555-0930-4a1e-a4e6-fb088d201ced",
   "metadata": {
    "id": "6zeWhBTmvC2N"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    dataframe = dataframe.iloc[:CFG.debug_samples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc687c3-b2d5-4ad1-b872-bc08c0edea4e",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f8730b-3f39-46bb-ad8d-28521a3aa08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>983</td>\n",
       "      <td>d336ee90bdc74b1c</td>\n",
       "      <td>air flow line</td>\n",
       "      <td>fluid flow line</td>\n",
       "      <td>B63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. SHIPS OR ...</td>\n",
       "      <td>air flow line[SEP]fluid flow line[SEP]PERFORMI...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>700</td>\n",
       "      <td>e5a6dccf738babe3</td>\n",
       "      <td>adjacent laterally</td>\n",
       "      <td>adjacent to mall</td>\n",
       "      <td>A41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>HUMAN NECESSITIES. WEARING APPAREL</td>\n",
       "      <td>adjacent laterally[SEP]adjacent to mall[SEP]HU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>463</td>\n",
       "      <td>f030009ac7858e1b</td>\n",
       "      <td>acrylate groups</td>\n",
       "      <td>interpolymer invention</td>\n",
       "      <td>D21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXTILES; PAPER. PAPER-MAKING; PRODUCTION OF C...</td>\n",
       "      <td>acrylate groups[SEP]interpolymer invention[SEP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>0136064bfb779543</td>\n",
       "      <td>agitate means</td>\n",
       "      <td>muscle shivering</td>\n",
       "      <td>B01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...</td>\n",
       "      <td>agitate means[SEP]muscle shivering[SEP]PERFORM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>e865c688d8198872</td>\n",
       "      <td>accept information</td>\n",
       "      <td>information data</td>\n",
       "      <td>A45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HUMAN NECESSITIES. HAND OR TRAVELLING ARTICLES</td>\n",
       "      <td>accept information[SEP]information data[SEP]HU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                id              anchor                  target  \\\n",
       "983         983  d336ee90bdc74b1c       air flow line         fluid flow line   \n",
       "700         700  e5a6dccf738babe3  adjacent laterally        adjacent to mall   \n",
       "463         463  f030009ac7858e1b     acrylate groups  interpolymer invention   \n",
       "926         926  0136064bfb779543       agitate means        muscle shivering   \n",
       "235         235  e865c688d8198872  accept information        information data   \n",
       "\n",
       "    context  score                                       context_text  \\\n",
       "983     B63   0.75  PERFORMING OPERATIONS; TRANSPORTING. SHIPS OR ...   \n",
       "700     A41   0.00                 HUMAN NECESSITIES. WEARING APPAREL   \n",
       "463     D21   0.25  TEXTILES; PAPER. PAPER-MAKING; PRODUCTION OF C...   \n",
       "926     B01   0.00  PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...   \n",
       "235     A45   0.25     HUMAN NECESSITIES. HAND OR TRAVELLING ARTICLES   \n",
       "\n",
       "                                                  text  score_map  \n",
       "983  air flow line[SEP]fluid flow line[SEP]PERFORMI...          3  \n",
       "700  adjacent laterally[SEP]adjacent to mall[SEP]HU...          0  \n",
       "463  acrylate groups[SEP]interpolymer invention[SEP...          1  \n",
       "926  agitate means[SEP]muscle shivering[SEP]PERFORM...          0  \n",
       "235  accept information[SEP]information data[SEP]HU...          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "      <th>score_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>9658a68dedd1b4cc</td>\n",
       "      <td>adjacent laterally</td>\n",
       "      <td>radius</td>\n",
       "      <td>A41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>HUMAN NECESSITIES. WEARING APPAREL</td>\n",
       "      <td>adjacent laterally[SEP]radius[SEP]HUMAN NECESS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>d2088cdd8be8761b</td>\n",
       "      <td>achieve authentication</td>\n",
       "      <td>biometric</td>\n",
       "      <td>H04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n",
       "      <td>achieve authentication[SEP]biometric[SEP]ELECT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>548</td>\n",
       "      <td>8ed41bd0deb21205</td>\n",
       "      <td>activating position</td>\n",
       "      <td>active material</td>\n",
       "      <td>G06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PHYSICS. COMPUTING; CALCULATING; COUNTING</td>\n",
       "      <td>activating position[SEP]active material[SEP]PH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>07f1cfe84cd4ebdc</td>\n",
       "      <td>acrylate groups</td>\n",
       "      <td>nitro group</td>\n",
       "      <td>D21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXTILES; PAPER. PAPER-MAKING; PRODUCTION OF C...</td>\n",
       "      <td>acrylate groups[SEP]nitro group[SEP]TEXTILES; ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>f798712a28d6660b</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>rosmarinic acid</td>\n",
       "      <td>B01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...</td>\n",
       "      <td>acid absorption[SEP]rosmarinic acid[SEP]PERFOR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                id                  anchor           target  \\\n",
       "719         719  9658a68dedd1b4cc      adjacent laterally           radius   \n",
       "256         256  d2088cdd8be8761b  achieve authentication        biometric   \n",
       "548         548  8ed41bd0deb21205     activating position  active material   \n",
       "473         473  07f1cfe84cd4ebdc         acrylate groups      nitro group   \n",
       "308         308  f798712a28d6660b         acid absorption  rosmarinic acid   \n",
       "\n",
       "    context  score                                       context_text  \\\n",
       "719     A41   0.25                 HUMAN NECESSITIES. WEARING APPAREL   \n",
       "256     H04   0.25      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE   \n",
       "548     G06   0.00          PHYSICS. COMPUTING; CALCULATING; COUNTING   \n",
       "473     D21   0.00  TEXTILES; PAPER. PAPER-MAKING; PRODUCTION OF C...   \n",
       "308     B01   0.25  PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL ...   \n",
       "\n",
       "                                                  text  score_map  \n",
       "719  adjacent laterally[SEP]radius[SEP]HUMAN NECESS...          1  \n",
       "256  achieve authentication[SEP]biometric[SEP]ELECT...          1  \n",
       "548  activating position[SEP]active material[SEP]PH...          0  \n",
       "473  acrylate groups[SEP]nitro group[SEP]TEXTILES; ...          0  \n",
       "308  acid absorption[SEP]rosmarinic acid[SEP]PERFOR...          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dataframe, test_size = 0.1, random_state = CFG.seed, stratify = dataframe.score_map)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb4ea4-8f8b-4860-bccf-238f968b3c3e",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c5624-94b1-4170-b3ea-5656ca92c3f4",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fee091-3c88-4e80-b6ba-16dc97f07200",
   "metadata": {
    "id": "Vs9TXF3pufI0"
   },
   "outputs": [],
   "source": [
    "def set_tokenizer(config_dict):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config_dict['model'])\n",
    "    tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "    config_dict['tokenizer'] = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74b765-ebb0-4d17-8c23-ad9d7bfaa153",
   "metadata": {
    "id": "I8CsgvQFnr7e"
   },
   "source": [
    "## Maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4147285a-c73b-4329-8eeb-d862bf599d29",
   "metadata": {
    "id": "Hxle-CPRnr7e"
   },
   "outputs": [],
   "source": [
    "def set_max_len(config_dict, cpc_texts=cpc_texts, train_df=dataframe):\n",
    "    tokenizer = config_dict['tokenizer']\n",
    "    lengths_dict = {}\n",
    "\n",
    "    lengths = []\n",
    "    tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "    lengths_dict['context_text'] = lengths\n",
    "\n",
    "    for text_col in ['anchor', 'target']:\n",
    "        lengths = []\n",
    "        tk0 = tqdm(train_df[text_col].fillna(\"\").values, total=len(train_df))\n",
    "        for text in tk0:\n",
    "            length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "            lengths.append(length)\n",
    "        lengths_dict[text_col] = lengths\n",
    "\n",
    "    config_dict['max_len'] = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n",
    "                    + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cef85f-21a3-4a36-8982-fdf33b97e362",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66398e59-885f-49ef-8f6b-79b5518c7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(config_dict, text):\n",
    "    tokenizer = config_dict['tokenizer']\n",
    "    inputs = tokenizer(text,\n",
    "                       add_special_tokens = True,\n",
    "                       max_length = config_dict['max_len'],\n",
    "                       padding = \"max_length\",\n",
    "                       return_offsets_mapping = False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5087433-6899-4564-9194-537a0164aefd",
   "metadata": {
    "id": "AEyPtCQvnr7f"
   },
   "outputs": [],
   "source": [
    "class USPPM_dataset(Dataset):\n",
    "    def __init__(self, config_dict, train_df, train=True):\n",
    "        self.config_dict = config_dict\n",
    "        self.texts = train_df['text'].values\n",
    "        self.train = train\n",
    "        if train:\n",
    "            self.labels = train_df['score'].values\n",
    "            self.score_map = train_df['score_map'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.config_dict, self.texts[item])\n",
    "        if self.train:\n",
    "            labels = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "            return dict(\n",
    "                  inputs = inputs,\n",
    "                  labels = labels\n",
    "            )\n",
    "        else:\n",
    "            return dict(\n",
    "                  inputs = inputs\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f2468-de35-4bd7-87e8-8b83a3794ab1",
   "metadata": {},
   "source": [
    "# K-Fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18fb2d-a3f7-4cfb-a3dc-ad613c26c2fb",
   "metadata": {
    "id": "Q0HgRiNlnr7g"
   },
   "source": [
    "## KFold DataModule definition                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a3a977-1f80-4039-abfc-eb24ebd4e9a2",
   "metadata": {
    "id": "MVmHarn0nr7h"
   },
   "outputs": [],
   "source": [
    "class BaseKFoldDataModule(LightningDataModule, ABC):\n",
    "    @abstractmethod\n",
    "    def setup_folds(self, num_folds: int) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def setup_fold_index(self, fold_index: int) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d242c6a-01f3-4388-a38b-47f85fcd2240",
   "metadata": {
    "id": "4wjghxElnr7i"
   },
   "source": [
    "## KFoldDataModule implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f986de2-1661-4654-8db0-348e7d8174c1",
   "metadata": {
    "id": "BUeE7TJUnr7i"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class USPPPM_kf_datamodule(BaseKFoldDataModule):\n",
    "    def __init__(self, config_dict, dataframe = dataframe):\n",
    "        \n",
    "        self.config_dict = config_dict\n",
    "        self.prepare_data_per_node = False\n",
    "        self._log_hyperparams = False\n",
    "        \n",
    "        train_dataset: Optional[Dataset] = None\n",
    "        test_dataset: Optional[Dataset] = None\n",
    "        train_fold: Optional[Dataset] = None\n",
    "        val_fold: Optional[Dataset] = None\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "            \n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        train_df, test_df = train_test_split(self.dataframe, test_size = 0.1, random_state = CFG.seed, stratify = self.dataframe.score_map)\n",
    "        self.train_dataset = USPPM_dataset(self.config_dict, train_df)\n",
    "        self.test_dataset = USPPM_dataset(self.config_dict, test_df)\n",
    "\n",
    "    def setup_folds(self, num_folds: int) -> None:\n",
    "        print(\"we are in: datamodule.setup_folds()\")\n",
    "        self.num_folds = num_folds\n",
    "        Fold = StratifiedKFold(n_splits=self.num_folds, shuffle=True)\n",
    "        self.splits = [split for split in Fold.split(self.train_dataset, self.train_dataset.score_map)]\n",
    "        print(self.splits)\n",
    "        print(len(self.splits))\n",
    "\n",
    "    def setup_fold_index(self, fold_index: int) -> None:\n",
    "        print(\"we are in: datamodule.setup_folds_index()\")\n",
    "        train_indices, val_indices = self.splits[fold_index]\n",
    "        self.train_fold = Subset(self.train_dataset, train_indices)\n",
    "        self.val_fold = Subset(self.train_dataset, val_indices)\n",
    "        print(\"TRAIN FOLD\", fold_index + 1, len(self.train_fold))\n",
    "        print(\"VALID FOLD\", fold_index + 1, len(self.val_fold))\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_fold, num_workers = self.config_dict['num_workers'], batch_size = self.config_dict['batch_size'])\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.val_fold, num_workers = self.config_dict['num_workers'], batch_size = self.config_dict['batch_size'])\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.test_dataset, num_workers = self.config_dict['num_workers'], batch_size = self.config_dict['batch_size'])\n",
    "    \n",
    "    def __post_init__(cls):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275e1d1-51fd-4d78-a9f1-4b8dde805ab0",
   "metadata": {
    "id": "1RLF9XVinr7j"
   },
   "source": [
    "## Ensemble Model for kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aebb0fff-b740-4997-9ebd-1624d561d9af",
   "metadata": {
    "id": "dwvwouh3nr7j"
   },
   "outputs": [],
   "source": [
    "class EnsembleVotingModel(LightningModule):\n",
    "    def __init__(self, model_cls: Type[LightningModule], checkpoint_paths: List[str]):\n",
    "        super().__init__()\n",
    "        # Create `num_folds` models with their associated fold weights\n",
    "        self.models = torch.nn.ModuleList([model_cls.load_from_checkpoint(p) for p in checkpoint_paths])\n",
    "        self.last_acc = Accuracy()\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        # Compute the averaged predictions over the `num_folds` models.\n",
    "        logits = torch.stack([m(batch[0]) for m in self.models])\n",
    "\n",
    "        avg_logits = logits.mean(0)\n",
    "        acc = self.last_acc(avg_logits, batch[1])\n",
    "\n",
    "        accs = torch.stack([self.last_acc(logit, batch[1]) for logit in logits])\n",
    "        avg_acc = accs.mean(0)\n",
    "        self.log('voting acc', acc)\n",
    "        print('accs print', accs)\n",
    "        print('avg_acc print', avg_acc)\n",
    "        self.log('avg_acc', avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea969f-f0e2-4771-8460-f5df58d3aa7e",
   "metadata": {
    "id": "E2ch26C4nr7k"
   },
   "source": [
    "## KFoldLoop implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdcaf77c-dc40-4149-9a17-6b297691c26c",
   "metadata": {
    "id": "ozwbPnfenr7m"
   },
   "outputs": [],
   "source": [
    "class KFoldLoop(Loop):\n",
    "    def __init__(self, num_folds: int, export_path: str) -> None:\n",
    "        super().__init__()\n",
    "        self.num_folds = num_folds\n",
    "        self.current_fold: int = 0\n",
    "        self.export_path = export_path\n",
    "\n",
    "    @property\n",
    "    def done(self) -> bool:\n",
    "        return self.current_fold >= self.num_folds\n",
    "\n",
    "    def connect(self, fit_loop: FitLoop) -> None:\n",
    "        self.fit_loop = fit_loop\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Nothing to reset in this loop.\"\"\"\n",
    "\n",
    "    def on_run_start(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Used to call `setup_folds` from the `BaseKFoldDataModule` instance and store the original weights of the model.\"\"\"\n",
    "        print(\"Is datamodule a datamodule?\")\n",
    "        assert isinstance(self.trainer.datamodule, BaseKFoldDataModule)\n",
    "        print(\"Datamodule is a datamodule\")\n",
    "        self.trainer.datamodule.setup_folds(self.num_folds)\n",
    "        self.lightning_module_state_dict = deepcopy(self.trainer.lightning_module.state_dict())\n",
    "\n",
    "    def on_advance_start(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Used to call `setup_fold_index` from the `BaseKFoldDataModule` instance.\"\"\"\n",
    "        print(f\"STARTING FOLD {self.current_fold+1}\")\n",
    "        assert isinstance(self.trainer.datamodule, BaseKFoldDataModule)\n",
    "        self.trainer.datamodule.setup_fold_index(self.current_fold)\n",
    "\n",
    "    def advance(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Used to the run a fitting and testing on the current hold.\"\"\"\n",
    "        self._reset_fitting()  # requires to reset the tracking stage.\n",
    "        self.fit_loop.run()\n",
    "\n",
    "        self._reset_testing()  # requires to reset the tracking stage.\n",
    "        self.trainer.test_loop.run()\n",
    "        print('TEST for FOLD', self.current_fold+1)\n",
    "        \n",
    "        self.current_fold += 1  # increment fold tracking number.\n",
    "\n",
    "    def on_advance_end(self) -> None:\n",
    "        \"\"\"Used to save the weights of the current fold and reset the LightningModule and its optimizers.\"\"\"\n",
    "        self.trainer.save_checkpoint(os.path.join(self.export_path, f\"model.{self.current_fold}.pt\"))\n",
    "        # restore the original weights + optimizers and schedulers.\n",
    "        self.trainer.lightning_module.load_state_dict(self.lightning_module_state_dict)\n",
    "        self.trainer.strategy.setup_optimizers(self.trainer)\n",
    "        self.replace(fit_loop=FitLoop)\n",
    "\n",
    "    def on_run_end(self) -> None:\n",
    "        \"\"\"Used to compute the performance of the ensemble model on the test set.\"\"\"\n",
    "        checkpoint_paths = [os.path.join(self.export_path, f\"model.{f_idx + 1}.pt\") for f_idx in range(self.num_folds)]\n",
    "        voting_model = EnsembleVotingModel(type(self.trainer.lightning_module), checkpoint_paths)\n",
    "        voting_model.trainer = self.trainer\n",
    "\n",
    "        # This requires to connect the new model and move it the right device.\n",
    "        self.trainer.strategy.connect(voting_model)\n",
    "        self.trainer.strategy.model_to_device()\n",
    "        self.trainer.test_loop.run()\n",
    "\n",
    "    def on_save_checkpoint(self) -> Dict[str, int]:\n",
    "        return {\"current_fold\": self.current_fold}\n",
    "\n",
    "    def on_load_checkpoint(self, state_dict: Dict) -> None:\n",
    "        self.current_fold = state_dict[\"current_fold\"]\n",
    "\n",
    "    def _reset_fitting(self) -> None:\n",
    "        self.trainer.reset_train_dataloader()\n",
    "        self.trainer.reset_val_dataloader()\n",
    "        self.trainer.state.fn = TrainerFn.FITTING\n",
    "        self.trainer.training = True\n",
    "\n",
    "    def _reset_testing(self) -> None:\n",
    "        self.trainer.reset_test_dataloader()\n",
    "        self.trainer.state.fn = TrainerFn.TESTING\n",
    "        self.trainer.testing = True\n",
    "\n",
    "    def __getattr__(self, key) -> Any:\n",
    "        # requires to be overridden as attributes of the wrapped loop are being accessed.\n",
    "        if key not in self.__dict__:\n",
    "            return getattr(self.fit_loop, key)\n",
    "        return self.__dict__[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b6702-c290-42e7-8055-33f48a348dff",
   "metadata": {
    "id": "GYPJGJ-Fnr7n"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f8ff48d-c3de-4e84-8df6-b064ed250e6f",
   "metadata": {
    "id": "GY0QVy62nr7o"
   },
   "outputs": [],
   "source": [
    "class USPPPM_model(pl.LightningModule):\n",
    "    def __init__(self, config_dict=config_dict, config_path=None, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config_dict = config_dict\n",
    "        self.n_warmup_steps = config_dict['warmup_steps']\n",
    "        self.n_training_steps = config_dict['training_steps']\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "        \n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(config_dict['model'], output_hidden_states = True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "            \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(config_dict['model'], config = self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "            \n",
    "        self.fc_dropout = nn.Dropout(config_dict['fc_dropout'])\n",
    "        self.fc = nn.Linear(self.config.hidden_size, config_dict['target_size'])\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.batch_labels = []\n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(inputs, labels.unsqueeze(1))\n",
    "        session.report({\"train_loss\": loss})  # Send the score to Tune.\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(inputs, labels.unsqueeze(1))\n",
    "        session.report({\"val_loss\": loss})  # Send the score to Tune.\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs = batch[\"inputs\"]\n",
    "        loss, outputs = self(inputs)\n",
    "        session.report({\"test_loss\": loss})  # Send the score to Tune.\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "    \n",
    "    def validation_epoch_end(self, batch_results):\n",
    "        outputs, labels, losses = [], [], []\n",
    "        for batch in batch_results:\n",
    "            outputs.append(batch['predictions'])\n",
    "            labels.append(batch['labels'])\n",
    "            losses.append(batch['loss'])\n",
    "\n",
    "        labels = torch.cat(labels).cpu().numpy()\n",
    "        predictions = np.concatenate(torch.cat(outputs).sigmoid().to('cpu').numpy())\n",
    "        score = get_score(labels, predictions)\n",
    "        session.report({\"val_score\": score})  # Send the score to Tune.\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config_dict['encoder_lr'])\n",
    "        # optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        )\n",
    "        return dict(\n",
    "          optimizer=optimizer,\n",
    "          lr_scheduler=dict(\n",
    "            scheduler=scheduler,\n",
    "            interval='step'\n",
    "          )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563fc01-1170-43cf-ac1b-f577730cf1a6",
   "metadata": {
    "id": "fK6gpNx1nr7q"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b10ba-6205-419f-844f-0fe5b9dc07d0",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f7ea00-b260-41fd-a636-159e38b66fa8",
   "metadata": {
    "id": "fAEhe31znr7q"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "metrics = {\"val_score\": \"val_score\", \"train_loss\" : \"train_loss\", \"val_loss\" : \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143d9932-bb80-433c-b534-9464d9729443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config_dict):  # Pass a \"config\" dictionary into your trainable.\n",
    "\n",
    "    set_tokenizer(config_dict)\n",
    "    set_max_len(config_dict)\n",
    "    # train_dataset = USPPM_dataset(config_dict)\n",
    "    datamodule = USPPPM_kf_datamodule(config_dict, dataframe)\n",
    "    \n",
    "    steps_per_epoch = len(train_df) // config_dict['batch_size']\n",
    "    config_dict['training_steps'] = steps_per_epoch * config_dict['epochs']\n",
    "    \n",
    "    model = USPPPM_model(config_dict)\n",
    "    \n",
    "    callbacks = [TuneReportCallback(metrics, on=\"validation_end\")]\n",
    "    trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=config_dict['epochs'],\n",
    "            devices=[1],\n",
    "            accelerator=\"gpu\",\n",
    "            )\n",
    "    \n",
    "    internal_fit_loop = trainer.fit_loop\n",
    "    trainer.fit_loop = KFoldLoop(config_dict['n_fold'], export_path=\"./\")\n",
    "    trainer.fit_loop.connect(internal_fit_loop)\n",
    "    \n",
    "    print(type(trainer.fit_loop))\n",
    "    print(\"DEBUG: Fitting is about to start\")\n",
    "    trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad5bea5-2224-4ef3-b06c-21db07e5a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(tune.with_resources(trainable, \n",
    "                                       {\"gpu\": 4}), \n",
    "                                       param_space = config_dict,\n",
    "                                       tune_config = tune.TuneConfig(metric=\"val_score\", mode=\"max\"),\n",
    "                                       run_config = air.RunConfig(name=\"tune_uspppm\", verbose=3)\n",
    "                                      )\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ea534b6-3f59-4342-8e6a-738bb2f14ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 18:58:05,091\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-06 18:58:20 (running for 00:00:15.83)<br>Memory usage on this node: 87.2/503.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/80 CPUs, 0/4 GPUs, 0.0/289.07 GiB heap, 0.0/127.88 GiB objects (0.0/1.0 accelerator_type:P100)<br>Result logdir: /storagenfs/m.petix/ray_results/tune_uspppm<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_903aa_00000</td><td>ERROR   </td><td>131.114.50.210:278924</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_903aa_00000</td><td style=\"text-align: right;\">           1</td><td>/storagenfs/m.petix/ray_results/tune_uspppm/trainable_903aa_00000_0_2022-11-06_18-58-05/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 136/136 [00:00<00:00, 4672.94it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "100%|| 1000/1000 [00:00<00:00, 13154.89it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "100%|| 1000/1000 [00:00<00:00, 14512.51it/s]\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m /storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m Missing logger folder: lightning_logs/USPPPM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m <class '__main__.KFoldLoop'>\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m DEBUG: Fitting is about to start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   | Name       | Type              | Params\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m -------------------------------------------------\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 0 | criterion  | BCEWithLogitsLoss | 0     \n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 1 | model      | DistilBertModel   | 66.4 M\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 2 | fc_dropout | Dropout           | 0     \n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 3 | fc         | Linear            | 769   \n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 4 | attention  | Sequential        | 394 K \n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m -------------------------------------------------\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 66.8 M    Trainable params\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 66.8 M    Total params\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 267.032   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m 2022-11-06 18:58:20,664\tERROR function_trainable.py:298 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     return self._trainable_func(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"<ipython-input-23-bc62486c66c9>\", line 28, in trainable\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     self._call_and_handle_interrupt(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1274, in _run_train\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     self._run_sanity_check()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1336, in _run_sanity_check\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     val_loop._reload_evaluation_dataloaders()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 237, in _reload_evaluation_dataloaders\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     self.trainer.reset_val_dataloader()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1932, in reset_val_dataloader\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     self.num_val_batches, self.val_dataloaders = self._data_connector._reset_eval_dataloader(\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 365, in _reset_eval_dataloader\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     dataloaders = self._request_dataloader(mode)\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 453, in _request_dataloader\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     dataloader = source.dataloader()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 530, in dataloader\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m     return method()\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m   File \"<ipython-input-18-6f47d60e2b1a>\", line 41, in val_dataloader\n",
      "\u001b[2m\u001b[36m(trainable pid=278924)\u001b[0m AttributeError: 'USPPPM_kf_datamodule' object has no attribute 'val_fold'\n",
      "2022-11-06 18:58:20,776\tERROR trial_runner.py:987 -- Trial trainable_903aa_00000: Error processing event.\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=278924, ip=131.114.50.210, repr=trainable)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 349, in train\n",
      "    result = self.step()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 417, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 589, in _report_thread_runner_error\n",
      "    raise e\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\n",
      "    self._entrypoint()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-23-bc62486c66c9>\", line 28, in trainable\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 696, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1274, in _run_train\n",
      "    self._run_sanity_check()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1336, in _run_sanity_check\n",
      "    val_loop._reload_evaluation_dataloaders()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 237, in _reload_evaluation_dataloaders\n",
      "    self.trainer.reset_val_dataloader()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1932, in reset_val_dataloader\n",
      "    self.num_val_batches, self.val_dataloaders = self._data_connector._reset_eval_dataloader(\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 365, in _reset_eval_dataloader\n",
      "    dataloaders = self._request_dataloader(mode)\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 453, in _request_dataloader\n",
      "    dataloader = source.dataloader()\n",
      "  File \"/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 530, in dataloader\n",
      "    return method()\n",
      "  File \"<ipython-input-18-6f47d60e2b1a>\", line 41, in val_dataloader\n",
      "AttributeError: 'USPPPM_kf_datamodule' object has no attribute 'val_fold'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for trainable_903aa_00000:\n",
      "  date: 2022-11-06_18-58-13\n",
      "  experiment_id: 26523de921f4417abfc3e43ca26e4f3b\n",
      "  hostname: c4130-p100\n",
      "  node_ip: 131.114.50.210\n",
      "  pid: 278924\n",
      "  timestamp: 1667757493\n",
      "  trial_id: 903aa_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 18:58:21,100\tERROR tune.py:754 -- Trials did not complete: [trainable_903aa_00000]\n",
      "2022-11-06 18:58:21,102\tINFO tune.py:758 -- Total run time: 16.01 seconds (15.75 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'trial_id': '903aa_00000'}, error=RayTaskError(AttributeError)(AttributeError(\"'USPPPM_kf_datamodule' object has no attribute 'val_fold'\")), log_dir=PosixPath('/storagenfs/m.petix/ray_results/tune_uspppm/trainable_903aa_00000_0_2022-11-06_18-58-05'))\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result()  # Get best result object\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d41de4-a568-4693-8519-cd1bb2d02a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6839021d-1fba-43cc-afe0-bd79a6ab96b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d62caab93d0409b9e049bd6bbcd640d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820a5dd496774c0eb1ec17d03a9d1158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3df24737a748ea812f7a73478084b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:229: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:233: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "  rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:258: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "  rank_zero_deprecation(\n",
      "/storagenfs/m.petix/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:267: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.KFoldLoop'>\n",
      "DEBUG: Fitting is about to start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | criterion  | BCEWithLogitsLoss | 0     \n",
      "1 | model      | DistilBertModel   | 66.4 M\n",
      "2 | fc_dropout | Dropout           | 0     \n",
      "3 | fc         | Linear            | 769   \n",
      "4 | attention  | Sequential        | 394 K \n",
      "-------------------------------------------------\n",
      "66.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.8 M    Total params\n",
      "267.032   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202a714c639f4156978679fa6522330d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'USPPPM_kf_datamodule' object has no attribute 'val_fold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9135d746aa4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-bc62486c66c9>\u001b[0m in \u001b[0;36mtrainable\u001b[0;34m(config_dict)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: Fitting is about to start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \"\"\"\n\u001b[1;32m    695\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         self._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         \u001b[0;31m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         )\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# reload dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reload_evaluation_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             self.num_sanity_val_batches = [\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval_batches\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_val_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36m_reload_evaluation_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloaders\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_reload_val_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_val_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mreset_val_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_val_dl_reload_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             self.num_val_batches, self.val_dataloaders = self._data_connector._reset_eval_dataloader(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpl_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36m_reset_eval_dataloader\u001b[0;34m(self, mode, model)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;31m# always get the loaders first so we can count how many there are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverfit_batches\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36m_request_dataloader\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;31m# methods so that the re-instantiated object is as close to the original as possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36mdataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6f47d60e2b1a>\u001b[0m in \u001b[0;36mval_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_workers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'USPPPM_kf_datamodule' object has no attribute 'val_fold'"
     ]
    }
   ],
   "source": [
    "trainable(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef1b6c-8cf1-48e3-ac78-d172efdbb973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
